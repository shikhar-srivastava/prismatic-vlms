{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the root directory and the datasets of interest\n",
    "root_dir = 'evaluations/'\n",
    "datasets = {\n",
    "    'vqa-v2': 'vqa-v2-slim',\n",
    "    'text-vqa': 'text-vqa-slim',\n",
    "    'gqa': 'gqa-slim'\n",
    "}\n",
    "nlu_datasets = [\"wsc273\", \"winogrande\", \"lambada_standard\", \"arc_easy\", \"arc_challenge\"]\n",
    "\n",
    "# Initialize the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Iterate through each model folder under the root directory\n",
    "for model_name in os.listdir(root_dir):\n",
    "    model_path = os.path.join(root_dir, model_name)\n",
    "    if ('pythia' not in model_path):\n",
    "        continue\n",
    "    if os.path.isdir(model_path):\n",
    "        print(f\"Processing model: {model_name}\")\n",
    "        model_result = {}\n",
    "        \n",
    "        # Iterate through each dataset folder under the model folder\n",
    "        for dataset, dataset_slim in datasets.items():\n",
    "            dataset_path = os.path.join(model_path, dataset, dataset_slim, 'prism-clip+7b', 'metrics.json')\n",
    "            if os.path.isfile(dataset_path):\n",
    "                # Parse the metrics.json file\n",
    "                with open(dataset_path, 'r') as f:\n",
    "                    metrics = json.load(f)\n",
    "                    summary = metrics.get('summary', {})\n",
    "                    \n",
    "                    # Capture accuracies based on the dataset\n",
    "                    if dataset == 'vqa-v2':\n",
    "                        accuracy = summary.get('accuracy')\n",
    "                        if accuracy is not None:\n",
    "                            model_result['vqa-v2'] = accuracy / 100.0\n",
    "                    elif dataset == 'text-vqa':\n",
    "                        ocr_accuracy = summary.get('accuracy__TextVQA-OCR')\n",
    "                        pure_accuracy = summary.get('accuracy__TextVQA-Pure')\n",
    "                        if ocr_accuracy is not None:\n",
    "                            model_result['textvqa-ocr'] = ocr_accuracy\n",
    "                        if pure_accuracy is not None:\n",
    "                            model_result['textvqa-pure'] = pure_accuracy\n",
    "                    elif dataset == 'gqa':\n",
    "                        accuracy = summary.get('accuracy')\n",
    "                        if accuracy is not None:\n",
    "                            model_result['gqa'] = accuracy / 100.0\n",
    "        \n",
    "        # Parse NLU/NLG results\n",
    "        nlu_path = os.path.join(model_path, 'nlp/nlu', 'results.json')\n",
    "        if os.path.isfile(nlu_path):\n",
    "            with open(nlu_path, 'r') as f:\n",
    "                nlu_results = json.load(f).get('results', {})\n",
    "                for nlu_dataset in nlu_datasets:\n",
    "                    if nlu_dataset in nlu_results:\n",
    "                        acc = nlu_results[nlu_dataset].get('acc,none')\n",
    "                        if acc is not None:\n",
    "                            model_result[nlu_dataset] = acc\n",
    "\n",
    "        # Parse MMLU results\n",
    "        mmlu_path = os.path.join(model_path, 'nlp/mmlu', 'results.json')\n",
    "        if os.path.isfile(mmlu_path):\n",
    "            with open(mmlu_path, 'r') as f:\n",
    "                mmlu_results = json.load(f).get('results', {})\n",
    "                mmlu_acc = mmlu_results.get('mmlu', {}).get('acc,none')\n",
    "                if mmlu_acc is not None:\n",
    "                    model_result['mmlu'] = mmlu_acc\n",
    "\n",
    "        # Add the model results to the final result dictionary\n",
    "        if model_result:\n",
    "            result[model_name] = model_result\n",
    "\n",
    "# Save the final JSON to results_A.json\n",
    "with open('results_A.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to results_A.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
