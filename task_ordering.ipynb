{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: naive-ft, Stage: 0, VL: 0.0037, NL: 0.3863352100999474\n",
      "Model: naive-ft, Stage: 1, VL: 0.4421524886376234, NL: 0.2700812156708484\n",
      "Model: naive-ft, Stage: 2, VL: 0.16669767843708932, NL: 0.34263702858390443\n",
      "Model: naive-ft, Stage: 3, VL: 0.004805223973421436, NL: 0.3151680192897782\n",
      "Model: olf, Stage: 0, VL: 0.0040999999999999995, NL: 0.38621147563923447\n",
      "Model: olf, Stage: 1, VL: 0.43272009065155803, NL: 0.3355705798232125\n",
      "Model: olf, Stage: 2, VL: 0.10596761881622202, NL: 0.35619713904716904\n",
      "Model: olf, Stage: 3, VL: 0.020523550104608348, NL: 0.3279029484150912\n",
      "Model: soft, Stage: 0, VL: 0.0045000000000000005, NL: 0.38408061658239784\n",
      "Model: soft, Stage: 1, VL: 0.0015918367346938777, NL: 0.2454425568378775\n",
      "Model: soft, Stage: 2, VL: 0.10230418779859914, NL: 0.33810199662515095\n",
      "Model: soft, Stage: 3, VL: 0.003102369722228088, NL: 0.2831706057243446\n",
      "Model: ia3, Stage: 0, VL: 0.001, NL: 0.40600564872147704\n",
      "Model: ia3, Stage: 1, VL: 0.24948089844499902, NL: 0.3957752637623065\n",
      "Model: ia3, Stage: 2, VL: 0.0839628614382616, NL: 0.40026584021388995\n",
      "Model: ia3, Stage: 3, VL: 0.004781475525401752, NL: 0.40302616151465237\n",
      "Model: lora, Stage: 0, VL: 0.002, NL: 0.3784273481481115\n",
      "Model: lora, Stage: 1, VL: 0.374638336115034, NL: 0.3799173833943919\n",
      "Model: lora, Stage: 2, VL: 0.14028927544647746, NL: 0.367197878990521\n",
      "Model: lora, Stage: 3, VL: 0.09589530345069068, NL: 0.3485350680819869\n",
      "Model: sgm, Stage: 0, VL: 0.001, NL: 0.3810485695829846\n",
      "Model: sgm, Stage: 1, VL: 0.363138591322978, NL: 0.37644060500130067\n",
      "Model: sgm, Stage: 2, VL: 0.11690132796859852, NL: 0.3782128819730278\n",
      "Model: sgm, Stage: 3, VL: 0.003228536424869774, NL: 0.3289816479866609\n",
      "Model: sgm-olf, Stage: 0, VL: 0.001, NL: 0.3877200965903955\n",
      "Model: sgm-olf, Stage: 1, VL: 0.3336884643644379, NL: 0.38672764739776067\n",
      "Model: sgm-olf, Stage: 2, VL: 0.12801830103460632, NL: 0.3782274294195454\n",
      "Model: sgm-olf, Stage: 3, VL: 0.004698733061818007, NL: 0.3331599703209514\n",
      "Model: rehearsal1, Stage: 0, VL: 0.0037, NL: 0.3863352100999474\n",
      "Model: rehearsal1, Stage: 1, VL: 0.377391536977492, NL: 0.2831597762236547\n",
      "Model: rehearsal1, Stage: 2, VL: 0.034741401479705655, NL: 0.3180421774885778\n",
      "Model: rehearsal1, Stage: 3, VL: 0.0355303716175607, NL: 0.3156863341394475\n",
      "Model: rehearsal10, Stage: 0, VL: 0.0037, NL: 0.3863352100999474\n",
      "Model: rehearsal10, Stage: 1, VL: 0.4184446337711513, NL: 0.3253639711571972\n",
      "Model: rehearsal10, Stage: 2, VL: 0.19910599865085127, NL: 0.3354831095161295\n",
      "Model: rehearsal10, Stage: 3, VL: 0.17796758163144205, NL: 0.3551835393938372\n",
      "Model: sgm-rehearsal1, Stage: 0, VL: 0.001, NL: 0.3810485695829846\n",
      "Model: sgm-rehearsal1, Stage: 1, VL: 0.3527785253329672, NL: 0.38492655078295074\n",
      "Model: sgm-rehearsal1, Stage: 2, VL: 0.12380275745484842, NL: 0.36965523080833634\n",
      "Model: sgm-rehearsal1, Stage: 3, VL: 0.10207281503268635, NL: 0.36443544021476076\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Model Performance:} Task-wise Accuracies and Forgetting of Each Mitigation Method across VL and NL tasks}\n",
      "  \\label{tab:vl_nl_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cc|cc|cc|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{2}{c|}{\\textbf{Task 0 (Instruct)}} & \\multicolumn{2}{c|}{\\textbf{Task 1 (VQA)}} & \\multicolumn{2}{c|}{\\textbf{Task 2 (OCR)}} & \\multicolumn{2}{c}{\\textbf{Task 3 (Ref)}} \\\\\n",
      "     & \\textbf{VL} & \\textbf{NL} & \\textbf{VL} & \\textbf{NL} & \\textbf{VL} & \\textbf{NL} & \\textbf{VL} & \\textbf{NL} \\\\\n",
      "     & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} \\\\\n",
      "     \\midrule\n",
      "Original LLaVA & 0.37 & 0.58 & 44.22 & 12.21 & 16.67 & 4.95 & 0.48 & 7.70 \\\\\n",
      "\\midrule\n",
      "OLF & 0.41 & 0.60 & 43.27 & 5.66 & 10.60 & 3.60 & 2.05 & 6.43 \\\\\n",
      "Soft Targets (ST) & 0.45 & 0.81 & 0.16 & 14.67 & 10.23 & 5.41 & 0.31 & 10.90 \\\\\n",
      "IA3 & 0.10 & -1.38 & 24.95 & -0.36 & 8.40 & -0.81 & 0.48 & -1.08 \\\\\n",
      "LoRA & 0.20 & 1.38 & 37.46 & 1.23 & 14.03 & 2.50 & 9.59 & 4.36 \\\\\n",
      "mSGM & 0.10 & 1.11 & 36.31 & 1.57 & 11.69 & 1.40 & 0.32 & 6.32 \\\\\n",
      "mSGM + OLF & 0.10 & 0.45 & 33.37 & 0.55 & 12.80 & 1.40 & 0.47 & 5.90 \\\\\n",
      "Rehearsal \\((1\\%)\\) & 0.37 & 0.58 & 37.74 & 10.90 & 3.47 & 7.41 & 3.55 & 7.65 \\\\\n",
      "Rehearsal \\((10\\%)\\) & 0.37 & 0.58 & 41.84 & 6.68 & 19.91 & 5.67 & 17.80 & 3.70 \\\\\n",
      "mSGM + Rehearsal \\((1\\%)\\) & 0.10 & 1.11 & 35.28 & 0.73 & 12.38 & 2.25 & 10.21 & 2.77 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Define the dataset stages and the corresponding labels\n",
    "stages = [\"Instruct (0)\", \"VQA (1)\", \"OCR (2)\", \"Ref (3)\"]\n",
    "datasets = [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\", \"refcoco\"]\n",
    "nlu_nlg_datasets = [\"wsc273\", \"winogrande\", \"lambada_standard\", \"arc_easy\", \"arc_challenge\"]\n",
    "vl_evaluate_sequence = [[\"vqa-v2\"], [\"vqa-v2\", \"gqa\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\", \"refcoco\"]]\n",
    "\n",
    "# Define the mitigation methods and their sequence of model names\n",
    "cl_runs = {\n",
    "    \"naive-ft\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m\",\n",
    "        \"cl-vqa-stage-1-pythia+410m\",\n",
    "        \"cl-ocr-stage-2-pythia+410m\",\n",
    "        \"cl-ref-stage-3-pythia+410m\"\n",
    "    ],\n",
    "    \"olf\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-olf\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-olf\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-olf\",\n",
    "        \"cl-ref-stage-3-pythia+410m-olf\"\n",
    "    ],\n",
    "    \"soft\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-soft\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-soft\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-soft\",\n",
    "        \"cl-ref-stage-3-pythia+410m-soft\"\n",
    "    ],\n",
    "    \"ia3\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-ia3\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-ia3\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-ia3\",\n",
    "        \"cl-ref-stage-3-pythia+410m-ia3\"\n",
    "    ],\n",
    "    \"lora\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-lora\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-lora\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-lora\",\n",
    "        \"cl-ref-stage-3-pythia+410m-lora\"\n",
    "    ],\n",
    "    \"sgm\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-sgm\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-sgm\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-sgm\",\n",
    "        \"cl-ref-stage-3-pythia+410m-sgm\"\n",
    "    ],\n",
    "    \"sgm-olf\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-sgm-olf\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-sgm-olf\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-sgm-olf\",\n",
    "        \"cl-ref-stage-3-pythia+410m-sgm-olf\"\n",
    "    ],\n",
    "    \"rehearsal1\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-rehearsal1\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-rehearsal1\",\n",
    "        \"cl-ref-stage-3-pythia+410m-rehearsal1\"\n",
    "    ],\n",
    "    \"rehearsal10\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-rehearsal10\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-rehearsal10\",\n",
    "        \"cl-ref-stage-3-pythia+410m-rehearsal10\"\n",
    "    ],\n",
    "    \"sgm-rehearsal1\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-sgm\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-sgm-rehearsal1\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-sgm-rehearsal1\",\n",
    "        \"cl-ref-stage-3-pythia+410m-sgm-rehearsal1\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Baseline run_id\n",
    "baseline_run_id = \"reproduction-align-pythia+410m\"\n",
    "\n",
    "# Load the JSON data from the results file\n",
    "with open('results_nlp.json', 'r') as file:\n",
    "    result = json.load(file)\n",
    "\n",
    "# Check for the existence of baseline results\n",
    "baseline_results = result.get(baseline_run_id)\n",
    "if not baseline_results:\n",
    "    raise ValueError(f\"Baseline run ID '{baseline_run_id}' not found in results.\")\n",
    "\n",
    "# Function to replace None values with a small positive value\n",
    "def replace_none_and_zeros(arr, epsilon=EPSILON):\n",
    "    return [epsilon if (x is None or np.isnan(x) or x == 0) else x for x in arr]\n",
    "\n",
    "# Calculate performance changes and averages for each CL run\n",
    "cl_performance_change = {}\n",
    "cl_performance = {}\n",
    "\n",
    "for model_name, run_ids in cl_runs.items():\n",
    "    changes = {}\n",
    "    performances = {}\n",
    "    missing_data = False\n",
    "\n",
    "    for i, run_id in enumerate(run_ids):\n",
    "        current_results = result.get(run_id)\n",
    "        if not current_results:\n",
    "            missing_data = True\n",
    "            print(f\"Run '{run_id}' missing for model '{model_name}'\")\n",
    "            break\n",
    "        \n",
    "        change = {dataset: current_results.get(dataset, np.nan) - baseline_results.get(dataset, np.nan) for dataset in baseline_results.keys()}\n",
    "        changes[f'stage_{i}'] = change\n",
    "        performances[f'stage_{i}'] = current_results\n",
    "        \n",
    "        vl_scores = replace_none_and_zeros([current_results.get(dataset, np.nan) for dataset in vl_evaluate_sequence[i]])\n",
    "        baseline_vl_scores = replace_none_and_zeros([baseline_results.get(dataset, np.nan) for dataset in vl_evaluate_sequence[i]])\n",
    "        avg_delta_vl = hmean(baseline_vl_scores) - hmean(vl_scores)\n",
    "        avg_acc_vl = hmean(vl_scores)\n",
    "        \n",
    "        nl_scores = replace_none_and_zeros([current_results.get(dataset, np.nan) for dataset in nlu_nlg_datasets])\n",
    "        baseline_nl_scores = replace_none_and_zeros([baseline_results.get(dataset, np.nan) for dataset in nlu_nlg_datasets])\n",
    "        avg_delta_nl = hmean(baseline_nl_scores) -  hmean(nl_scores)\n",
    "        avg_acc_nl = hmean(nl_scores)\n",
    "        \n",
    "        changes[f'stage_{i}_avg'] = {'VL': avg_delta_vl, 'NL': avg_delta_nl}\n",
    "        performances[f'stage_{i}_avg'] = {'VL': avg_acc_vl, 'NL': avg_acc_nl}\n",
    "        print(f\"Model: {model_name}, Stage: {i}, VL: {avg_acc_vl}, NL: {avg_acc_nl}\")\n",
    "    \n",
    "    if not missing_data:\n",
    "        cl_performance_change[model_name] = changes\n",
    "        cl_performance[model_name] = performances\n",
    "\n",
    "# Save the performance changes and averages to JSON files\n",
    "with open('cl_performance_change.json', 'w') as f:\n",
    "    json.dump(cl_performance_change, f, indent=2)\n",
    "\n",
    "with open('cl_performance.json', 'w') as f:\n",
    "    json.dump(cl_performance, f, indent=2)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "name_mapping = {\n",
    "    'olf': 'OLF',\n",
    "    'sgm': 'mSGM',\n",
    "    'sgm-rehearsal1': 'mSGM + Rehearsal \\((1\\%)\\)',\n",
    "    'sgm-olf': 'mSGM + OLF',\n",
    "    'rehearsal1': 'Rehearsal \\((1\\%)\\)',\n",
    "    'rehearsal10': 'Rehearsal \\((10\\%)\\)',\n",
    "    'lora': 'LoRA',\n",
    "    'naive-ft': 'Original LLaVA',\n",
    "    'soft': 'Soft Targets (ST)',\n",
    "    'ia3': 'IA3'\n",
    "}\n",
    "\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Task-wise Accuracies and Forgetting of Each Mitigation Method across VL and NL tasks}\n",
    "  \\\\label{tab:vl_nl_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cc|cc|cc|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{2}{c|}{\\\\textbf{Task 0 (Instruct)}} & \\\\multicolumn{2}{c|}{\\\\textbf{Task 1 (VQA)}} & \\\\multicolumn{2}{c|}{\\\\textbf{Task 2 (OCR)}} & \\\\multicolumn{2}{c}{\\\\textbf{Task 3 (Ref)}} \\\\\\\\\n",
    "     & \\\\textbf{VL} & \\\\textbf{NL} & \\\\textbf{VL} & \\\\textbf{NL} & \\\\textbf{VL} & \\\\textbf{NL} & \\\\textbf{VL} & \\\\textbf{NL} \\\\\\\\\n",
    "     & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Include the Naive-FT benchmark first\n",
    "model_name = 'naive-ft'\n",
    "tasks = cl_performance[model_name]\n",
    "\n",
    "model_results = (\n",
    "    name_mapping[model_name],\n",
    "    tasks['stage_0_avg']['VL'] * 100, cl_performance_change[model_name]['stage_0_avg']['NL'] * 100,\n",
    "    tasks['stage_1_avg']['VL'] * 100, cl_performance_change[model_name]['stage_1_avg']['NL'] * 100,\n",
    "    tasks['stage_2_avg']['VL'] * 100, cl_performance_change[model_name]['stage_2_avg']['NL'] * 100,\n",
    "    tasks['stage_3_avg']['VL'] * 100, cl_performance_change[model_name]['stage_3_avg']['NL'] * 100\n",
    ")\n",
    "\n",
    "latex_code += \"{model} & {t0_vl_a:.2f} & {t0_nl_d:.2f} & {t1_vl_a:.2f} & {t1_nl_d:.2f} & {t2_vl_a:.2f} & {t2_nl_d:.2f} & {t3_vl_a:.2f} & {t3_nl_d:.2f} \\\\\\\\\\n\".format(\n",
    "    model=model_results[0],\n",
    "    t0_vl_a=model_results[1], t0_nl_d=model_results[2],\n",
    "    t1_vl_a=model_results[3], t1_nl_d=model_results[4],\n",
    "    t2_vl_a=model_results[5], t2_nl_d=model_results[6],\n",
    "    t3_vl_a=model_results[7], t3_nl_d=model_results[8]\n",
    ")\n",
    "\n",
    "latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "# Include the rest of the models\n",
    "for model_name, tasks in cl_performance.items():\n",
    "    if model_name not in name_mapping or model_name == 'naive-ft':\n",
    "        continue\n",
    "\n",
    "    model_results = (\n",
    "        name_mapping[model_name],\n",
    "        tasks['stage_0_avg']['VL'] * 100, cl_performance_change[model_name]['stage_0_avg']['NL'] * 100,\n",
    "        tasks['stage_1_avg']['VL'] * 100, cl_performance_change[model_name]['stage_1_avg']['NL'] * 100,\n",
    "        tasks['stage_2_avg']['VL'] * 100, cl_performance_change[model_name]['stage_2_avg']['NL'] * 100,\n",
    "        tasks['stage_3_avg']['VL'] * 100, cl_performance_change[model_name]['stage_3_avg']['NL'] * 100\n",
    "    )\n",
    "    \n",
    "    latex_code += \"{model} & {t0_vl_a:.2f} & {t0_nl_d:.2f} & {t1_vl_a:.2f} & {t1_nl_d:.2f} & {t2_vl_a:.2f} & {t2_nl_d:.2f} & {t3_vl_a:.2f} & {t3_nl_d:.2f} \\\\\\\\\\n\".format(\n",
    "        model=model_results[0],\n",
    "        t0_vl_a=model_results[1], t0_nl_d=model_results[2],\n",
    "        t1_vl_a=model_results[3], t1_nl_d=model_results[4],\n",
    "        t2_vl_a=model_results[5], t2_nl_d=model_results[6],\n",
    "        t3_vl_a=model_results[7], t3_nl_d=model_results[8]\n",
    "    )\n",
    "\n",
    "latex_code += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [\"Task 2 (Instruct)\", \"Task 3 (OCR)\", \"Task 4 (Ref)\",  \"Task 5 (VQA)\"]\n",
    "vl_evaluate_sequence = [[\"gqa\"], [\"gqa\", \"textvqa-ocr\", \"textvqa-pure\"], [\"refcoco\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\", \"refcoco\"]]\n",
    "\n",
    "cl_runs = {\n",
    "    \"naive-ft\": [\n",
    "        \"cl-instruct-stage-0-pythia+160m-iorv\",\n",
    "        \"cl-ocr-stage-1-pythia+160m-iorv\",\n",
    "        \"cl-ref-stage-2-pythia+160m-iorv\",\n",
    "        \"cl-vqa-stage-3-pythia+160m-iorv\"\n",
    "    ],\n",
    "    \"sgm-rehearsal1\": [\n",
    "        \"cl-instruct-stage-0-pythia+160m-sgm\",\n",
    "        \"cl-ocr-stage-1-pythia+160m-sgm-rehearsal1-iorv\",\n",
    "        \"cl-ref-stage-2-pythia+160m-sgm-rehearsal1-iorv\",\n",
    "        \"cl-vqa-stage-3-pythia+160m-sgm-rehearsal1-iorv\"\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [\"Task 2 (VQA)\", \"Task 3 (OCR)\", \"Task 4 (Instruct)\", \"Task 5 (Ref)\"]\n",
    "vl_evaluate_sequence = [[\"vqa-v2\"], [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\", \"refcoco\"]]\n",
    "\n",
    "cl_runs = {\n",
    "    \"naive-ft\": [\n",
    "        \"cl-vqa-stage-0-pythia+160m-voir\",\n",
    "        \"cl-ocr-stage-1-pythia+160m-voir\",\n",
    "        \"cl-instruct-stage-2-pythia+160m-voir\",\n",
    "        \"cl-ref-stage-3-pythia+160m-voir\"\n",
    "    ],\n",
    "    \"sgm-rehearsal1\": [\n",
    "        \"cl-vqa-stage-0-pythia+160m-sgm-voir\",\n",
    "        \"cl-ocr-stage-1-pythia+160m-sgm-rehearsal1-voir\",\n",
    "        \"cl-instruct-stage-2-pythia+160m-sgm-rehearsal1-voir\",\n",
    "        \"cl-ref-stage-3-pythia+160m-sgm-rehearsal1-voir\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cl_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m cl_performance_change \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     31\u001b[0m cl_performance \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, run_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcl_runs\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m     changes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     35\u001b[0m     performances \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cl_runs' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "datasets = [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\", \"refcoco\"]\n",
    "nlu_nlg_datasets = [\"wsc273\", \"winogrande\", \"lambada_standard\", \"arc_easy\", \"arc_challenge\"]\n",
    "\n",
    "\n",
    "# Baseline run_id\n",
    "baseline_run_id = \"reproduction-align-pythia+160m\"\n",
    "\n",
    "# Load the JSON data from the results file\n",
    "with open('results_nlp.json', 'r') as file:\n",
    "    result = json.load(file)\n",
    "\n",
    "# Check for the existence of baseline results\n",
    "baseline_results = result.get(baseline_run_id)\n",
    "if not baseline_results:\n",
    "    raise ValueError(f\"Baseline run ID '{baseline_run_id}' not found in results.\")\n",
    "\n",
    "# Function to replace None values with a small positive value\n",
    "def replace_none_and_zeros(arr, epsilon=EPSILON):\n",
    "    return [epsilon if (x is None or np.isnan(x) or x == 0) else x for x in arr]\n",
    "\n",
    "# Calculate performance changes and averages for each CL run\n",
    "cl_performance_change = {}\n",
    "cl_performance = {}\n",
    "\n",
    "for model_name, run_ids in cl_runs.items():\n",
    "    changes = {}\n",
    "    performances = {}\n",
    "    missing_data = False\n",
    "\n",
    "    for i, run_id in enumerate(run_ids):\n",
    "        current_results = result.get(run_id)\n",
    "        if not current_results:\n",
    "            missing_data = True\n",
    "            print(f\"Run '{run_id}' missing for model '{model_name}'\")\n",
    "            break\n",
    "        \n",
    "        change = {dataset: current_results.get(dataset, np.nan) - baseline_results.get(dataset, np.nan) for dataset in baseline_results.keys()}\n",
    "        changes[f'stage_{i}'] = change\n",
    "        performances[f'stage_{i}'] = current_results\n",
    "        \n",
    "        vl_scores = replace_none_and_zeros([current_results.get(dataset, np.nan) for dataset in vl_evaluate_sequence[i]])\n",
    "        baseline_vl_scores = replace_none_and_zeros([baseline_results.get(dataset, np.nan) for dataset in vl_evaluate_sequence[i]])\n",
    "        avg_delta_vl = hmean(baseline_vl_scores) - hmean(vl_scores)\n",
    "        avg_acc_vl = hmean(vl_scores)\n",
    "        \n",
    "        nl_scores = replace_none_and_zeros([current_results.get(dataset, np.nan) for dataset in nlu_nlg_datasets])\n",
    "        baseline_nl_scores = replace_none_and_zeros([baseline_results.get(dataset, np.nan) for dataset in nlu_nlg_datasets])\n",
    "        avg_delta_nl = hmean(baseline_nl_scores) - hmean(nl_scores)\n",
    "        avg_acc_nl = hmean(nl_scores)\n",
    "        \n",
    "        changes[f'stage_{i}_avg'] = {'VL': avg_delta_vl, 'NL': avg_delta_nl}\n",
    "        performances[f'stage_{i}_avg'] = {'VL': avg_acc_vl, 'NL': avg_acc_nl}\n",
    "        print(f\"Model: {model_name}, Stage: {i}, VL: {avg_acc_vl}, NL: {avg_acc_nl}\")\n",
    "    \n",
    "    if not missing_data:\n",
    "        cl_performance_change[model_name] = changes\n",
    "        cl_performance[model_name] = performances\n",
    "\n",
    "# Save the performance changes and averages to JSON files\n",
    "with open('cl_performance_change.json', 'w') as f:\n",
    "    json.dump(cl_performance_change, f, indent=2)\n",
    "\n",
    "with open('cl_performance.json', 'w') as f:\n",
    "    json.dump(cl_performance, f, indent=2)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "name_mapping = {\n",
    "    'sgm-rehearsal1': 'mSGM + Rehearsal \\((1\\%)\\)',\n",
    "    'naive-ft': 'Original LLaVA'\n",
    "}\n",
    "\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Task-wise Accuracies and Forgetting of Each Mitigation Method across VL and NL tasks}\n",
    "  \\\\label{tab:vl_nl_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cc|cc|cc|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model}\"\"\"\n",
    "\n",
    "# Add multicolumn headers based on stages\n",
    "for stage in stages:\n",
    "    latex_code += \" & \\\\multicolumn{2}{c|}{\\\\textbf{\" + stage + \"}}\"\n",
    "\n",
    "latex_code = latex_code.rstrip('|')  # Remove the trailing '|'\n",
    "latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "# Add subheaders for VL and NL metrics\n",
    "latex_code += \"     & \\\\textbf{VL (A $\\\\uparrow$)} & \\\\textbf{NL ($\\\\Delta \\\\downarrow$)}\" * len(stages)\n",
    "latex_code += \" \\\\\\\\\\n     \\\\midrule\\n\"\n",
    "# Include the Naive-FT benchmark first\n",
    "model_name = 'naive-ft'\n",
    "tasks = cl_performance[model_name]\n",
    "\n",
    "model_results = (\n",
    "    name_mapping[model_name],\n",
    "    tasks['stage_0_avg']['VL'] * 100, cl_performance_change[model_name]['stage_0_avg']['NL'] * 100,\n",
    "    tasks['stage_1_avg']['VL'] * 100, cl_performance_change[model_name]['stage_1_avg']['NL'] * 100,\n",
    "    tasks['stage_2_avg']['VL'] * 100, cl_performance_change[model_name]['stage_2_avg']['NL'] * 100,\n",
    "    tasks['stage_3_avg']['VL'] * 100, cl_performance_change[model_name]['stage_3_avg']['NL'] * 100\n",
    ")\n",
    "\n",
    "latex_code += \"{model} & {t0_vl_a:.2f} & {t0_nl_d:.2f} & {t1_vl_a:.2f} & {t1_nl_d:.2f} & {t2_vl_a:.2f} & {t2_nl_d:.2f} & {t3_vl_a:.2f} & {t3_nl_d:.2f} \\\\\\\\\\n\".format(\n",
    "    model=model_results[0],\n",
    "    t0_vl_a=model_results[1], t0_nl_d=model_results[2],\n",
    "    t1_vl_a=model_results[3], t1_nl_d=model_results[4],\n",
    "    t2_vl_a=model_results[5], t2_nl_d=model_results[6],\n",
    "    t3_vl_a=model_results[7], t3_nl_d=model_results[8]\n",
    ")\n",
    "\n",
    "latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "# Include the rest of the models\n",
    "for model_name, tasks in cl_performance.items():\n",
    "    if model_name not in name_mapping or model_name == 'naive-ft':\n",
    "        continue\n",
    "\n",
    "    model_results = (\n",
    "        name_mapping[model_name],\n",
    "        tasks['stage_0_avg']['VL'] * 100, cl_performance_change[model_name]['stage_0_avg']['NL'] * 100,\n",
    "        tasks['stage_1_avg']['VL'] * 100, cl_performance_change[model_name]['stage_1_avg']['NL'] * 100,\n",
    "        tasks['stage_2_avg']['VL'] * 100, cl_performance_change[model_name]['stage_2_avg']['NL'] * 100,\n",
    "        tasks['stage_3_avg']['VL'] * 100, cl_performance_change[model_name]['stage_3_avg']['NL'] * 100\n",
    "    )\n",
    "    \n",
    "    latex_code += \"{model} & {t0_vl_a:.2f} & {t0_nl_d:.2f} & {t1_vl_a:.2f} & {t1_nl_d:.2f} & {t2_vl_a:.2f} & {t2_nl_d:.2f} & {t3_vl_a:.2f} & {t3_nl_d:.2f} \\\\\\\\\\n\".format(\n",
    "        model=model_results[0],\n",
    "        t0_vl_a=model_results[1], t0_nl_d=model_results[2],\n",
    "        t1_vl_a=model_results[3], t1_nl_d=model_results[4],\n",
    "        t2_vl_a=model_results[5], t2_nl_d=model_results[6],\n",
    "        t3_vl_a=model_results[7], t3_nl_d=model_results[8]\n",
    "    )\n",
    "\n",
    "latex_code += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
