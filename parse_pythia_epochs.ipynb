{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythia410M Epochs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": 0.001,\n",
      "    \"textvqa-ocr\": 0.001953125,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.002,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.6446886446886447,\n",
      "    \"winogrande\": 0.5343330702446725,\n",
      "    \"lambada_standard\": 0.39355715117407336,\n",
      "    \"arc_easy\": 0.5147306397306397,\n",
      "    \"arc_challenge\": 0.20648464163822525\n",
      "  },\n",
      "  \"Naive FT (410M)\": {\n",
      "    \"vqa-v2\": 0.5488000000000001,\n",
      "    \"textvqa-ocr\": 0.24384765625000018,\n",
      "    \"textvqa-pure\": 0.20781250000000018,\n",
      "    \"gqa\": 0.4102,\n",
      "    \"refcoco\": 0.052734375,\n",
      "    \"wsc273\": 0.6043956043956044,\n",
      "    \"winogrande\": 0.5295974743488555,\n",
      "    \"lambada_standard\": 0.3073937512128857,\n",
      "    \"arc_easy\": 0.4978956228956229,\n",
      "    \"arc_challenge\": 0.2295221843003413\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.025699999999999997,\n",
      "    \"textvqa-ocr\": 0.003125,\n",
      "    \"textvqa-pure\": 0.0421875,\n",
      "    \"gqa\": 0.0039000000000000003,\n",
      "    \"refcoco\": 0.0341796875,\n",
      "    \"wsc273\": 0.6190476190476191,\n",
      "    \"winogrande\": 0.5445935280189423,\n",
      "    \"lambada_standard\": 0.2841063458179701,\n",
      "    \"arc_easy\": 0.4810606060606061,\n",
      "    \"arc_challenge\": 0.2354948805460751\n",
      "  },\n",
      "  \"Naive FT (410M, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6029,\n",
      "    \"textvqa-ocr\": 0.25458984375000004,\n",
      "    \"textvqa-pure\": 0.25410156250000016,\n",
      "    \"gqa\": 0.42869999999999997,\n",
      "    \"refcoco\": 0.0302734375,\n",
      "    \"wsc273\": 0.5897435897435898,\n",
      "    \"winogrande\": 0.5035516969218626,\n",
      "    \"lambada_standard\": 0.2679992237531535,\n",
      "    \"arc_easy\": 0.5004208754208754,\n",
      "    \"arc_challenge\": 0.24488054607508533\n",
      "  },\n",
      "  \"Soft Targets (410M)\": {\n",
      "    \"vqa-v2\": 0.4975,\n",
      "    \"textvqa-ocr\": 0.22988281250000006,\n",
      "    \"textvqa-pure\": 0.1310546875,\n",
      "    \"gqa\": 0.3418,\n",
      "    \"refcoco\": 0.052734375,\n",
      "    \"wsc273\": 0.6263736263736264,\n",
      "    \"winogrande\": 0.5335438042620363,\n",
      "    \"lambada_standard\": 0.3353386376867844,\n",
      "    \"arc_easy\": 0.5025252525252525,\n",
      "    \"arc_challenge\": 0.22525597269624573\n",
      "  },\n",
      "  \"Soft Targets (410M, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.5379,\n",
      "    \"textvqa-ocr\": 0.25917968750000014,\n",
      "    \"textvqa-pure\": 0.16738281250000012,\n",
      "    \"gqa\": 0.3945,\n",
      "    \"refcoco\": 0.0537109375,\n",
      "    \"wsc273\": 0.5934065934065934,\n",
      "    \"winogrande\": 0.5398579321231255,\n",
      "    \"lambada_standard\": 0.2938094313991849,\n",
      "    \"arc_easy\": 0.5058922558922558,\n",
      "    \"arc_challenge\": 0.25\n",
      "  },\n",
      "  \"Soft Targets (410M, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.5661,\n",
      "    \"textvqa-ocr\": 0.15341796875,\n",
      "    \"textvqa-pure\": 0.1733398437500001,\n",
      "    \"gqa\": 0.38380000000000003,\n",
      "    \"refcoco\": 0.033203125,\n",
      "    \"wsc273\": 0.6336996336996337,\n",
      "    \"winogrande\": 0.5240726124704025,\n",
      "    \"lambada_standard\": 0.28798758005045605,\n",
      "    \"arc_easy\": 0.4739057239057239,\n",
      "    \"arc_challenge\": 0.24829351535836178\n",
      "  },\n",
      "  \"Corrected OLF LLaVA (410M)\": {\n",
      "    \"vqa-v2\": 0.5396,\n",
      "    \"textvqa-ocr\": 0.21669921875000006,\n",
      "    \"textvqa-pure\": 0.19990234375000013,\n",
      "    \"gqa\": 0.39840000000000003,\n",
      "    \"refcoco\": 0.041015625,\n",
      "    \"wsc273\": 0.6007326007326007,\n",
      "    \"winogrande\": 0.5232833464877664,\n",
      "    \"lambada_standard\": 0.3013778381525325,\n",
      "    \"arc_easy\": 0.49242424242424243,\n",
      "    \"arc_challenge\": 0.22525597269624573\n",
      "  },\n",
      "  \"SGM + Corrected OLF (410M)\": {\n",
      "    \"vqa-v2\": 0.41119999999999995,\n",
      "    \"textvqa-ocr\": 0.14960937499999996,\n",
      "    \"textvqa-pure\": 0.08398437499999997,\n",
      "    \"gqa\": 0.2988,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.63003663003663,\n",
      "    \"winogrande\": 0.5209155485398579,\n",
      "    \"lambada_standard\": 0.3465942169609936,\n",
      "    \"arc_easy\": 0.4793771043771044,\n",
      "    \"arc_challenge\": 0.22098976109215018\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
      "  \\label{tab:lora_variants_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 54.88 & 24.38 & 20.78 & 41.02 & 30.37 & 1.23 & 37.99 \\\\\n",
      "Language Only LLM & 0.10 & 0.20 & 0.00 & 0.20 & 0.00 & - & 39.22 \\\\\n",
      "\\midrule\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 54.88 & 24.38 & 20.78 & 41.02 & 30.37 & 1.23 & 37.99 \\\\\n",
      "Language Only LLM & 0.10 & 0.20 & 0.00 & 0.20 & 0.00 & - & 39.22 \\\\\n",
      "\\midrule\n",
      "Naive FT (410M, +3 Epochs) & 60.29 & 25.46 & 25.41 & 42.87 & 33.74 & 2.17 & 37.05 \\\\\n",
      "Corrected OLF LLaVA (410M) & 53.96 & 21.67 & 19.99 & 39.84 & 28.61 & 1.80 & 37.41 \\\\\n",
      "Soft Targets (410M, +2 Epochs) & 53.79 & 25.92 & 16.74 & 39.45 & 28.12 & 0.51 & 38.71 \\\\\n",
      "Soft Targets (410M, +3 Epochs) & 56.61 & 15.34 & 17.33 & 38.38 & 24.01 & 1.04 & 38.18 \\\\\n",
      "Soft Targets (410M) & 49.75 & 22.99 & 13.11 & 34.18 & 23.65 & 0.40 & 38.81 \\\\\n",
      "SGM + Corrected OLF (410M) & 41.12 & 14.96 & 8.40 & 29.88 & 16.41 & 0.77 & 38.45 \\\\\n",
      "Naive FT (410M, +2 Epochs) & 2.57 & 0.31 & 4.22 & 0.39 & 0.63 & 1.61 & 37.60 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'vicuna' : 'reproduction-align-pythia+410m',\n",
    "    'original' : 'stage-final-llava-v15-pythia+410m',\n",
    "    'original+2epochs': 'stage-final-llava-v15-pythia+410m-epochs-2',\n",
    "    'original+3epochs': 'stage-final-llava-v15-pythia+410m-epochs-3',\n",
    "    'soft': 'stage-final-llava-v15-pythia+410m-soft',\n",
    "    'soft+2epochs': 'stage-final-llava-v15-pythia+410m-soft-epochs-2',\n",
    "    'soft+3epochs': 'stage-final-llava-v15-pythia+410m-soft-epochs-3',\n",
    "    'oolf': 'stage-final-llava-v15-pythia+410m-oolf',\n",
    "    'sgm-oolf': 'stage-final-llava-v15-pythia+410m-sgm-oolf'\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants of LoRA\n",
    "name_mapping = {\n",
    "    'vicuna' : 'Language Only LLM',\n",
    "    'original': 'Naive FT (410M)',\n",
    "    'original+2epochs': 'Naive FT (410M, +2 Epochs)',\n",
    "    'original+3epochs': 'Naive FT (410M, +3 Epochs)',\n",
    "    'soft': 'Soft Targets (410M)',\n",
    "    'soft+2epochs': 'Soft Targets (410M, +2 Epochs)',\n",
    "    'soft+3epochs': 'Soft Targets (410M, +3 Epochs)',\n",
    "    'oolf': 'Corrected OLF LLaVA (410M)',\n",
    "    'sgm-oolf': 'SGM + Corrected OLF (410M)'\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Naive FT (410M)\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Naive FT (410M)\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Separate the data into two groups\n",
    "lora_variants = [\n",
    "    'LoRA (1/4 Full Rank)', 'LoRA (1/4 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank)', 'LoRA (1/2 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank, RSLoRA)', 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)'\n",
    "]\n",
    "\n",
    "lora_table_data = [item for item in table_data if item[0] in lora_variants]\n",
    "other_table_data = [item for item in table_data if item[0] not in lora_variants]\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for LoRA variants\n",
    "latex_code_lora = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
    "  \\\\label{tab:lora_variants_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_lora += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in lora_table_data:\n",
    "    latex_code_lora += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_lora += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "latex_code_other += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in other_table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_lora)\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythia1B Epochs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": 0.044000000000000004,\n",
      "    \"textvqa-ocr\": 0.00615234375,\n",
      "    \"textvqa-pure\": 0.04140625,\n",
      "    \"gqa\": 0.0127,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.673992673992674,\n",
      "    \"winogrande\": 0.5280189423835833,\n",
      "    \"lambada_standard\": 0.4395497768290316,\n",
      "    \"arc_easy\": 0.5845959595959596,\n",
      "    \"arc_challenge\": 0.24488054607508533\n",
      "  },\n",
      "  \"Naive FT (1B)\": {\n",
      "    \"vqa-v2\": 0.6443000000000001,\n",
      "    \"textvqa-ocr\": 0.3836914062500002,\n",
      "    \"textvqa-pure\": 0.3547851562499999,\n",
      "    \"gqa\": 0.45409999999999995,\n",
      "    \"refcoco\": 0.078125,\n",
      "    \"wsc273\": 0.6556776556776557,\n",
      "    \"winogrande\": 0.5351223362273086,\n",
      "    \"lambada_standard\": 0.390064040364836,\n",
      "    \"arc_easy\": 0.5715488215488216,\n",
      "    \"arc_challenge\": 0.27047781569965873\n",
      "  },\n",
      "  \"Naive FT (1B, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.664,\n",
      "    \"textvqa-ocr\": 0.38593750000000027,\n",
      "    \"textvqa-pure\": 0.36591796875000004,\n",
      "    \"gqa\": 0.4805,\n",
      "    \"refcoco\": 0.1220703125,\n",
      "    \"wsc273\": 0.663003663003663,\n",
      "    \"winogrande\": 0.5374901341752171,\n",
      "    \"lambada_standard\": 0.36561226470017466,\n",
      "    \"arc_easy\": 0.5702861952861953,\n",
      "    \"arc_challenge\": 0.2645051194539249\n",
      "  },\n",
      "  \"Naive FT (1B, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6535,\n",
      "    \"textvqa-ocr\": 0.3631835937500002,\n",
      "    \"textvqa-pure\": 0.3677734374999999,\n",
      "    \"gqa\": 0.48340000000000005,\n",
      "    \"refcoco\": 0.1513671875,\n",
      "    \"wsc273\": 0.652014652014652,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.35416262371434115,\n",
      "    \"arc_easy\": 0.569023569023569,\n",
      "    \"arc_challenge\": 0.2738907849829352\n",
      "  },\n",
      "  \"Soft Targets (1B)\": {\n",
      "    \"vqa-v2\": 0.5946,\n",
      "    \"textvqa-ocr\": 0.3458007812500003,\n",
      "    \"textvqa-pure\": 0.3119140625000001,\n",
      "    \"gqa\": 0.39840000000000003,\n",
      "    \"refcoco\": 0.0419921875,\n",
      "    \"wsc273\": 0.6593406593406593,\n",
      "    \"winogrande\": 0.5501183898973955,\n",
      "    \"lambada_standard\": 0.4116048903551329,\n",
      "    \"arc_easy\": 0.5765993265993266,\n",
      "    \"arc_challenge\": 0.26621160409556316\n",
      "  },\n",
      "  \"Soft Targets (1B, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6112,\n",
      "    \"textvqa-ocr\": 0.3769531250000001,\n",
      "    \"textvqa-pure\": 0.33125,\n",
      "    \"gqa\": 0.44920000000000004,\n",
      "    \"refcoco\": 0.0478515625,\n",
      "    \"wsc273\": 0.6703296703296703,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.40520085387153115,\n",
      "    \"arc_easy\": 0.5580808080808081,\n",
      "    \"arc_challenge\": 0.2841296928327645\n",
      "  },\n",
      "  \"Soft Targets (1B, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6182,\n",
      "    \"textvqa-ocr\": 0.3604492187500001,\n",
      "    \"textvqa-pure\": 0.32197265625,\n",
      "    \"gqa\": 0.4355,\n",
      "    \"refcoco\": 0.1005859375,\n",
      "    \"wsc273\": 0.6483516483516484,\n",
      "    \"winogrande\": 0.531965272296764,\n",
      "    \"lambada_standard\": 0.3700756840675335,\n",
      "    \"arc_easy\": 0.5509259259259259,\n",
      "    \"arc_challenge\": 0.2713310580204778\n",
      "  },\n",
      "  \"SGM + Corrected OLF (1B)\": {\n",
      "    \"vqa-v2\": 0.5354,\n",
      "    \"textvqa-ocr\": 0.3369140625000001,\n",
      "    \"textvqa-pure\": 0.28193359375000016,\n",
      "    \"gqa\": 0.374,\n",
      "    \"refcoco\": 0.0556640625,\n",
      "    \"wsc273\": 0.6813186813186813,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.44905880069862214,\n",
      "    \"arc_easy\": 0.569023569023569,\n",
      "    \"arc_challenge\": 0.26621160409556316\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
      "  \\label{tab:lora_variants_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 64.43 & 38.37 & 35.48 & 45.41 & 43.58 & -0.16 & 43.84 \\\\\n",
      "Language Only LLM & 4.40 & 0.62 & 4.14 & 1.27 & 1.39 & - & 43.68 \\\\\n",
      "\\midrule\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 64.43 & 38.37 & 35.48 & 45.41 & 43.58 & -0.16 & 43.84 \\\\\n",
      "Language Only LLM & 4.40 & 0.62 & 4.14 & 1.27 & 1.39 & - & 43.68 \\\\\n",
      "\\midrule\n",
      "Naive FT (1B, +2 Epochs) & 66.40 & 38.59 & 36.59 & 48.05 & 44.89 & 0.72 & 42.96 \\\\\n",
      "Naive FT (1B, +3 Epochs) & 65.35 & 36.32 & 36.78 & 48.34 & 44.09 & 0.62 & 43.06 \\\\\n",
      "Soft Targets (1B, +2 Epochs) & 61.12 & 37.70 & 33.12 & 44.92 & 41.96 & -1.29 & 44.97 \\\\\n",
      "Soft Targets (1B, +3 Epochs) & 61.82 & 36.04 & 32.20 & 43.55 & 40.84 & 0.67 & 43.01 \\\\\n",
      "Soft Targets (1B) & 59.46 & 34.58 & 31.19 & 39.84 & 38.87 & -0.75 & 44.43 \\\\\n",
      "SGM + Corrected OLF (1B) & 53.54 & 33.69 & 28.19 & 37.40 & 36.18 & -1.55 & 45.23 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'vicuna' : 'reproduction-align-pythia+1b',\n",
    "    'original' : 'stage-final-llava-v15-pythia+1b',\n",
    "    'original+2epochs': 'stage-final-llava-v15-pythia+1b-epochs-2',\n",
    "    'original+3epochs': 'stage-final-llava-v15-pythia+1b-epochs-3',\n",
    "    'soft': 'stage-final-llava-v15-pythia+1b-soft',\n",
    "    'soft+2epochs': 'stage-final-llava-v15-pythia+1b-soft-epochs-2',\n",
    "    'soft+3epochs': 'stage-final-llava-v15-pythia+1b-soft-epochs-3',\n",
    "    'sgm+oolf': 'stage-final-llava-v15-pythia+1b-sgm-oolf'\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants of LoRA\n",
    "name_mapping = {\n",
    "    'vicuna' : 'Language Only LLM',\n",
    "    'original': 'Naive FT (1B)',\n",
    "    'original+2epochs': 'Naive FT (1B, +2 Epochs)',\n",
    "    'original+3epochs': 'Naive FT (1B, +3 Epochs)',\n",
    "    'soft': 'Soft Targets (1B)',\n",
    "    'soft+2epochs': 'Soft Targets (1B, +2 Epochs)',\n",
    "    'soft+3epochs': 'Soft Targets (1B, +3 Epochs)',\n",
    "    'sgm+oolf': 'SGM + Corrected OLF (1B)'\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Naive FT (1B)\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Naive FT (1B)\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Separate the data into two groups\n",
    "lora_variants = [\n",
    "    'LoRA (1/4 Full Rank)', 'LoRA (1/4 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank)', 'LoRA (1/2 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank, RSLoRA)', 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)'\n",
    "]\n",
    "\n",
    "lora_table_data = [item for item in table_data if item[0] in lora_variants]\n",
    "other_table_data = [item for item in table_data if item[0] not in lora_variants]\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for LoRA variants\n",
    "latex_code_lora = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
    "  \\\\label{tab:lora_variants_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_lora += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in lora_table_data:\n",
    "    latex_code_lora += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_lora += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "latex_code_other += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in other_table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_lora)\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
