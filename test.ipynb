{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "hf_token = None\n",
    "model_path = \"/localdisk/ssrivas9/prismatic-vlms/runs/lora-stage-0-after-llava-vqav2/checkpoints/latest-checkpoint.pt\"\n",
    "llm_config = AutoConfig.from_pretrained(\"lmsys/vicuna-7b-v1.5\", token=hf_token)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"lmsys/vicuna-7b-v1.5\",\n",
    "        config=llm_config,  # Pass the modified configuration\n",
    "        token=hf_token,\n",
    "    )\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PrefixTuningConfig, #Prefix-Tuning\n",
    "    PromptEncoderConfig, #P-Tuning\n",
    "    PromptTuningConfig, # Prompt Tuning\n",
    "    IA3Config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_kbit_training,\n",
    "    set_peft_model_state_dict,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "lora_r=4\n",
    "lora_target_modules=[\"q_proj\", \"v_proj\"]\n",
    "lora_alpha=16\n",
    "lora_dropout=0.05\n",
    "# Add PEFT LoRA on top of this.\n",
    "llm_model = prepare_model_for_kbit_training(llm_model)\n",
    "loraconfig = LoraConfig(\n",
    "    r=lora_r, lora_alpha=lora_alpha, target_modules=lora_target_modules,\n",
    "    lora_dropout=lora_dropout, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "llm_model = get_peft_model(llm_model, loraconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"lmsys/vicuna-7b-v1.5\", model_max_length=2048, token=hf_token)\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32064, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "llm_model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['llm.base_model.model.model.embed_tokens.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.weight', 'llm.base_model.model.model.layers.0.input_layernorm.weight', 'llm.base_model.model.model.layers.0.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.1.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.weight', 'llm.base_model.model.model.layers.1.input_layernorm.weight', 'llm.base_model.model.model.layers.1.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.weight', 'llm.base_model.model.model.layers.2.input_layernorm.weight', 'llm.base_model.model.model.layers.2.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.weight', 'llm.base_model.model.model.layers.3.input_layernorm.weight', 'llm.base_model.model.model.layers.3.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.weight', 'llm.base_model.model.model.layers.4.input_layernorm.weight', 'llm.base_model.model.model.layers.4.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.5.mlp.up_proj.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.weight', 'llm.base_model.model.model.layers.5.input_layernorm.weight', 'llm.base_model.model.model.layers.5.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.weight', 'llm.base_model.model.model.layers.6.input_layernorm.weight', 'llm.base_model.model.model.layers.6.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.weight', 'llm.base_model.model.model.layers.7.input_layernorm.weight', 'llm.base_model.model.model.layers.7.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.weight', 'llm.base_model.model.model.layers.8.input_layernorm.weight', 'llm.base_model.model.model.layers.8.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.weight', 'llm.base_model.model.model.layers.9.input_layernorm.weight', 'llm.base_model.model.model.layers.9.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.weight', 'llm.base_model.model.model.layers.10.input_layernorm.weight', 'llm.base_model.model.model.layers.10.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.weight', 'llm.base_model.model.model.layers.11.input_layernorm.weight', 'llm.base_model.model.model.layers.11.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.12.mlp.up_proj.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.weight', 'llm.base_model.model.model.layers.12.input_layernorm.weight', 'llm.base_model.model.model.layers.12.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.13.mlp.up_proj.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.weight', 'llm.base_model.model.model.layers.13.input_layernorm.weight', 'llm.base_model.model.model.layers.13.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.weight', 'llm.base_model.model.model.layers.14.input_layernorm.weight', 'llm.base_model.model.model.layers.14.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.weight', 'llm.base_model.model.model.layers.15.input_layernorm.weight', 'llm.base_model.model.model.layers.15.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.16.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.16.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.16.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.16.mlp.up_proj.weight', 'llm.base_model.model.model.layers.16.mlp.down_proj.weight', 'llm.base_model.model.model.layers.16.input_layernorm.weight', 'llm.base_model.model.model.layers.16.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.17.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.17.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.17.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.17.mlp.up_proj.weight', 'llm.base_model.model.model.layers.17.mlp.down_proj.weight', 'llm.base_model.model.model.layers.17.input_layernorm.weight', 'llm.base_model.model.model.layers.17.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.18.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.18.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.18.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.18.mlp.up_proj.weight', 'llm.base_model.model.model.layers.18.mlp.down_proj.weight', 'llm.base_model.model.model.layers.18.input_layernorm.weight', 'llm.base_model.model.model.layers.18.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.19.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.19.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.19.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.19.mlp.up_proj.weight', 'llm.base_model.model.model.layers.19.mlp.down_proj.weight', 'llm.base_model.model.model.layers.19.input_layernorm.weight', 'llm.base_model.model.model.layers.19.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.20.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.20.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.20.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.20.mlp.up_proj.weight', 'llm.base_model.model.model.layers.20.mlp.down_proj.weight', 'llm.base_model.model.model.layers.20.input_layernorm.weight', 'llm.base_model.model.model.layers.20.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.21.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.21.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.21.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.21.mlp.up_proj.weight', 'llm.base_model.model.model.layers.21.mlp.down_proj.weight', 'llm.base_model.model.model.layers.21.input_layernorm.weight', 'llm.base_model.model.model.layers.21.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.22.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.22.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.22.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.22.mlp.up_proj.weight', 'llm.base_model.model.model.layers.22.mlp.down_proj.weight', 'llm.base_model.model.model.layers.22.input_layernorm.weight', 'llm.base_model.model.model.layers.22.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.23.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.23.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.23.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.23.mlp.up_proj.weight', 'llm.base_model.model.model.layers.23.mlp.down_proj.weight', 'llm.base_model.model.model.layers.23.input_layernorm.weight', 'llm.base_model.model.model.layers.23.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.24.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.24.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.24.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.24.mlp.up_proj.weight', 'llm.base_model.model.model.layers.24.mlp.down_proj.weight', 'llm.base_model.model.model.layers.24.input_layernorm.weight', 'llm.base_model.model.model.layers.24.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.25.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.25.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.25.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.25.mlp.up_proj.weight', 'llm.base_model.model.model.layers.25.mlp.down_proj.weight', 'llm.base_model.model.model.layers.25.input_layernorm.weight', 'llm.base_model.model.model.layers.25.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.26.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.26.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.26.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.26.mlp.up_proj.weight', 'llm.base_model.model.model.layers.26.mlp.down_proj.weight', 'llm.base_model.model.model.layers.26.input_layernorm.weight', 'llm.base_model.model.model.layers.26.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.27.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.27.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.27.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.27.mlp.up_proj.weight', 'llm.base_model.model.model.layers.27.mlp.down_proj.weight', 'llm.base_model.model.model.layers.27.input_layernorm.weight', 'llm.base_model.model.model.layers.27.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.28.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.28.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.28.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.28.mlp.up_proj.weight', 'llm.base_model.model.model.layers.28.mlp.down_proj.weight', 'llm.base_model.model.model.layers.28.input_layernorm.weight', 'llm.base_model.model.model.layers.28.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.29.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.29.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.29.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.29.mlp.up_proj.weight', 'llm.base_model.model.model.layers.29.mlp.down_proj.weight', 'llm.base_model.model.model.layers.29.input_layernorm.weight', 'llm.base_model.model.model.layers.29.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.30.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.30.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.30.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.30.mlp.up_proj.weight', 'llm.base_model.model.model.layers.30.mlp.down_proj.weight', 'llm.base_model.model.model.layers.30.input_layernorm.weight', 'llm.base_model.model.model.layers.30.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.31.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.31.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.31.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.31.mlp.up_proj.weight', 'llm.base_model.model.model.layers.31.mlp.down_proj.weight', 'llm.base_model.model.model.layers.31.input_layernorm.weight', 'llm.base_model.model.model.layers.31.post_attention_layernorm.weight', 'llm.base_model.model.model.norm.weight', 'llm.base_model.model.lm_head.weight'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights from model_path\n",
    "import torch\n",
    "state_dicts = (torch.load(model_path))\n",
    "print(state_dicts.keys())\n",
    "state_dicts['model']['llm_backbone'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['projector', 'llm_backbone'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dicts['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model has the llm prefix in the state dict keys and adjust them if necessary\n",
    "if any(key.startswith('llm.') for key in state_dicts['model']['llm_backbone'].keys()):\n",
    "    adjusted_state_dict = {key.replace('llm.', ''): value for key, value in state_dicts['model']['llm_backbone'].items()}\n",
    "else:\n",
    "    adjusted_state_dict = state_dicts['model']['llm_backbone']\n",
    "    # Load the adjusted state dict into the model\n",
    "    llm_model.load_state_dict(adjusted_state_dict)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32064, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_layer',\n",
       " 'lm_head',\n",
       " 'k_proj',\n",
       " 'up_proj',\n",
       " 'o_proj',\n",
       " 'default',\n",
       " 'down_proj',\n",
       " 'gate_proj']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LlamaForCausalLM:\n\tsize mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([32064, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([32064, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModelForCausalLM\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/localdisk/ssrivas9/prismatic-vlms/runs/lora-stage-0-after-llava-vqav2-lora-rank-32/checkpoint_llm_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#model = PeftModelForCausalLM.from_pretrained(model = llm, model_id=\"/localdisk/ssrivas9/prismatic-vlms/runs/qlora-stage-0-after-llava-vqav2/checkpoint_llm_only\")\u001b[39;00m\n",
      "File \u001b[0;32m/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/modeling_utils.py:3742\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3739\u001b[0m     model\u001b[38;5;241m.\u001b[39mhf_quantizer \u001b[38;5;241m=\u001b[39m hf_quantizer\n\u001b[1;32m   3741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _adapter_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3742\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_adapter_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3744\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3746\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_loading_info:\n\u001b[1;32m   3750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loading_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/integrations/peft.py:206\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, adapter_kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     processed_adapter_state_dict[new_key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Load state dict\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m \u001b[43mset_peft_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_adapter_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incompatible_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# check only for unexpected keys\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(incompatible_keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(incompatible_keys\u001b[38;5;241m.\u001b[39munexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/peft/utils/save_and_load.py:353\u001b[0m, in \u001b[0;36mset_peft_model_state_dict\u001b[0;34m(model, peft_model_state_dict, adapter_name, ignore_mismatched_sizes)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    350\u001b[0m peft_model_state_dict, mismatched_keys \u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m    351\u001b[0m     model, peft_model_state_dict, ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes\n\u001b[1;32m    352\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m load_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    355\u001b[0m     model\u001b[38;5;241m.\u001b[39mprompt_encoder[adapter_name]\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m    356\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m: peft_model_state_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]}, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LlamaForCausalLM:\n\tsize mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([32064, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([32064, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096])."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoModel\n",
    "from peft import PeftModelForCausalLM\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"/localdisk/ssrivas9/prismatic-vlms/runs/lora-stage-0-after-llava-vqav2-lora-rank-32/checkpoint_llm_only\")\n",
    "#model = PeftModelForCausalLM.from_pretrained(model = llm, model_id=\"/localdisk/ssrivas9/prismatic-vlms/runs/qlora-stage-0-after-llava-vqav2/checkpoint_llm_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "from_pretrained() missing 1 required positional argument: 'model_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(peft_dir)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the adapter model (PEFT model)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m adapter_model \u001b[38;5;241m=\u001b[39m \u001b[43mPeftModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Inspect the weights\u001b[39;00m\n\u001b[1;32m     14\u001b[0m adapter_weights \u001b[38;5;241m=\u001b[39m adapter_model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "\u001b[0;31mTypeError\u001b[0m: from_pretrained() missing 1 required positional argument: 'model_id'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Define the path to the directory where the adapter weights are saved\n",
    "peft_dir = \"/localdisk/ssrivas9/prismatic-vlms/runs/qlora-stage-0-after-llava-vqav2/checkpoint_llm_only\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_dir)\n",
    "\n",
    "# Load the adapter model (PEFT model)\n",
    "adapter_model = PeftModel.from_pretrained(peft_dir)\n",
    "\n",
    "# Inspect the weights\n",
    "adapter_weights = adapter_model.state_dict()\n",
    "\n",
    "# Print the keys of the adapter weights to see what is stored\n",
    "print(\"Adapter Weights Keys:\")\n",
    "for key in adapter_weights.keys():\n",
    "    print(key)\n",
    "\n",
    "# If you want to inspect specific weights\n",
    "print(\"\\nSample Weights:\")\n",
    "for key in adapter_weights.keys():\n",
    "    print(f\"{key}: {adapter_weights[key].shape}\")\n",
    "    break  # remove this line to print all weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/localdisk/ssrivas9/miniconda3/envs/prism/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Loading adapter weights from /localdisk/ssrivas9/prismatic-vlms/runs/qlora-stage-0-after-llava-vqav2/checkpoint_llm_only led to unexpected keys not found in the model:  ['llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.embed_tokens.weight', 'llm.base_model.model.lm_head.weight']. \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Loaded model is not an instance of supported PEFT model classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mfrom_pretrained(peft_dir, safe_serialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model is not an instance of supported PEFT model classes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Loaded model is not an instance of supported PEFT model classes."
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftModelForCausalLM\n",
    "\n",
    "# Define the path to the directory where the model and tokenizer are saved\n",
    "peft_dir = Path(\"/localdisk/ssrivas9/prismatic-vlms/runs/qlora-stage-0-after-llava-vqav2/checkpoint_llm_only\")\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(peft_dir)\n",
    "\n",
    "# # Load the model\n",
    "# model_config = AutoModelForCausalLM.from_pretrained(peft_dir)\n",
    "# if isinstance(model_config, PeftModel) or isinstance(model_config, PeftModelForCausalLM):\n",
    "#     model = model_config.from_pretrained(peft_dir, safe_serialization=False)\n",
    "# else:\n",
    "#     raise TypeError(\"Loaded model is not an instance of supported PEFT model classes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Script to load a PeftModel from a given path\n",
    "from peft import load_peft_model\n",
    "model_dir = ''\n",
    "model = load_peft_model(model_dir)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the path to the adapter model file\n",
    "adapter_model_path = \"/localdisk/ssrivas9/prismatic-vlms/runs/qlora-stage-0-after-llava-vqav2/checkpoint_llm_only/adapter_model.bin\"\n",
    "\n",
    "# Load the state dictionary from the adapter model file\n",
    "adapter_state_dict = torch.load(adapter_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.16.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.16.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.17.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.17.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.18.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.18.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.19.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.19.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.20.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.20.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.21.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.21.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.22.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.22.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.23.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.23.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.24.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.24.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.25.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.25.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.26.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.26.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.27.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.27.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.28.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.28.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.29.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.29.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.30.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.30.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight', 'llm.base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight', 'llm.base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight', 'llm.base_model.model.model.layers.31.mlp.down_proj.lora_A.weight', 'llm.base_model.model.model.layers.31.mlp.down_proj.lora_B.weight', 'llm.base_model.model.model.embed_tokens.weight', 'llm.base_model.model.lm_head.weight'])\n"
     ]
    }
   ],
   "source": [
    "print(adapter_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('llm.base_model.model.model.embed_tokens.weight',\n",
       "              tensor([[ 1.2517e-06, -1.7881e-06, -4.3511e-06,  ...,  8.9407e-07,\n",
       "                       -6.5565e-06,  8.9407e-07],\n",
       "                      [ 2.6588e-03, -4.0588e-03,  2.1038e-03,  ..., -9.7656e-03,\n",
       "                        3.4580e-03, -4.0665e-03],\n",
       "                      [ 1.0414e-02,  8.3237e-03, -5.6038e-03,  ...,  2.6588e-03,\n",
       "                       -1.3170e-03, -3.6335e-03],\n",
       "                      ...,\n",
       "                      [-9.7424e-03, -4.0932e-02,  1.7835e-03,  ...,  3.2697e-03,\n",
       "                        2.4879e-03, -4.2195e-03],\n",
       "                      [-9.8943e-04, -2.1665e-03,  1.9245e-03,  ...,  9.9978e-03,\n",
       "                       -1.1535e-02,  2.9351e-02],\n",
       "                      [ 6.5397e-03,  4.3520e-02, -5.6831e-04,  ...,  2.1207e-02,\n",
       "                       -1.0226e-02, -3.4046e-02]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0060, -0.0149, -0.0024,  ...,  0.0038,  0.0026, -0.0029],\n",
       "                      [ 0.0156, -0.0045,  0.0026,  ..., -0.0098, -0.0115,  0.0074],\n",
       "                      [-0.0152,  0.0132,  0.0009,  ...,  0.0068,  0.0188, -0.0038],\n",
       "                      ...,\n",
       "                      [ 0.0003,  0.0097, -0.0003,  ...,  0.0090, -0.0300,  0.0102],\n",
       "                      [ 0.0255,  0.0103,  0.0034,  ..., -0.0328, -0.0151, -0.0126],\n",
       "                      [-0.0127, -0.0055,  0.0015,  ...,  0.0179,  0.0160, -0.0086]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0072,  0.0065,  0.0092,  ...,  0.0008, -0.0125,  0.0105],\n",
       "                      [ 0.0007, -0.0007,  0.0119,  ..., -0.0149,  0.0072, -0.0050],\n",
       "                      [-0.0005, -0.0043,  0.0050,  ...,  0.0064, -0.0042,  0.0051],\n",
       "                      [ 0.0073, -0.0088,  0.0163,  ...,  0.0060, -0.0119, -0.0065]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.9462e-04, -7.0272e-04, -1.8805e-05, -3.0913e-04],\n",
       "                      [ 2.7841e-05,  2.7206e-04, -8.3523e-04, -2.2362e-04],\n",
       "                      [ 5.6128e-04,  3.0253e-04,  3.8068e-04,  3.3662e-04],\n",
       "                      ...,\n",
       "                      [ 1.3395e-04,  5.4514e-05, -6.1178e-04,  4.3588e-04],\n",
       "                      [ 7.6873e-04,  4.0186e-04,  4.5570e-04, -3.1822e-04],\n",
       "                      [-6.9490e-04, -3.5407e-04, -4.3600e-04,  3.0572e-04]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0150,  0.0084, -0.0015,  ...,  0.0167, -0.0095, -0.0148],\n",
       "                      [ 0.0200, -0.0001,  0.0044,  ..., -0.0216,  0.0156,  0.0242],\n",
       "                      [-0.0242, -0.0212,  0.0014,  ...,  0.0148, -0.0164, -0.0126],\n",
       "                      ...,\n",
       "                      [ 0.0126, -0.0010, -0.0010,  ...,  0.0001,  0.0043,  0.0070],\n",
       "                      [-0.0060,  0.0175, -0.0029,  ..., -0.0028,  0.0100, -0.0097],\n",
       "                      [ 0.0037, -0.0023,  0.0010,  ...,  0.0065, -0.0102,  0.0083]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 1.4601e-03, -2.3842e-06,  3.7861e-03,  ...,  6.5498e-03,\n",
       "                        4.2844e-04,  1.0239e-02],\n",
       "                      [-6.7177e-03, -1.1024e-03, -7.6866e-03,  ..., -1.0803e-02,\n",
       "                        1.2665e-02,  3.5057e-03],\n",
       "                      [ 1.5678e-03,  8.6212e-03,  6.5231e-04,  ...,  3.6640e-03,\n",
       "                       -1.2535e-02, -1.4343e-02],\n",
       "                      ...,\n",
       "                      [-5.7106e-03, -6.3286e-03,  1.0567e-02,  ...,  2.9812e-03,\n",
       "                        3.1586e-03, -3.5667e-03],\n",
       "                      [ 3.3875e-03,  4.1847e-03, -1.5059e-03,  ...,  3.8090e-03,\n",
       "                        1.5457e-02,  8.7261e-04],\n",
       "                      [-1.7567e-03,  1.0891e-03,  4.0512e-03,  ..., -2.2964e-03,\n",
       "                       -2.1541e-04,  6.5708e-04]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0087,  0.0080, -0.0004,  ..., -0.0005, -0.0079,  0.0073],\n",
       "                      [-0.0147,  0.0092,  0.0093,  ...,  0.0127,  0.0078,  0.0135],\n",
       "                      [-0.0030,  0.0066, -0.0149,  ..., -0.0147,  0.0072,  0.0088],\n",
       "                      [-0.0006,  0.0045, -0.0133,  ...,  0.0117,  0.0114,  0.0127]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0013,  0.0007,  0.0006,  0.0010],\n",
       "                      [ 0.0012, -0.0012, -0.0008, -0.0013],\n",
       "                      [-0.0002,  0.0001,  0.0003,  0.0002],\n",
       "                      ...,\n",
       "                      [-0.0005,  0.0005,  0.0005,  0.0005],\n",
       "                      [-0.0003,  0.0002,  0.0003,  0.0004],\n",
       "                      [ 0.0006, -0.0005, -0.0005, -0.0006]])),\n",
       "             ('llm.base_model.model.model.layers.0.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0006, -0.0017,  0.0050,  ...,  0.0053,  0.0052, -0.0094],\n",
       "                      [ 0.0036,  0.0013, -0.0009,  ..., -0.0013,  0.0025,  0.0077],\n",
       "                      [ 0.0028, -0.0015,  0.0010,  ..., -0.0024, -0.0053, -0.0016],\n",
       "                      ...,\n",
       "                      [ 0.0043, -0.0031,  0.0056,  ..., -0.0001,  0.0014,  0.0053],\n",
       "                      [-0.0041, -0.0023, -0.0031,  ...,  0.0072, -0.0036, -0.0022],\n",
       "                      [ 0.0068, -0.0006,  0.0038,  ...,  0.0055, -0.0070, -0.0073]])),\n",
       "             ('llm.base_model.model.model.layers.0.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0146,  0.0164,  0.0321,  ..., -0.0164,  0.0076,  0.0167],\n",
       "                      [-0.0017, -0.0054,  0.0060,  ...,  0.0159, -0.0102,  0.0090],\n",
       "                      [ 0.0052, -0.0225,  0.0200,  ..., -0.0124,  0.0208,  0.0194],\n",
       "                      ...,\n",
       "                      [-0.0010, -0.0326,  0.0059,  ..., -0.0086, -0.0126,  0.0406],\n",
       "                      [ 0.0268,  0.0201, -0.0179,  ..., -0.0052, -0.0053, -0.0189],\n",
       "                      [-0.0005, -0.0121, -0.0255,  ...,  0.0025,  0.0062, -0.0244]])),\n",
       "             ('llm.base_model.model.model.layers.0.mlp.up_proj.weight',\n",
       "              tensor([[-0.0010, -0.0283,  0.0141,  ..., -0.0222, -0.0290,  0.0073],\n",
       "                      [-0.0119, -0.0320,  0.0118,  ...,  0.0202,  0.0065,  0.0020],\n",
       "                      [-0.0069,  0.0151, -0.0094,  ..., -0.0220,  0.0085,  0.0028],\n",
       "                      ...,\n",
       "                      [-0.0089, -0.0022, -0.0055,  ...,  0.0296, -0.0022,  0.0195],\n",
       "                      [-0.0177,  0.0079,  0.0199,  ...,  0.0004, -0.0164,  0.0031],\n",
       "                      [ 0.0189,  0.0207, -0.0019,  ...,  0.0134, -0.0136, -0.0378]])),\n",
       "             ('llm.base_model.model.model.layers.0.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0012, -0.0147,  0.0083,  ..., -0.0184, -0.0059, -0.0003],\n",
       "                      [ 0.0039, -0.0038,  0.0081,  ...,  0.0157, -0.0147,  0.0338],\n",
       "                      [ 0.0020,  0.0350, -0.0047,  ..., -0.0142,  0.0212,  0.0166],\n",
       "                      ...,\n",
       "                      [-0.0087, -0.0120,  0.0044,  ...,  0.0234, -0.0134,  0.0299],\n",
       "                      [-0.0175,  0.0381,  0.0106,  ..., -0.0061, -0.0131, -0.0210],\n",
       "                      [ 0.0110, -0.0008, -0.0064,  ...,  0.0006, -0.0038, -0.0299]])),\n",
       "             ('llm.base_model.model.model.layers.0.input_layernorm.weight',\n",
       "              tensor([0.0287, 0.0115, 0.0028,  ..., 0.0119, 0.0113, 0.0068])),\n",
       "             ('llm.base_model.model.model.layers.0.post_attention_layernorm.weight',\n",
       "              tensor([0.0507, 0.0533, 0.0509,  ..., 0.0514, 0.0542, 0.0487])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-1.1368e-02,  6.3553e-03, -3.6591e-02,  ..., -4.2648e-03,\n",
       "                       -5.7983e-02,  3.4515e-02],\n",
       "                      [-4.3249e-04, -6.9580e-03,  6.7291e-03,  ..., -7.2823e-03,\n",
       "                       -4.8828e-02,  2.8778e-02],\n",
       "                      [ 2.9541e-02,  3.2104e-02,  2.3438e-02,  ..., -5.7268e-04,\n",
       "                       -7.3303e-02,  2.2247e-02],\n",
       "                      ...,\n",
       "                      [-3.3140e-04,  2.0981e-03,  3.0785e-03,  ..., -8.6517e-03,\n",
       "                       -4.0169e-03, -5.9853e-03],\n",
       "                      [-1.9321e-03, -4.0741e-03, -3.6602e-03,  ...,  8.7509e-03,\n",
       "                        5.2986e-03,  6.0883e-03],\n",
       "                      [ 1.9431e-05,  5.0087e-03,  6.1531e-03,  ..., -7.6981e-03,\n",
       "                       -6.8378e-04, -1.1177e-02]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0046,  0.0125, -0.0075,  ...,  0.0066, -0.0043, -0.0138],\n",
       "                      [ 0.0054,  0.0122, -0.0064,  ..., -0.0043,  0.0004,  0.0074],\n",
       "                      [-0.0151, -0.0155,  0.0128,  ...,  0.0032, -0.0044,  0.0163],\n",
       "                      [-0.0002,  0.0118, -0.0132,  ...,  0.0037,  0.0114,  0.0166]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-4.2690e-04, -4.4585e-04, -4.2815e-04, -3.6478e-04],\n",
       "                      [ 5.8315e-04,  6.5262e-04,  6.1850e-04,  6.0436e-04],\n",
       "                      [-6.4701e-04, -7.7380e-04, -6.3195e-04, -3.4996e-04],\n",
       "                      ...,\n",
       "                      [-8.7705e-05,  4.4738e-05,  1.1399e-05, -3.1568e-05],\n",
       "                      [ 8.8554e-05, -4.6209e-05, -1.2131e-05,  2.4537e-05],\n",
       "                      [-8.6049e-05,  6.4975e-05,  1.9614e-05, -4.0284e-05]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0245, -0.0027,  0.0382,  ...,  0.0189,  0.0192, -0.0105],\n",
       "                      [-0.0306,  0.0053, -0.0100,  ..., -0.0141,  0.0091, -0.0590],\n",
       "                      [-0.0250,  0.0302, -0.0654,  ...,  0.0360,  0.0074, -0.0568],\n",
       "                      ...,\n",
       "                      [-0.0108,  0.0182, -0.0010,  ...,  0.0101, -0.0005,  0.0075],\n",
       "                      [ 0.0077, -0.0184,  0.0035,  ..., -0.0114, -0.0010, -0.0073],\n",
       "                      [-0.0077,  0.0139,  0.0012,  ...,  0.0033, -0.0021,  0.0068]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0079, -0.0070, -0.0042,  ..., -0.0065, -0.0334, -0.0262],\n",
       "                      [-0.0034,  0.0033, -0.0027,  ...,  0.0003,  0.0100,  0.0306],\n",
       "                      [ 0.0068, -0.0130,  0.0112,  ...,  0.0011, -0.0002, -0.0001],\n",
       "                      ...,\n",
       "                      [-0.0042,  0.0032,  0.0058,  ..., -0.0009,  0.0002,  0.0013],\n",
       "                      [-0.0067, -0.0050,  0.0093,  ..., -0.0069,  0.0031, -0.0004],\n",
       "                      [-0.0017,  0.0017,  0.0036,  ...,  0.0019, -0.0067,  0.0068]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0056,  0.0056, -0.0025,  ...,  0.0031, -0.0009,  0.0031],\n",
       "                      [-0.0040, -0.0097,  0.0095,  ...,  0.0154,  0.0133, -0.0067],\n",
       "                      [-0.0002,  0.0007,  0.0030,  ..., -0.0062,  0.0036,  0.0162],\n",
       "                      [ 0.0128,  0.0071,  0.0002,  ...,  0.0138,  0.0165, -0.0080]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-9.6498e-04, -4.5069e-04, -1.0123e-03,  8.5732e-04],\n",
       "                      [ 1.4502e-03,  7.8806e-04,  1.4167e-03, -1.2084e-03],\n",
       "                      [-3.9701e-04,  3.5587e-04,  1.4046e-04,  4.0681e-04],\n",
       "                      ...,\n",
       "                      [-2.7127e-04, -4.9632e-04, -2.8973e-04,  6.6816e-05],\n",
       "                      [-7.1503e-04, -1.2174e-03, -8.8389e-04,  4.0186e-04],\n",
       "                      [ 2.5520e-04,  2.1646e-04,  2.6701e-04, -2.6293e-04]])),\n",
       "             ('llm.base_model.model.model.layers.1.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0042, -0.0190,  0.0147,  ..., -0.0060, -0.0011,  0.0003],\n",
       "                      [-0.0009, -0.0065, -0.0129,  ..., -0.0011, -0.0031,  0.0034],\n",
       "                      [ 0.0235,  0.0138, -0.0106,  ...,  0.0034,  0.0011, -0.0032],\n",
       "                      ...,\n",
       "                      [ 0.0032,  0.0053,  0.0045,  ...,  0.0004,  0.0028, -0.0013],\n",
       "                      [ 0.0027, -0.0131,  0.0068,  ..., -0.0023,  0.0007,  0.0024],\n",
       "                      [-0.0051, -0.0203,  0.0070,  ...,  0.0018, -0.0043,  0.0023]])),\n",
       "             ('llm.base_model.model.model.layers.1.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0293, -0.0103,  0.0394,  ..., -0.0348, -0.0197, -0.0108],\n",
       "                      [-0.0285, -0.0011, -0.0303,  ...,  0.0150, -0.0221, -0.0418],\n",
       "                      [-0.0071, -0.0298,  0.0037,  ..., -0.0094, -0.0144, -0.0198],\n",
       "                      ...,\n",
       "                      [-0.0403,  0.0177, -0.0047,  ..., -0.0019,  0.0144, -0.0013],\n",
       "                      [-0.0162,  0.0052, -0.0372,  ...,  0.0209,  0.0195, -0.0131],\n",
       "                      [-0.0250,  0.0154,  0.0060,  ...,  0.0361,  0.0102, -0.0359]])),\n",
       "             ('llm.base_model.model.model.layers.1.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0015,  0.0339, -0.0169,  ...,  0.0101,  0.0309, -0.0184],\n",
       "                      [ 0.0097, -0.0043, -0.0150,  ..., -0.0066,  0.0106,  0.0081],\n",
       "                      [ 0.0271, -0.0443,  0.0138,  ...,  0.0151, -0.0449,  0.0288],\n",
       "                      ...,\n",
       "                      [-0.0140, -0.0274,  0.0126,  ...,  0.0250,  0.0119, -0.0255],\n",
       "                      [ 0.0347,  0.0020, -0.0177,  ...,  0.0055, -0.0076, -0.0020],\n",
       "                      [-0.0163, -0.0188, -0.0105,  ..., -0.0224, -0.0060,  0.0207]])),\n",
       "             ('llm.base_model.model.model.layers.1.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0086,  0.0098,  0.0573,  ..., -0.0173,  0.0029, -0.0198],\n",
       "                      [ 0.0093,  0.0047, -0.0364,  ...,  0.0088, -0.0131,  0.0019],\n",
       "                      [-0.0174, -0.0159, -0.0236,  ..., -0.0011, -0.0102,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0101, -0.0056, -0.0161,  ...,  0.0428, -0.0063,  0.0063],\n",
       "                      [-0.0149,  0.0218,  0.0135,  ..., -0.0287, -0.0176,  0.0234],\n",
       "                      [ 0.0247, -0.0045, -0.0159,  ..., -0.0130, -0.0136,  0.0280]])),\n",
       "             ('llm.base_model.model.model.layers.1.input_layernorm.weight',\n",
       "              tensor([0.1130, 0.1097, 0.1009,  ..., 0.0630, 0.0937, 0.0741])),\n",
       "             ('llm.base_model.model.model.layers.1.post_attention_layernorm.weight',\n",
       "              tensor([0.0990, 0.1019, 0.0964,  ..., 0.1063, 0.1001, 0.1018])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0259, -0.0078,  0.0073,  ..., -0.0102, -0.0181, -0.0090],\n",
       "                      [-0.0135,  0.0110, -0.0379,  ..., -0.0367, -0.0191,  0.0273],\n",
       "                      [-0.0138,  0.0337, -0.0253,  ..., -0.0038, -0.0197,  0.0210],\n",
       "                      ...,\n",
       "                      [-0.0504,  0.0133, -0.0215,  ..., -0.0068, -0.0300, -0.0374],\n",
       "                      [ 0.0029, -0.0094,  0.0025,  ..., -0.0007, -0.0154,  0.0143],\n",
       "                      [-0.0054, -0.0203,  0.0256,  ...,  0.0641, -0.0475,  0.0025]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0126, -0.0154, -0.0059,  ..., -0.0135, -0.0046, -0.0039],\n",
       "                      [ 0.0122, -0.0110, -0.0028,  ..., -0.0109, -0.0086,  0.0094],\n",
       "                      [ 0.0005,  0.0112,  0.0077,  ...,  0.0057, -0.0035,  0.0011],\n",
       "                      [-0.0042,  0.0068,  0.0129,  ..., -0.0016, -0.0102,  0.0171]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-1.9088e-04, -2.0122e-04,  4.1754e-04,  5.4474e-04],\n",
       "                      [ 2.9533e-04,  2.8172e-04, -3.9248e-04, -6.5223e-04],\n",
       "                      [ 5.4928e-04, -4.2772e-04,  3.9381e-04,  6.5799e-04],\n",
       "                      ...,\n",
       "                      [-2.1447e-04, -7.6420e-05, -1.9453e-04, -3.4583e-04],\n",
       "                      [ 1.3318e-03, -8.9754e-04,  6.4404e-04, -1.7686e-04],\n",
       "                      [ 8.5908e-04, -3.1220e-04,  2.3969e-04,  5.2679e-04]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0015,  0.0090, -0.0070,  ..., -0.0167, -0.0075,  0.0086],\n",
       "                      [ 0.0175, -0.0130, -0.0053,  ...,  0.0168, -0.0047, -0.0009],\n",
       "                      [ 0.0147,  0.0124,  0.0352,  ..., -0.0130,  0.0106,  0.0038],\n",
       "                      ...,\n",
       "                      [ 0.0335,  0.0494, -0.0286,  ...,  0.0298, -0.0422, -0.0052],\n",
       "                      [-0.0075, -0.0114, -0.0013,  ...,  0.0031,  0.0016, -0.0046],\n",
       "                      [ 0.0041, -0.0149, -0.0058,  ..., -0.0831, -0.0282,  0.0869]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0058,  0.0019,  0.0218,  ...,  0.0399, -0.0065,  0.0050],\n",
       "                      [ 0.0035,  0.0142, -0.0226,  ..., -0.0102,  0.0033, -0.0174],\n",
       "                      [-0.0027,  0.0166, -0.0030,  ..., -0.0172, -0.0301, -0.0295],\n",
       "                      ...,\n",
       "                      [ 0.0002, -0.0304, -0.0188,  ..., -0.0134, -0.0023,  0.0008],\n",
       "                      [-0.0355,  0.0008,  0.0182,  ..., -0.0068, -0.0111, -0.0072],\n",
       "                      [-0.0111,  0.0168,  0.0005,  ..., -0.0054,  0.0137, -0.0084]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0045,  0.0147, -0.0072,  ...,  0.0029,  0.0084, -0.0061],\n",
       "                      [ 0.0031, -0.0046, -0.0010,  ..., -0.0062, -0.0135,  0.0136],\n",
       "                      [-0.0120, -0.0088, -0.0087,  ..., -0.0135,  0.0093, -0.0128],\n",
       "                      [ 0.0148,  0.0046,  0.0029,  ..., -0.0087, -0.0026,  0.0084]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 3.0250e-04,  2.6120e-04, -4.4493e-04, -4.7794e-06],\n",
       "                      [-6.0606e-04, -6.1762e-04,  7.6276e-04, -4.0549e-04],\n",
       "                      [-1.5380e-05, -2.8418e-05,  6.4653e-05,  5.7204e-05],\n",
       "                      ...,\n",
       "                      [ 8.0126e-04,  7.9650e-04, -7.5178e-04,  9.9634e-04],\n",
       "                      [-7.5405e-04, -7.5558e-04,  6.3565e-04, -9.2871e-04],\n",
       "                      [-4.1921e-04, -4.4546e-04,  3.8869e-04, -4.1750e-04]])),\n",
       "             ('llm.base_model.model.model.layers.2.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0026,  0.0152,  0.0084,  ...,  0.0175,  0.0032, -0.0276],\n",
       "                      [-0.0014, -0.0185,  0.0050,  ...,  0.0056, -0.0139, -0.0191],\n",
       "                      [-0.0205,  0.0039, -0.0129,  ..., -0.0181, -0.0083,  0.0094],\n",
       "                      ...,\n",
       "                      [-0.0072, -0.0278,  0.0306,  ..., -0.0053, -0.0216,  0.0217],\n",
       "                      [ 0.0208, -0.0153,  0.0355,  ...,  0.0168,  0.0028, -0.0214],\n",
       "                      [-0.0116,  0.0007,  0.0094,  ..., -0.0081,  0.0110, -0.0152]])),\n",
       "             ('llm.base_model.model.model.layers.2.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0073,  0.0235, -0.0133,  ..., -0.0079,  0.0276,  0.0036],\n",
       "                      [ 0.0009,  0.0022, -0.0034,  ...,  0.0107, -0.0157, -0.0076],\n",
       "                      [ 0.0028, -0.0079,  0.0273,  ..., -0.0117,  0.0179,  0.0089],\n",
       "                      ...,\n",
       "                      [ 0.0279, -0.0103, -0.0143,  ..., -0.0317, -0.0424, -0.0115],\n",
       "                      [-0.0126, -0.0145, -0.0020,  ...,  0.0221, -0.0505,  0.0148],\n",
       "                      [-0.0017,  0.0131,  0.0040,  ..., -0.0140, -0.0300,  0.0056]])),\n",
       "             ('llm.base_model.model.model.layers.2.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0017, -0.0009,  0.0123,  ..., -0.0192,  0.0057, -0.0003],\n",
       "                      [ 0.0077, -0.0196, -0.0116,  ...,  0.0043,  0.0127,  0.0077],\n",
       "                      [ 0.0267,  0.0172,  0.0280,  ..., -0.0123, -0.0050,  0.0209],\n",
       "                      ...,\n",
       "                      [-0.0089, -0.0165,  0.0019,  ..., -0.0157, -0.0086,  0.0211],\n",
       "                      [ 0.0135, -0.0050,  0.0134,  ..., -0.0020,  0.0067, -0.0267],\n",
       "                      [-0.0146, -0.0284, -0.0227,  ..., -0.0055,  0.0022, -0.0068]])),\n",
       "             ('llm.base_model.model.model.layers.2.mlp.down_proj.weight',\n",
       "              tensor([[ 7.3433e-03,  1.4717e-02,  3.3539e-02,  ..., -2.0767e-02,\n",
       "                       -3.3932e-03, -3.0991e-02],\n",
       "                      [ 1.9806e-02, -2.5238e-02, -1.2505e-02,  ...,  1.2474e-02,\n",
       "                        3.5076e-03, -2.5635e-02],\n",
       "                      [ 4.0070e-02, -2.0706e-02, -4.4327e-03,  ..., -2.7206e-02,\n",
       "                        2.1229e-03, -3.3600e-02],\n",
       "                      ...,\n",
       "                      [-1.2848e-02,  2.8824e-02, -6.7406e-03,  ..., -5.9783e-05,\n",
       "                       -5.5656e-03, -1.3283e-02],\n",
       "                      [-2.0401e-02,  3.5034e-02,  1.0605e-02,  ...,  1.0811e-02,\n",
       "                       -1.4565e-02, -1.0239e-02],\n",
       "                      [ 3.6835e-02,  6.5002e-03, -2.2583e-02,  ...,  2.7847e-02,\n",
       "                       -4.1840e-02, -6.9389e-03]])),\n",
       "             ('llm.base_model.model.model.layers.2.input_layernorm.weight',\n",
       "              tensor([0.1741, 0.1770, 0.1727,  ..., 0.1772, 0.1704, 0.1760])),\n",
       "             ('llm.base_model.model.model.layers.2.post_attention_layernorm.weight',\n",
       "              tensor([0.1335, 0.1384, 0.1353,  ..., 0.1367, 0.1399, 0.1367])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 7.6103e-03,  1.3504e-02, -6.3658e-05,  ...,  2.6947e-02,\n",
       "                        1.4313e-02,  2.1484e-02],\n",
       "                      [-1.1757e-02,  1.6678e-02, -1.9394e-02,  ..., -4.4861e-02,\n",
       "                        4.4370e-04, -5.4588e-03],\n",
       "                      [ 1.6510e-02,  6.0043e-03, -2.0294e-02,  ...,  1.0559e-02,\n",
       "                       -1.9958e-02, -3.6530e-02],\n",
       "                      ...,\n",
       "                      [ 6.9153e-02, -6.6528e-02,  4.0924e-02,  ..., -7.6477e-02,\n",
       "                       -1.1162e-02,  5.7640e-03],\n",
       "                      [-7.8979e-02,  3.6499e-02, -2.7599e-03,  ...,  3.2928e-02,\n",
       "                        7.0129e-02,  2.0340e-02],\n",
       "                      [-1.4481e-02, -5.2307e-02,  7.1228e-02,  ..., -2.3438e-02,\n",
       "                       -9.5901e-03, -1.3489e-02]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0109,  0.0151, -0.0145,  ...,  0.0104, -0.0056, -0.0081],\n",
       "                      [ 0.0028,  0.0042, -0.0123,  ..., -0.0134, -0.0103,  0.0019],\n",
       "                      [-0.0058, -0.0090,  0.0170,  ...,  0.0063, -0.0076,  0.0116],\n",
       "                      [-0.0006, -0.0024, -0.0100,  ...,  0.0056,  0.0105, -0.0041]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 4.0457e-04,  3.9304e-04, -4.4301e-04,  7.3938e-04],\n",
       "                      [-1.0420e-03,  3.5249e-04,  2.7493e-04, -7.3718e-05],\n",
       "                      [-4.4370e-04, -3.7101e-04,  4.6339e-04, -1.6115e-04],\n",
       "                      ...,\n",
       "                      [-7.7076e-04,  2.5170e-04, -4.2908e-04,  1.6039e-04],\n",
       "                      [ 6.2958e-04, -2.7465e-04, -7.0598e-06, -3.2959e-04],\n",
       "                      [ 6.6871e-04, -2.9289e-04,  1.5695e-04, -3.6375e-04]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0100, -0.0085, -0.0065,  ..., -0.0050,  0.0025,  0.0410],\n",
       "                      [-0.0115,  0.0117, -0.0234,  ..., -0.0001, -0.0094, -0.0380],\n",
       "                      [ 0.0006, -0.0083, -0.0025,  ...,  0.0068, -0.0053, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.0908, -0.0853,  0.0033,  ..., -0.0637, -0.0029,  0.0269],\n",
       "                      [-0.0880,  0.0275,  0.0436,  ...,  0.0085,  0.0494, -0.0003],\n",
       "                      [-0.0003, -0.0504,  0.0919,  ..., -0.0147,  0.0082, -0.0113]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0003,  0.0100, -0.0060,  ..., -0.0127,  0.0048, -0.0122],\n",
       "                      [-0.0114,  0.0245, -0.0172,  ..., -0.0057, -0.0094, -0.0083],\n",
       "                      [ 0.0023, -0.0023,  0.0030,  ..., -0.0389, -0.0127, -0.0292],\n",
       "                      ...,\n",
       "                      [-0.0087, -0.0094,  0.0024,  ...,  0.0009, -0.0025, -0.0079],\n",
       "                      [ 0.0042,  0.0007,  0.0052,  ...,  0.0028, -0.0071,  0.0018],\n",
       "                      [-0.0095, -0.0074,  0.0093,  ...,  0.0011,  0.0009,  0.0134]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 1.6011e-02,  1.3515e-02,  1.6492e-02,  ...,  9.0806e-03,\n",
       "                        1.6080e-02, -1.6640e-02],\n",
       "                      [ 3.6921e-03,  1.2954e-03,  6.4153e-03,  ..., -2.9240e-03,\n",
       "                        7.5117e-03, -3.4603e-03],\n",
       "                      [ 1.5633e-02,  1.7095e-02, -3.2161e-03,  ...,  5.2340e-03,\n",
       "                        1.3603e-02, -3.4360e-03],\n",
       "                      [-4.1410e-03, -2.0605e-05,  1.2926e-02,  ...,  1.5594e-02,\n",
       "                       -6.0425e-03,  5.5044e-03]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 2.5790e-04,  1.1876e-04, -1.1110e-03,  9.6869e-04],\n",
       "                      [-1.6972e-03, -2.1652e-03, -1.5079e-03,  1.1381e-03],\n",
       "                      [-3.4360e-04, -6.8490e-04, -9.2742e-05,  1.1285e-04],\n",
       "                      ...,\n",
       "                      [ 5.5694e-04, -5.7164e-04, -1.0778e-03,  8.9645e-04],\n",
       "                      [-7.4819e-04, -5.8711e-04, -4.4273e-04,  7.4171e-04],\n",
       "                      [-2.3627e-04,  9.1653e-04,  3.1388e-04,  4.1156e-04]])),\n",
       "             ('llm.base_model.model.model.layers.3.self_attn.o_proj.weight',\n",
       "              tensor([[-2.8061e-02,  6.7558e-03, -1.6235e-02,  ...,  5.7220e-03,\n",
       "                        4.9667e-03, -1.8053e-03],\n",
       "                      [ 2.6993e-02, -2.8732e-02, -8.2855e-03,  ...,  8.3237e-03,\n",
       "                       -2.8973e-03,  9.1600e-04],\n",
       "                      [-7.8392e-04, -1.2177e-02, -2.5501e-03,  ...,  7.3195e-05,\n",
       "                        1.2512e-03,  5.1956e-03],\n",
       "                      ...,\n",
       "                      [ 6.3896e-03,  1.4313e-02,  1.2131e-02,  ...,  1.5612e-03,\n",
       "                        3.3722e-03,  1.1002e-02],\n",
       "                      [ 1.9150e-02,  2.3209e-02, -3.8891e-03,  ...,  1.4267e-03,\n",
       "                       -3.4084e-03, -3.6602e-03],\n",
       "                      [ 9.2163e-03, -4.6883e-03,  5.2681e-03,  ...,  3.6449e-03,\n",
       "                        2.2335e-03,  7.6141e-03]])),\n",
       "             ('llm.base_model.model.model.layers.3.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0049, -0.0128, -0.0162,  ..., -0.0281,  0.0436,  0.0115],\n",
       "                      [ 0.0162, -0.0006, -0.0129,  ..., -0.0062, -0.0233, -0.0128],\n",
       "                      [-0.0272,  0.0032, -0.0120,  ...,  0.0082, -0.0055, -0.0347],\n",
       "                      ...,\n",
       "                      [-0.0002,  0.0374,  0.0038,  ...,  0.0170, -0.0141, -0.0052],\n",
       "                      [-0.0052,  0.0077, -0.0019,  ...,  0.0004,  0.0002, -0.0104],\n",
       "                      [-0.0022, -0.0171,  0.0027,  ...,  0.0220, -0.0251,  0.0122]])),\n",
       "             ('llm.base_model.model.model.layers.3.mlp.up_proj.weight',\n",
       "              tensor([[-1.2726e-02,  1.4229e-02,  5.9471e-03,  ..., -4.5166e-03,\n",
       "                        1.4908e-02, -9.8419e-03],\n",
       "                      [-1.2604e-02, -1.5625e-02,  3.6560e-02,  ...,  1.7822e-02,\n",
       "                        1.6235e-02, -7.0496e-03],\n",
       "                      [-1.9217e-03, -2.2736e-03, -1.4259e-02,  ..., -6.0511e-04,\n",
       "                        3.1738e-03, -1.1208e-02],\n",
       "                      ...,\n",
       "                      [-8.3008e-03, -5.3482e-03, -3.8128e-03,  ...,  2.2430e-02,\n",
       "                        9.9869e-03, -2.3697e-02],\n",
       "                      [ 4.1962e-03, -1.0231e-02, -7.4692e-03,  ...,  1.1124e-02,\n",
       "                       -2.0599e-02, -1.0193e-02],\n",
       "                      [ 4.0436e-02,  3.0804e-03, -9.4533e-05,  ...,  4.4067e-02,\n",
       "                        6.7062e-03,  2.9240e-03]])),\n",
       "             ('llm.base_model.model.model.layers.3.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0010, -0.0048,  0.0050,  ..., -0.0074,  0.0055,  0.0193],\n",
       "                      [ 0.0255,  0.0071,  0.0157,  ..., -0.0165, -0.0163, -0.0114],\n",
       "                      [ 0.0137,  0.0122, -0.0177,  ..., -0.0127, -0.0091,  0.0053],\n",
       "                      ...,\n",
       "                      [ 0.0205, -0.0096, -0.0149,  ...,  0.0025,  0.0162,  0.0177],\n",
       "                      [-0.0214,  0.0129, -0.0162,  ..., -0.0028, -0.0160,  0.0132],\n",
       "                      [ 0.0076, -0.0152, -0.0251,  ..., -0.0021,  0.0081,  0.0083]])),\n",
       "             ('llm.base_model.model.model.layers.3.input_layernorm.weight',\n",
       "              tensor([0.2825, 0.2832, 0.2808,  ..., 0.2786, 0.2896, 0.2908])),\n",
       "             ('llm.base_model.model.model.layers.3.post_attention_layernorm.weight',\n",
       "              tensor([0.1752, 0.1754, 0.1711,  ..., 0.1742, 0.1696, 0.1731])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0177,  0.0035, -0.0020,  ..., -0.0045, -0.0028,  0.0085],\n",
       "                      [ 0.0230, -0.0139, -0.0094,  ...,  0.0100, -0.0254, -0.0001],\n",
       "                      [-0.0031, -0.0282,  0.0152,  ..., -0.0002, -0.0120, -0.0293],\n",
       "                      ...,\n",
       "                      [ 0.0213, -0.0053, -0.0034,  ...,  0.0019,  0.0257, -0.0646],\n",
       "                      [-0.0331,  0.0127,  0.0270,  ..., -0.0514,  0.0018,  0.0324],\n",
       "                      [-0.0113, -0.0338,  0.0648,  ...,  0.0614,  0.0405, -0.0364]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0068,  0.0085, -0.0101,  ..., -0.0131,  0.0084,  0.0065],\n",
       "                      [ 0.0103, -0.0084, -0.0029,  ..., -0.0020,  0.0169, -0.0029],\n",
       "                      [-0.0131, -0.0056,  0.0033,  ...,  0.0049,  0.0154,  0.0081],\n",
       "                      [-0.0028, -0.0004,  0.0132,  ..., -0.0031,  0.0061,  0.0137]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.4933e-04, -2.1523e-04, -1.6912e-04, -4.1901e-04],\n",
       "                      [-7.3474e-05,  1.0619e-04, -3.5567e-04,  3.4658e-04],\n",
       "                      [-2.8023e-04,  9.1612e-05,  6.3498e-05, -2.5244e-04],\n",
       "                      ...,\n",
       "                      [ 1.2774e-03,  7.1384e-04,  1.5501e-03, -1.3108e-03],\n",
       "                      [ 6.5606e-04,  3.9331e-04,  6.3155e-04, -4.3463e-04],\n",
       "                      [-7.2623e-04, -8.4099e-06, -5.6929e-04, -9.5266e-04]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0079,  0.0137, -0.0122,  ..., -0.0182, -0.0021, -0.0020],\n",
       "                      [-0.0278, -0.0056,  0.0019,  ..., -0.0041,  0.0128,  0.0052],\n",
       "                      [ 0.0157, -0.0019, -0.0148,  ...,  0.0142,  0.0175,  0.0374],\n",
       "                      ...,\n",
       "                      [-0.0109,  0.1208,  0.0582,  ...,  0.0275, -0.0191, -0.0121],\n",
       "                      [ 0.0337,  0.0508, -0.0195,  ...,  0.0549, -0.0399,  0.0677],\n",
       "                      [ 0.0071,  0.0607,  0.0182,  ..., -0.0029,  0.0457, -0.0164]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0019,  0.0003, -0.0086,  ..., -0.0151, -0.0072, -0.0001],\n",
       "                      [-0.0036,  0.0242,  0.0072,  ...,  0.0095,  0.0013,  0.0111],\n",
       "                      [ 0.0122, -0.0012, -0.0369,  ...,  0.0080, -0.0051, -0.0203],\n",
       "                      ...,\n",
       "                      [-0.0017, -0.0098, -0.0237,  ..., -0.0140, -0.0063,  0.0012],\n",
       "                      [-0.0027, -0.0070, -0.0011,  ...,  0.0039, -0.0045,  0.0082],\n",
       "                      [-0.0023, -0.0193, -0.0020,  ...,  0.0068, -0.0032,  0.0149]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0068,  0.0058,  0.0137,  ...,  0.0115,  0.0015,  0.0140],\n",
       "                      [ 0.0099, -0.0085,  0.0034,  ...,  0.0014, -0.0033,  0.0073],\n",
       "                      [ 0.0170,  0.0045, -0.0011,  ..., -0.0167, -0.0133, -0.0123],\n",
       "                      [ 0.0016, -0.0177,  0.0095,  ...,  0.0106,  0.0135,  0.0144]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.1037e-03,  2.9438e-04, -8.4935e-04,  9.3775e-04],\n",
       "                      [-2.7930e-04, -7.0613e-04,  8.4938e-04, -8.4855e-04],\n",
       "                      [-8.3830e-04, -3.6654e-04,  9.7156e-04, -7.3250e-04],\n",
       "                      ...,\n",
       "                      [-9.4022e-04, -6.1236e-04,  7.5255e-04, -1.1032e-03],\n",
       "                      [ 1.7643e-03,  9.3816e-04, -1.3088e-03,  1.6910e-03],\n",
       "                      [-2.2280e-05, -2.6418e-04,  1.0856e-04,  7.4728e-04]])),\n",
       "             ('llm.base_model.model.model.layers.4.self_attn.o_proj.weight',\n",
       "              tensor([[ 3.5431e-02,  8.3771e-03, -7.5388e-04,  ..., -2.6488e-04,\n",
       "                       -2.4490e-02, -3.6201e-03],\n",
       "                      [ 3.8929e-03, -3.8326e-05, -5.5809e-03,  ...,  3.3073e-03,\n",
       "                       -1.9928e-02,  3.1986e-03],\n",
       "                      [-7.3481e-04,  5.1117e-03, -1.1246e-02,  ..., -1.1169e-02,\n",
       "                        8.3084e-03, -3.6526e-03],\n",
       "                      ...,\n",
       "                      [-1.0445e-02,  3.0273e-02, -1.7685e-02,  ..., -2.4475e-02,\n",
       "                        4.1504e-03, -1.3458e-02],\n",
       "                      [-2.3651e-03, -4.5509e-03, -1.3710e-02,  ..., -6.9275e-03,\n",
       "                       -7.2479e-04, -7.9803e-03],\n",
       "                      [ 1.2390e-02,  2.1225e-02, -7.8201e-03,  ..., -3.0174e-03,\n",
       "                        1.5526e-02, -3.4809e-04]])),\n",
       "             ('llm.base_model.model.model.layers.4.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0025,  0.0079, -0.0104,  ..., -0.0155,  0.0002, -0.0146],\n",
       "                      [-0.0263,  0.0128,  0.0112,  ...,  0.0056,  0.0123, -0.0063],\n",
       "                      [-0.0081, -0.0225, -0.0032,  ...,  0.0017, -0.0026,  0.0272],\n",
       "                      ...,\n",
       "                      [-0.0120, -0.0035,  0.0114,  ..., -0.0288,  0.0055, -0.0016],\n",
       "                      [-0.0302,  0.0174, -0.0272,  ...,  0.0165,  0.0249, -0.0054],\n",
       "                      [ 0.0017, -0.0094, -0.0088,  ..., -0.0124,  0.0183,  0.0165]])),\n",
       "             ('llm.base_model.model.model.layers.4.mlp.up_proj.weight',\n",
       "              tensor([[-0.0128, -0.0082, -0.0432,  ...,  0.0126,  0.0044, -0.0029],\n",
       "                      [-0.0198, -0.0438,  0.0048,  ..., -0.0100,  0.0113, -0.0258],\n",
       "                      [-0.0033,  0.0297,  0.0039,  ..., -0.0346, -0.0142,  0.0044],\n",
       "                      ...,\n",
       "                      [-0.0048, -0.0320, -0.0178,  ...,  0.0091, -0.0084,  0.0485],\n",
       "                      [ 0.0089, -0.0083, -0.0142,  ..., -0.0437, -0.0089,  0.0126],\n",
       "                      [ 0.0016,  0.0231,  0.0042,  ...,  0.0004, -0.0010, -0.0033]])),\n",
       "             ('llm.base_model.model.model.layers.4.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0229, -0.0010,  0.0253,  ..., -0.0194,  0.0040,  0.0317],\n",
       "                      [-0.0070, -0.0444,  0.0405,  ..., -0.0241, -0.0207, -0.0040],\n",
       "                      [ 0.0007, -0.0175,  0.0236,  ...,  0.0079, -0.0024,  0.0179],\n",
       "                      ...,\n",
       "                      [-0.0274, -0.0032, -0.0163,  ...,  0.0224,  0.0009,  0.0144],\n",
       "                      [-0.0171,  0.0077, -0.0263,  ...,  0.0141, -0.0349, -0.0066],\n",
       "                      [ 0.0168, -0.0289, -0.0149,  ..., -0.0029, -0.0442, -0.0273]])),\n",
       "             ('llm.base_model.model.model.layers.4.input_layernorm.weight',\n",
       "              tensor([0.2617, 0.2590, 0.2595,  ..., 0.2556, 0.2642, 0.2722])),\n",
       "             ('llm.base_model.model.model.layers.4.post_attention_layernorm.weight',\n",
       "              tensor([0.1888, 0.1869, 0.1821,  ..., 0.1887, 0.1866, 0.1873])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0074, -0.0056, -0.0139,  ..., -0.0118, -0.0215,  0.0121],\n",
       "                      [-0.0231,  0.0145,  0.0403,  ..., -0.0104, -0.0165, -0.0318],\n",
       "                      [ 0.0083,  0.0096, -0.0125,  ...,  0.0248, -0.0096,  0.0081],\n",
       "                      ...,\n",
       "                      [-0.0117,  0.0068, -0.0060,  ...,  0.0483,  0.0067,  0.0327],\n",
       "                      [ 0.0378,  0.0150,  0.0200,  ..., -0.0430, -0.0364, -0.0297],\n",
       "                      [ 0.0069,  0.0232,  0.0305,  ..., -0.0300, -0.0148,  0.0009]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0115,  0.0113,  0.0018,  ..., -0.0096,  0.0032, -0.0043],\n",
       "                      [ 0.0079, -0.0095,  0.0101,  ..., -0.0079,  0.0023, -0.0063],\n",
       "                      [-0.0038, -0.0052, -0.0018,  ..., -0.0012,  0.0024, -0.0146],\n",
       "                      [-0.0047, -0.0014,  0.0137,  ...,  0.0003,  0.0012, -0.0170]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0007,  0.0009,  0.0010, -0.0006],\n",
       "                      [ 0.0007, -0.0010, -0.0011,  0.0013],\n",
       "                      [ 0.0007,  0.0007,  0.0010, -0.0005],\n",
       "                      ...,\n",
       "                      [-0.0002, -0.0011, -0.0010,  0.0006],\n",
       "                      [ 0.0003,  0.0012,  0.0010, -0.0008],\n",
       "                      [-0.0003, -0.0011, -0.0010,  0.0005]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0135,  0.0300,  0.0041,  ...,  0.0162,  0.0004, -0.0029],\n",
       "                      [ 0.0003, -0.0010, -0.0285,  ...,  0.0186, -0.0084,  0.0356],\n",
       "                      [-0.0067, -0.0156,  0.0002,  ...,  0.0035, -0.0097,  0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0066, -0.0016, -0.0234,  ...,  0.0379,  0.0056, -0.0303],\n",
       "                      [ 0.0554,  0.0196, -0.0195,  ..., -0.0015, -0.0150, -0.0356],\n",
       "                      [-0.0298, -0.0245,  0.0406,  ..., -0.0164, -0.0349,  0.0103]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0365,  0.0081,  0.0134,  ...,  0.0182,  0.0013,  0.0193],\n",
       "                      [ 0.0072,  0.0144, -0.0254,  ..., -0.0149,  0.0024, -0.0094],\n",
       "                      [ 0.0182,  0.0052,  0.0006,  ..., -0.0193,  0.0288,  0.0049],\n",
       "                      ...,\n",
       "                      [ 0.0245,  0.0137,  0.0066,  ...,  0.0367, -0.0081, -0.0021],\n",
       "                      [-0.0025,  0.0013, -0.0049,  ..., -0.0008, -0.0018, -0.0025],\n",
       "                      [-0.0054, -0.0089,  0.0204,  ..., -0.0066, -0.0047, -0.0224]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0123,  0.0052,  0.0043,  ..., -0.0137,  0.0072,  0.0077],\n",
       "                      [ 0.0008,  0.0062, -0.0048,  ...,  0.0140, -0.0007,  0.0141],\n",
       "                      [-0.0024, -0.0046, -0.0025,  ..., -0.0006, -0.0012,  0.0137],\n",
       "                      [-0.0116, -0.0126,  0.0009,  ..., -0.0079, -0.0113, -0.0093]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 3.4673e-04, -1.9079e-04, -6.1580e-04, -3.1499e-05],\n",
       "                      [-7.9419e-04, -7.0086e-04, -5.7340e-04, -7.1111e-04],\n",
       "                      [ 8.1128e-04,  7.6554e-04,  9.7785e-04,  8.9821e-04],\n",
       "                      ...,\n",
       "                      [-7.2008e-05, -2.1862e-04, -5.3360e-04, -4.0151e-04],\n",
       "                      [ 9.3824e-04,  1.0009e-03, -5.3982e-05,  6.8412e-04],\n",
       "                      [-3.4919e-04, -4.0044e-04, -3.9399e-04, -3.7912e-04]])),\n",
       "             ('llm.base_model.model.model.layers.5.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0133, -0.0054,  0.0042,  ..., -0.0166, -0.0107,  0.0236],\n",
       "                      [ 0.0031,  0.0011, -0.0137,  ..., -0.0177,  0.0017, -0.0008],\n",
       "                      [-0.0084, -0.0076,  0.0154,  ...,  0.0084,  0.0039,  0.0219],\n",
       "                      ...,\n",
       "                      [ 0.0169,  0.0052, -0.0049,  ...,  0.0163,  0.0332, -0.0211],\n",
       "                      [ 0.0038, -0.0048, -0.0028,  ..., -0.0150, -0.0077, -0.0037],\n",
       "                      [ 0.0059,  0.0025, -0.0127,  ...,  0.0073, -0.0077, -0.0182]])),\n",
       "             ('llm.base_model.model.model.layers.5.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0011, -0.0003, -0.0310,  ...,  0.0017, -0.0059, -0.0155],\n",
       "                      [ 0.0206, -0.0147, -0.0105,  ...,  0.0289,  0.0011, -0.0016],\n",
       "                      [ 0.0087,  0.0051, -0.0166,  ...,  0.0201,  0.0166, -0.0311],\n",
       "                      ...,\n",
       "                      [ 0.0045,  0.0079,  0.0406,  ..., -0.0687,  0.0138, -0.0238],\n",
       "                      [-0.0321,  0.0035,  0.0127,  ...,  0.0064,  0.0207, -0.0053],\n",
       "                      [ 0.0273, -0.0338, -0.0167,  ..., -0.0046, -0.0016, -0.0410]])),\n",
       "             ('llm.base_model.model.model.layers.5.mlp.up_proj.weight',\n",
       "              tensor([[-0.0045, -0.0164, -0.0017,  ..., -0.0141, -0.0055, -0.0117],\n",
       "                      [-0.0343, -0.0053, -0.0003,  ...,  0.0074,  0.0226,  0.0215],\n",
       "                      [-0.0003,  0.0122,  0.0072,  ...,  0.0016,  0.0104,  0.0172],\n",
       "                      ...,\n",
       "                      [ 0.0026,  0.0256, -0.0079,  ..., -0.0143,  0.0072,  0.0296],\n",
       "                      [ 0.0460, -0.0259, -0.0245,  ..., -0.0058, -0.0163,  0.0228],\n",
       "                      [ 0.0091,  0.0222,  0.0051,  ..., -0.0085, -0.0041, -0.0191]])),\n",
       "             ('llm.base_model.model.model.layers.5.mlp.down_proj.weight',\n",
       "              tensor([[-0.0046, -0.0299, -0.0043,  ..., -0.0030,  0.0076,  0.0135],\n",
       "                      [-0.0156,  0.0093,  0.0239,  ...,  0.0228, -0.0022, -0.0318],\n",
       "                      [ 0.0184,  0.0220,  0.0118,  ..., -0.0305, -0.0463,  0.0087],\n",
       "                      ...,\n",
       "                      [ 0.0089, -0.0247, -0.0037,  ..., -0.0018, -0.0257, -0.0196],\n",
       "                      [-0.0078, -0.0363,  0.0153,  ...,  0.0134,  0.0070, -0.0505],\n",
       "                      [ 0.0145,  0.0099, -0.0165,  ...,  0.0346,  0.0088, -0.0138]])),\n",
       "             ('llm.base_model.model.model.layers.5.input_layernorm.weight',\n",
       "              tensor([0.2632, 0.2627, 0.2605,  ..., 0.2527, 0.2683, 0.2700])),\n",
       "             ('llm.base_model.model.model.layers.5.post_attention_layernorm.weight',\n",
       "              tensor([0.2037, 0.1921, 0.1886,  ..., 0.2046, 0.1992, 0.2037])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0071, -0.0046,  0.0043,  ..., -0.0315, -0.0015, -0.0035],\n",
       "                      [-0.0003, -0.0162,  0.0086,  ...,  0.0130, -0.0017, -0.0283],\n",
       "                      [-0.0171,  0.0175, -0.0332,  ...,  0.0269, -0.0425, -0.0064],\n",
       "                      ...,\n",
       "                      [ 0.0163,  0.0097, -0.0340,  ...,  0.0220,  0.0057, -0.0044],\n",
       "                      [ 0.0321,  0.0369,  0.0060,  ..., -0.0109, -0.0916, -0.0202],\n",
       "                      [-0.0612, -0.0548,  0.0001,  ...,  0.0172,  0.0020,  0.0134]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0009, -0.0005,  0.0130,  ...,  0.0022, -0.0047, -0.0127],\n",
       "                      [-0.0044, -0.0019, -0.0057,  ..., -0.0145, -0.0122,  0.0035],\n",
       "                      [ 0.0153, -0.0106, -0.0168,  ...,  0.0010,  0.0012,  0.0068],\n",
       "                      [ 0.0020,  0.0097,  0.0055,  ...,  0.0111, -0.0050, -0.0077]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 4.3819e-04,  1.9592e-04, -6.2236e-04,  1.0420e-04],\n",
       "                      [-2.8523e-04,  4.2509e-04, -7.9174e-04,  1.0048e-03],\n",
       "                      [-6.6637e-04,  4.9288e-04,  3.9511e-04,  6.4641e-04],\n",
       "                      ...,\n",
       "                      [-1.8003e-03, -1.7306e-03,  1.4777e-03, -1.5473e-03],\n",
       "                      [-8.2375e-04, -5.8424e-04,  5.7124e-04,  4.8618e-04],\n",
       "                      [-6.6036e-05,  9.7108e-04, -1.0998e-03,  6.2990e-05]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.k_proj.weight',\n",
       "              tensor([[ 1.4389e-02, -1.3847e-02,  1.8265e-02,  ..., -7.9117e-03,\n",
       "                        2.0721e-02,  5.5237e-02],\n",
       "                      [-1.6464e-02, -5.9929e-03,  4.5929e-02,  ...,  7.0877e-03,\n",
       "                       -1.5976e-02,  1.0246e-02],\n",
       "                      [-9.5291e-03, -1.4183e-02, -4.2975e-05,  ..., -2.2507e-03,\n",
       "                       -2.6962e-02, -1.2856e-02],\n",
       "                      ...,\n",
       "                      [ 1.6129e-02, -3.9856e-02, -1.5381e-02,  ...,  5.9723e-02,\n",
       "                       -4.8184e-04, -4.5380e-02],\n",
       "                      [-2.0233e-02,  6.0120e-03, -2.9572e-02,  ..., -4.6997e-02,\n",
       "                       -4.1504e-02,  1.1856e-02],\n",
       "                      [-4.7394e-02, -2.5436e-02, -3.4454e-02,  ...,  1.7227e-02,\n",
       "                       -3.8818e-02, -2.6855e-02]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0126,  0.0349,  0.0067,  ...,  0.0117,  0.0025,  0.0040],\n",
       "                      [ 0.0348,  0.0005, -0.0072,  ...,  0.0040, -0.0001, -0.0004],\n",
       "                      [-0.0082, -0.0071,  0.0104,  ...,  0.0084,  0.0208,  0.0012],\n",
       "                      ...,\n",
       "                      [-0.0221, -0.0043,  0.0090,  ..., -0.0005, -0.0168,  0.0061],\n",
       "                      [-0.0193, -0.0099,  0.0027,  ..., -0.0039, -0.0018,  0.0230],\n",
       "                      [ 0.0357,  0.0071,  0.0198,  ..., -0.0214,  0.0009, -0.0025]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 5.3194e-03, -1.4448e-02, -7.5592e-05,  ...,  1.7565e-02,\n",
       "                        1.2406e-02,  4.2158e-03],\n",
       "                      [-1.4137e-02,  6.8709e-03,  9.3918e-03,  ..., -1.3081e-02,\n",
       "                       -5.3722e-03, -1.5464e-03],\n",
       "                      [ 9.5480e-03,  1.1940e-02,  1.2250e-02,  ..., -8.7488e-03,\n",
       "                        1.0872e-03,  6.8039e-04],\n",
       "                      [ 9.6941e-04,  1.3589e-02,  3.4909e-03,  ...,  3.9031e-03,\n",
       "                        4.5944e-03, -1.5627e-02]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 0.0012,  0.0014,  0.0011, -0.0011],\n",
       "                      [ 0.0003,  0.0005,  0.0003, -0.0004],\n",
       "                      [ 0.0013,  0.0012,  0.0010, -0.0010],\n",
       "                      ...,\n",
       "                      [-0.0005,  0.0006,  0.0005,  0.0004],\n",
       "                      [ 0.0007, -0.0005,  0.0007, -0.0006],\n",
       "                      [ 0.0019,  0.0010,  0.0014, -0.0014]])),\n",
       "             ('llm.base_model.model.model.layers.6.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0136, -0.0167, -0.0383,  ..., -0.0108,  0.0030,  0.0102],\n",
       "                      [-0.0213,  0.0050,  0.0036,  ..., -0.0199,  0.0037, -0.0027],\n",
       "                      [ 0.0021, -0.0027, -0.0036,  ...,  0.0100,  0.0029,  0.0094],\n",
       "                      ...,\n",
       "                      [-0.0019, -0.0161, -0.0125,  ...,  0.0067, -0.0053,  0.0220],\n",
       "                      [-0.0241,  0.0071,  0.0026,  ..., -0.0004,  0.0040, -0.0253],\n",
       "                      [-0.0189, -0.0152,  0.0060,  ..., -0.0151,  0.0087,  0.0106]])),\n",
       "             ('llm.base_model.model.model.layers.6.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0236,  0.0249, -0.0158,  ..., -0.0055, -0.0104, -0.0072],\n",
       "                      [ 0.0331, -0.0049, -0.0134,  ...,  0.0083,  0.0194,  0.0076],\n",
       "                      [-0.0177,  0.0215, -0.0129,  ..., -0.0221, -0.0014,  0.0094],\n",
       "                      ...,\n",
       "                      [ 0.0084, -0.0191, -0.0012,  ...,  0.0162, -0.0246, -0.0050],\n",
       "                      [ 0.0132, -0.0009, -0.0168,  ..., -0.0259, -0.0047, -0.0024],\n",
       "                      [-0.0311, -0.0495,  0.0226,  ..., -0.0418,  0.0021,  0.0192]])),\n",
       "             ('llm.base_model.model.model.layers.6.mlp.up_proj.weight',\n",
       "              tensor([[-0.0083, -0.0067, -0.0142,  ...,  0.0073, -0.0039, -0.0172],\n",
       "                      [ 0.0075, -0.0432,  0.0370,  ...,  0.0045,  0.0018, -0.0087],\n",
       "                      [-0.0265, -0.0211, -0.0225,  ...,  0.0066,  0.0190,  0.0222],\n",
       "                      ...,\n",
       "                      [-0.0269,  0.0037,  0.0186,  ...,  0.0184,  0.0031,  0.0419],\n",
       "                      [ 0.0249,  0.0157, -0.0014,  ..., -0.0304,  0.0163, -0.0062],\n",
       "                      [-0.0206,  0.0226, -0.0236,  ...,  0.0055, -0.0184, -0.0465]])),\n",
       "             ('llm.base_model.model.model.layers.6.mlp.down_proj.weight',\n",
       "              tensor([[-0.0079,  0.0172, -0.0023,  ...,  0.0006,  0.0119,  0.0151],\n",
       "                      [-0.0161, -0.0158,  0.0113,  ..., -0.0022, -0.0271, -0.0105],\n",
       "                      [-0.0014,  0.0154, -0.0128,  ...,  0.0272,  0.0254,  0.0129],\n",
       "                      ...,\n",
       "                      [ 0.0068, -0.0047,  0.0251,  ...,  0.0319, -0.0306, -0.0037],\n",
       "                      [ 0.0204, -0.0059,  0.0086,  ...,  0.0110, -0.0155, -0.0098],\n",
       "                      [ 0.0182, -0.0183, -0.0046,  ...,  0.0308, -0.0071,  0.0045]])),\n",
       "             ('llm.base_model.model.model.layers.6.input_layernorm.weight',\n",
       "              tensor([0.3181, 0.3567, 0.3306,  ..., 0.3176, 0.3364, 0.3196])),\n",
       "             ('llm.base_model.model.model.layers.6.post_attention_layernorm.weight',\n",
       "              tensor([0.2155, 0.2050, 0.2032,  ..., 0.2186, 0.2122, 0.2140])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0091,  0.0020,  0.0021,  ...,  0.0020, -0.0155, -0.0010],\n",
       "                      [-0.0038,  0.0060,  0.0028,  ...,  0.0148, -0.0120, -0.0113],\n",
       "                      [ 0.0009,  0.0073, -0.0189,  ..., -0.0180, -0.0016,  0.0096],\n",
       "                      ...,\n",
       "                      [ 0.0003, -0.0379, -0.0302,  ..., -0.0145,  0.0342,  0.0359],\n",
       "                      [ 0.0117,  0.0557, -0.0434,  ..., -0.0178, -0.0659, -0.0535],\n",
       "                      [ 0.0793, -0.0239, -0.0139,  ...,  0.0891,  0.0343, -0.0056]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0139, -0.0070,  0.0093,  ...,  0.0055,  0.0126, -0.0143],\n",
       "                      [-0.0093,  0.0074,  0.0123,  ...,  0.0028, -0.0025, -0.0081],\n",
       "                      [-0.0029, -0.0096,  0.0099,  ...,  0.0078, -0.0084, -0.0062],\n",
       "                      [-0.0028, -0.0078, -0.0008,  ..., -0.0057, -0.0055, -0.0142]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-5.4837e-04, -1.2004e-04,  4.6501e-05,  5.5980e-04],\n",
       "                      [ 8.0790e-04,  5.9608e-05,  5.7184e-04, -3.1104e-04],\n",
       "                      [-5.5405e-04, -6.0104e-04, -8.7139e-04,  6.9526e-04],\n",
       "                      ...,\n",
       "                      [ 6.1296e-04,  7.5067e-04,  6.6167e-04, -9.0860e-04],\n",
       "                      [-7.1949e-04, -9.0285e-04,  1.1159e-04,  9.8675e-05],\n",
       "                      [ 7.8358e-04,  2.2410e-04,  4.2361e-04,  4.4438e-04]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0050, -0.0065, -0.0125,  ...,  0.0085,  0.0067, -0.0053],\n",
       "                      [-0.0046, -0.0164,  0.0042,  ..., -0.0068,  0.0048,  0.0212],\n",
       "                      [-0.0050, -0.0073,  0.0184,  ..., -0.0081, -0.0132, -0.0186],\n",
       "                      ...,\n",
       "                      [ 0.0429,  0.0105,  0.0206,  ...,  0.0371,  0.0398,  0.0276],\n",
       "                      [ 0.0432,  0.0535, -0.0020,  ..., -0.0329, -0.0331, -0.0054],\n",
       "                      [ 0.0344,  0.0087,  0.0117,  ...,  0.0106,  0.0065, -0.0273]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0156,  0.0026,  0.0171,  ...,  0.0269,  0.0062, -0.0139],\n",
       "                      [ 0.0286, -0.0297, -0.0009,  ...,  0.0189, -0.0159, -0.0204],\n",
       "                      [-0.0089, -0.0067, -0.0080,  ..., -0.0165,  0.0103,  0.0028],\n",
       "                      ...,\n",
       "                      [ 0.0003, -0.0370,  0.0036,  ...,  0.0019, -0.0046, -0.0099],\n",
       "                      [-0.0326,  0.0170, -0.0270,  ..., -0.0125,  0.0133,  0.0011],\n",
       "                      [-0.0108, -0.0002, -0.0071,  ...,  0.0249,  0.0086,  0.0117]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0073,  0.0116, -0.0122,  ...,  0.0096, -0.0125, -0.0081],\n",
       "                      [ 0.0135, -0.0042, -0.0019,  ...,  0.0101, -0.0088,  0.0123],\n",
       "                      [-0.0009, -0.0057, -0.0046,  ..., -0.0084,  0.0041, -0.0055],\n",
       "                      [-0.0015,  0.0019, -0.0140,  ...,  0.0087,  0.0119,  0.0108]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-1.0164e-03,  6.9435e-04, -9.1345e-05,  5.3795e-04],\n",
       "                      [ 1.6267e-03, -1.1440e-03,  5.0181e-04, -1.1684e-03],\n",
       "                      [ 2.2657e-04,  6.5451e-04, -4.7667e-05,  5.5333e-04],\n",
       "                      ...,\n",
       "                      [-4.3404e-04,  1.8635e-04, -4.7325e-04,  8.0993e-05],\n",
       "                      [-1.3431e-04,  2.8432e-04, -5.2070e-04,  3.4039e-04],\n",
       "                      [ 1.1264e-03, -8.7127e-04,  9.6956e-04, -9.1630e-04]])),\n",
       "             ('llm.base_model.model.model.layers.7.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0146, -0.0162, -0.0042,  ...,  0.0083, -0.0240,  0.0023],\n",
       "                      [-0.0028,  0.0236,  0.0117,  ..., -0.0425, -0.0108, -0.0068],\n",
       "                      [ 0.0040,  0.0047, -0.0207,  ..., -0.0109, -0.0114, -0.0078],\n",
       "                      ...,\n",
       "                      [-0.0173, -0.0279, -0.0049,  ...,  0.0246, -0.0203, -0.0012],\n",
       "                      [-0.0202,  0.0070,  0.0112,  ...,  0.0087, -0.0137,  0.0154],\n",
       "                      [-0.0003,  0.0045,  0.0016,  ...,  0.0064, -0.0138,  0.0044]])),\n",
       "             ('llm.base_model.model.model.layers.7.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0027, -0.0009, -0.0157,  ..., -0.0037, -0.0304, -0.0077],\n",
       "                      [-0.0285,  0.0175, -0.0064,  ..., -0.0010, -0.0109, -0.0069],\n",
       "                      [ 0.0162, -0.0320, -0.0081,  ...,  0.0296, -0.0195,  0.0071],\n",
       "                      ...,\n",
       "                      [-0.0068,  0.0052, -0.0121,  ..., -0.0263, -0.0057, -0.0278],\n",
       "                      [-0.0033,  0.0208,  0.0107,  ..., -0.0073,  0.0054, -0.0315],\n",
       "                      [ 0.0199, -0.0173, -0.0041,  ...,  0.0144,  0.0193, -0.0012]])),\n",
       "             ('llm.base_model.model.model.layers.7.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0225,  0.0014, -0.0017,  ...,  0.0149, -0.0357,  0.0049],\n",
       "                      [-0.0117, -0.0215,  0.0334,  ...,  0.0003, -0.0122,  0.0208],\n",
       "                      [ 0.0211, -0.0146,  0.0078,  ..., -0.0117,  0.0183, -0.0300],\n",
       "                      ...,\n",
       "                      [ 0.0023,  0.0011, -0.0187,  ..., -0.0029, -0.0229,  0.0022],\n",
       "                      [ 0.0004,  0.0069,  0.0169,  ..., -0.0130,  0.0192, -0.0008],\n",
       "                      [-0.0235, -0.0164,  0.0064,  ...,  0.0183,  0.0098,  0.0043]])),\n",
       "             ('llm.base_model.model.model.layers.7.mlp.down_proj.weight',\n",
       "              tensor([[-0.0079, -0.0129,  0.0018,  ..., -0.0143, -0.0076, -0.0201],\n",
       "                      [-0.0028, -0.0065,  0.0207,  ..., -0.0046,  0.0042,  0.0020],\n",
       "                      [ 0.0103,  0.0131,  0.0315,  ..., -0.0152, -0.0086, -0.0143],\n",
       "                      ...,\n",
       "                      [-0.0056, -0.0007, -0.0223,  ...,  0.0175,  0.0037, -0.0283],\n",
       "                      [ 0.0421, -0.0100,  0.0036,  ..., -0.0183, -0.0001, -0.0150],\n",
       "                      [ 0.0174,  0.0175, -0.0316,  ...,  0.0036, -0.0238, -0.0009]])),\n",
       "             ('llm.base_model.model.model.layers.7.input_layernorm.weight',\n",
       "              tensor([0.3240, 0.3662, 0.3379,  ..., 0.3247, 0.3567, 0.3296])),\n",
       "             ('llm.base_model.model.model.layers.7.post_attention_layernorm.weight',\n",
       "              tensor([0.2336, 0.2173, 0.2180,  ..., 0.2253, 0.2242, 0.2233])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0079, -0.0121, -0.0254,  ..., -0.0053,  0.0032,  0.0030],\n",
       "                      [-0.0191, -0.0151, -0.0345,  ..., -0.0016, -0.0018, -0.0040],\n",
       "                      [-0.0327, -0.0031, -0.0106,  ...,  0.0051,  0.0191, -0.0195],\n",
       "                      ...,\n",
       "                      [-0.0068,  0.0847,  0.0412,  ..., -0.0289, -0.0293, -0.0452],\n",
       "                      [-0.0018, -0.0646, -0.0157,  ...,  0.0334,  0.0219,  0.0005],\n",
       "                      [-0.0617, -0.0586, -0.0117,  ..., -0.0488,  0.0297, -0.0161]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0086,  0.0011,  0.0057,  ...,  0.0154,  0.0136,  0.0097],\n",
       "                      [-0.0120, -0.0171,  0.0025,  ...,  0.0078,  0.0086,  0.0089],\n",
       "                      [-0.0093, -0.0076, -0.0041,  ..., -0.0092,  0.0033, -0.0105],\n",
       "                      [ 0.0145,  0.0041, -0.0072,  ...,  0.0117, -0.0039, -0.0103]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-4.9197e-04, -1.2239e-04, -3.9927e-04,  2.2265e-04],\n",
       "                      [-6.8244e-04,  6.5608e-05, -2.4072e-04, -1.7912e-05],\n",
       "                      [ 3.0339e-04, -2.7036e-04, -1.7853e-04,  2.1734e-04],\n",
       "                      ...,\n",
       "                      [ 3.5874e-04, -1.4298e-03,  1.6811e-04,  2.6233e-04],\n",
       "                      [-4.9675e-04,  6.8003e-04,  1.0300e-04, -9.4354e-06],\n",
       "                      [ 1.0697e-03, -3.8116e-04,  7.6863e-04, -9.9950e-04]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0053,  0.0049, -0.0074,  ..., -0.0074,  0.0062,  0.0089],\n",
       "                      [-0.0089,  0.0078, -0.0052,  ...,  0.0227, -0.0016,  0.0142],\n",
       "                      [-0.0113,  0.0028,  0.0064,  ...,  0.0016, -0.0165, -0.0158],\n",
       "                      ...,\n",
       "                      [-0.0027, -0.0371, -0.0076,  ..., -0.0332, -0.0146,  0.0268],\n",
       "                      [ 0.0030,  0.0243,  0.0266,  ..., -0.0371,  0.0446, -0.0579],\n",
       "                      [ 0.0166, -0.0026, -0.0323,  ...,  0.0226,  0.0113, -0.0109]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0265, -0.0123,  0.0052,  ..., -0.0151, -0.0120, -0.0077],\n",
       "                      [-0.0220, -0.0137,  0.0073,  ...,  0.0284,  0.0046,  0.0203],\n",
       "                      [-0.0048,  0.0157,  0.0140,  ..., -0.0043,  0.0069, -0.0221],\n",
       "                      ...,\n",
       "                      [ 0.0295, -0.0165,  0.0036,  ...,  0.0229, -0.0180,  0.0210],\n",
       "                      [ 0.0265, -0.0144,  0.0023,  ...,  0.0070, -0.0075,  0.0004],\n",
       "                      [ 0.0163,  0.0009, -0.0071,  ..., -0.0019,  0.0053, -0.0063]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0139, -0.0019,  0.0024,  ...,  0.0149, -0.0109,  0.0120],\n",
       "                      [-0.0121, -0.0039,  0.0016,  ...,  0.0147, -0.0120,  0.0110],\n",
       "                      [ 0.0122,  0.0099, -0.0046,  ..., -0.0130,  0.0097,  0.0120],\n",
       "                      [-0.0120,  0.0145,  0.0124,  ...,  0.0037, -0.0132, -0.0022]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0014, -0.0004, -0.0010,  0.0016],\n",
       "                      [ 0.0005,  0.0003,  0.0005, -0.0002],\n",
       "                      [-0.0008, -0.0005, -0.0003,  0.0011],\n",
       "                      ...,\n",
       "                      [-0.0009, -0.0008, -0.0008, -0.0006],\n",
       "                      [ 0.0008,  0.0007,  0.0008,  0.0003],\n",
       "                      [-0.0004, -0.0006, -0.0006, -0.0009]])),\n",
       "             ('llm.base_model.model.model.layers.8.self_attn.o_proj.weight',\n",
       "              tensor([[ 1.3641e-02,  1.3847e-02, -1.2276e-02,  ..., -1.0307e-02,\n",
       "                        2.0142e-03,  1.6174e-02],\n",
       "                      [ 9.4376e-03,  4.0016e-03, -3.2745e-02,  ..., -7.1526e-03,\n",
       "                       -1.0101e-02, -1.4565e-02],\n",
       "                      [ 9.0313e-04,  1.0681e-02, -2.6283e-03,  ..., -9.2840e-04,\n",
       "                        1.4610e-02,  2.0081e-02],\n",
       "                      ...,\n",
       "                      [-1.8173e-02,  2.3590e-02, -6.2599e-03,  ...,  4.1342e-04,\n",
       "                       -9.2793e-04, -3.3150e-03],\n",
       "                      [ 5.8708e-03,  9.2506e-05, -3.0594e-03,  ...,  2.6817e-03,\n",
       "                        8.6594e-03, -2.2797e-02],\n",
       "                      [-2.4658e-02,  6.3477e-03, -7.7362e-03,  ...,  2.0813e-02,\n",
       "                       -9.1248e-03, -4.2725e-03]])),\n",
       "             ('llm.base_model.model.model.layers.8.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0109,  0.0034, -0.0429,  ..., -0.0055, -0.0260, -0.0239],\n",
       "                      [-0.0034, -0.0431,  0.0119,  ..., -0.0010, -0.0456,  0.0210],\n",
       "                      [ 0.0161,  0.0187,  0.0225,  ...,  0.0270,  0.0208, -0.0106],\n",
       "                      ...,\n",
       "                      [-0.0130,  0.0030,  0.0081,  ...,  0.0254,  0.0157,  0.0057],\n",
       "                      [-0.0131,  0.0003,  0.0089,  ...,  0.0003, -0.0226,  0.0250],\n",
       "                      [-0.0252,  0.0054, -0.0035,  ..., -0.0126,  0.0113, -0.0018]])),\n",
       "             ('llm.base_model.model.model.layers.8.mlp.up_proj.weight',\n",
       "              tensor([[-0.0109,  0.0170, -0.0171,  ...,  0.0280,  0.0087, -0.0117],\n",
       "                      [-0.0488,  0.0175, -0.0394,  ...,  0.0157, -0.0025, -0.0063],\n",
       "                      [ 0.0098,  0.0045,  0.0095,  ..., -0.0132, -0.0200,  0.0312],\n",
       "                      ...,\n",
       "                      [-0.0117,  0.0398, -0.0179,  ...,  0.0142, -0.0083,  0.0094],\n",
       "                      [-0.0017, -0.0052, -0.0082,  ..., -0.0157,  0.0192, -0.0158],\n",
       "                      [-0.0150,  0.0165, -0.0143,  ..., -0.0160,  0.0018,  0.0050]])),\n",
       "             ('llm.base_model.model.model.layers.8.mlp.down_proj.weight',\n",
       "              tensor([[-0.0122, -0.0057,  0.0179,  ...,  0.0095,  0.0164, -0.0237],\n",
       "                      [ 0.0119,  0.0127, -0.0200,  ..., -0.0067,  0.0054, -0.0227],\n",
       "                      [ 0.0017, -0.0212, -0.0284,  ..., -0.0129,  0.0062, -0.0057],\n",
       "                      ...,\n",
       "                      [ 0.0161, -0.0201, -0.0373,  ...,  0.0059,  0.0053, -0.0170],\n",
       "                      [ 0.0148,  0.0047, -0.0056,  ..., -0.0029, -0.0056, -0.0150],\n",
       "                      [-0.0006,  0.0129,  0.0017,  ...,  0.0014,  0.0017,  0.0021]])),\n",
       "             ('llm.base_model.model.model.layers.8.input_layernorm.weight',\n",
       "              tensor([0.3311, 0.3467, 0.3308,  ..., 0.3206, 0.3445, 0.3215])),\n",
       "             ('llm.base_model.model.model.layers.8.post_attention_layernorm.weight',\n",
       "              tensor([0.2412, 0.2225, 0.2180,  ..., 0.2355, 0.2284, 0.2266])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0210,  0.0031,  0.0181,  ..., -0.0063, -0.0095, -0.0153],\n",
       "                      [ 0.0006, -0.0349,  0.0128,  ...,  0.0044, -0.0066,  0.0014],\n",
       "                      [ 0.0022, -0.0021, -0.0143,  ..., -0.0218, -0.0296, -0.0229],\n",
       "                      ...,\n",
       "                      [ 0.0035, -0.0453,  0.0179,  ...,  0.0230,  0.0154, -0.0201],\n",
       "                      [ 0.0134, -0.0212,  0.0083,  ...,  0.0107,  0.0144,  0.0097],\n",
       "                      [-0.0002,  0.0561,  0.0173,  ..., -0.0567,  0.0493, -0.0061]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0064,  0.0026, -0.0010,  ...,  0.0091, -0.0090, -0.0098],\n",
       "                      [-0.0172, -0.0138, -0.0134,  ..., -0.0014, -0.0111,  0.0102],\n",
       "                      [ 0.0093, -0.0019,  0.0133,  ...,  0.0112, -0.0033,  0.0082],\n",
       "                      [-0.0016,  0.0016, -0.0074,  ...,  0.0049,  0.0052,  0.0051]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 3.4928e-04,  8.3124e-04, -8.1891e-04, -6.9281e-04],\n",
       "                      [-3.4287e-05,  2.2625e-04,  4.1463e-04, -1.8154e-04],\n",
       "                      [ 9.9829e-04, -2.4404e-05, -3.5037e-04, -1.2094e-03],\n",
       "                      ...,\n",
       "                      [ 6.5845e-04, -5.7533e-04, -6.8621e-04,  4.7062e-04],\n",
       "                      [-4.9694e-04,  2.2300e-04,  1.7147e-04,  2.3376e-04],\n",
       "                      [ 2.9067e-05,  2.2983e-04,  3.5548e-04,  3.3114e-04]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0348,  0.0105, -0.0145,  ...,  0.0085, -0.0218, -0.0064],\n",
       "                      [-0.0067,  0.0333,  0.0096,  ..., -0.0128,  0.0093,  0.0012],\n",
       "                      [-0.0099, -0.0115,  0.0190,  ..., -0.0051, -0.0124, -0.0036],\n",
       "                      ...,\n",
       "                      [ 0.0130, -0.0178, -0.0067,  ..., -0.0104,  0.0226,  0.0221],\n",
       "                      [ 0.0329, -0.0098,  0.0211,  ...,  0.0475, -0.0137,  0.0514],\n",
       "                      [ 0.0075, -0.0258,  0.0294,  ...,  0.0091,  0.0246, -0.0224]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-3.7346e-03,  1.0124e-02,  9.9599e-05,  ...,  7.1106e-03,\n",
       "                       -2.1225e-02, -1.8143e-02],\n",
       "                      [-1.6846e-02, -1.6556e-02, -1.1597e-03,  ...,  2.8793e-02,\n",
       "                       -6.5327e-04, -3.1433e-03],\n",
       "                      [ 2.5043e-03, -2.4963e-02,  1.9043e-02,  ..., -2.6031e-02,\n",
       "                        6.2637e-03, -1.0490e-02],\n",
       "                      ...,\n",
       "                      [-6.4240e-03, -1.4610e-02,  6.2714e-03,  ...,  1.2770e-03,\n",
       "                       -2.1667e-02, -1.3361e-03],\n",
       "                      [-1.4603e-02,  4.2801e-03, -1.1124e-02,  ..., -9.5062e-03,\n",
       "                        3.6693e-04, -1.2695e-02],\n",
       "                      [ 2.5253e-02,  1.9714e-02, -1.5020e-04,  ..., -1.4992e-02,\n",
       "                       -7.1678e-03, -4.3068e-03]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 9.9233e-03, -9.9157e-04,  8.0574e-03,  ...,  1.6454e-02,\n",
       "                       -8.1055e-03, -1.6480e-02],\n",
       "                      [-8.5666e-05, -1.0748e-02, -1.2797e-02,  ..., -1.3908e-02,\n",
       "                        5.5520e-03, -6.1453e-03],\n",
       "                      [-8.4602e-03,  2.3073e-03,  8.4321e-03,  ..., -8.7697e-05,\n",
       "                        1.1104e-02,  1.9878e-03],\n",
       "                      [-1.0229e-02, -1.5579e-02,  9.0556e-03,  ..., -1.6276e-02,\n",
       "                       -3.9661e-03,  1.2316e-02]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.6995e-03, -2.7779e-03,  2.3829e-03, -1.5493e-03],\n",
       "                      [ 8.3884e-04, -1.3293e-03,  1.0040e-03, -1.1386e-03],\n",
       "                      [-3.7153e-04, -4.1483e-05,  2.9895e-04,  4.1733e-04],\n",
       "                      ...,\n",
       "                      [ 4.1828e-04, -9.9766e-04,  2.0603e-03, -9.1284e-04],\n",
       "                      [-6.9786e-04,  8.0416e-04, -4.4274e-04,  7.6466e-04],\n",
       "                      [ 6.9805e-04, -1.0193e-03,  4.1627e-04, -6.9986e-04]])),\n",
       "             ('llm.base_model.model.model.layers.9.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0091,  0.0108,  0.0054,  ..., -0.0088,  0.0005,  0.0004],\n",
       "                      [-0.0048, -0.0150, -0.0015,  ..., -0.0003,  0.0069,  0.0142],\n",
       "                      [-0.0350, -0.0307,  0.0112,  ...,  0.0265,  0.0021,  0.0125],\n",
       "                      ...,\n",
       "                      [ 0.0158, -0.0149,  0.0124,  ...,  0.0061,  0.0070, -0.0094],\n",
       "                      [ 0.0009,  0.0193,  0.0017,  ...,  0.0130,  0.0011, -0.0014],\n",
       "                      [ 0.0132,  0.0497, -0.0213,  ..., -0.0051,  0.0074,  0.0051]])),\n",
       "             ('llm.base_model.model.model.layers.9.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0061,  0.0267, -0.0076,  ..., -0.0262, -0.0125,  0.0025],\n",
       "                      [-0.0243,  0.0277,  0.0299,  ...,  0.0300,  0.0307, -0.0036],\n",
       "                      [ 0.0384,  0.0292, -0.0247,  ..., -0.0261,  0.0102, -0.0041],\n",
       "                      ...,\n",
       "                      [-0.0141, -0.0125, -0.0292,  ..., -0.0019, -0.0403,  0.0037],\n",
       "                      [-0.0143, -0.0236,  0.0231,  ..., -0.0145,  0.0016,  0.0129],\n",
       "                      [ 0.0109, -0.0161, -0.0097,  ...,  0.0115, -0.0160,  0.0081]])),\n",
       "             ('llm.base_model.model.model.layers.9.mlp.up_proj.weight',\n",
       "              tensor([[-0.0119,  0.0114,  0.0123,  ...,  0.0007, -0.0050,  0.0104],\n",
       "                      [ 0.0095, -0.0035,  0.0027,  ...,  0.0154,  0.0163, -0.0210],\n",
       "                      [-0.0217, -0.0104, -0.0201,  ..., -0.0036, -0.0097, -0.0039],\n",
       "                      ...,\n",
       "                      [-0.0029,  0.0099, -0.0143,  ..., -0.0055, -0.0314, -0.0182],\n",
       "                      [-0.0023,  0.0158, -0.0328,  ..., -0.0309, -0.0101, -0.0165],\n",
       "                      [ 0.0006, -0.0366, -0.0113,  ..., -0.0146,  0.0242,  0.0016]])),\n",
       "             ('llm.base_model.model.model.layers.9.mlp.down_proj.weight',\n",
       "              tensor([[-0.0039,  0.0239, -0.0412,  ...,  0.0015, -0.0128,  0.0100],\n",
       "                      [ 0.0260, -0.0217, -0.0163,  ...,  0.0031, -0.0288, -0.0311],\n",
       "                      [ 0.0004,  0.0044,  0.0015,  ..., -0.0166,  0.0024, -0.0035],\n",
       "                      ...,\n",
       "                      [-0.0083,  0.0176,  0.0007,  ..., -0.0023, -0.0302,  0.0074],\n",
       "                      [-0.0349, -0.0009,  0.0133,  ..., -0.0242, -0.0005, -0.0312],\n",
       "                      [ 0.0226,  0.0145,  0.0165,  ...,  0.0421,  0.0137,  0.0164]])),\n",
       "             ('llm.base_model.model.model.layers.9.input_layernorm.weight',\n",
       "              tensor([0.3521, 0.3606, 0.3237,  ..., 0.3518, 0.3450, 0.3408])),\n",
       "             ('llm.base_model.model.model.layers.9.post_attention_layernorm.weight',\n",
       "              tensor([0.2432, 0.2302, 0.2219,  ..., 0.2402, 0.2374, 0.2328])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0032,  0.0028, -0.0017,  ...,  0.0091, -0.0056, -0.0068],\n",
       "                      [-0.0054, -0.0089,  0.0153,  ..., -0.0052,  0.0608,  0.0014],\n",
       "                      [-0.0106, -0.0074, -0.0066,  ...,  0.0216, -0.0149, -0.0166],\n",
       "                      ...,\n",
       "                      [ 0.0327,  0.0642, -0.0154,  ...,  0.0294,  0.0345, -0.0078],\n",
       "                      [-0.0571,  0.0582, -0.0005,  ..., -0.0698, -0.0012, -0.0073],\n",
       "                      [-0.0508, -0.0237, -0.0058,  ..., -0.0092, -0.0337, -0.0172]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0092,  0.0018,  0.0093,  ...,  0.0054,  0.0070, -0.0142],\n",
       "                      [-0.0097, -0.0096,  0.0049,  ...,  0.0046, -0.0026,  0.0104],\n",
       "                      [ 0.0101,  0.0063,  0.0138,  ..., -0.0158, -0.0154, -0.0009],\n",
       "                      [ 0.0073,  0.0005,  0.0094,  ..., -0.0066, -0.0014,  0.0009]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-4.7081e-04,  3.8175e-04, -4.7318e-04, -3.3249e-04],\n",
       "                      [-4.3879e-05, -5.8746e-04, -7.0878e-04,  6.8979e-04],\n",
       "                      [ 1.2678e-03, -5.2832e-04,  8.6207e-04,  1.1579e-03],\n",
       "                      ...,\n",
       "                      [-7.1119e-04, -5.6457e-04, -8.8310e-04,  9.3079e-04],\n",
       "                      [-9.5389e-04, -2.6411e-04, -9.3308e-04,  4.6685e-04],\n",
       "                      [ 2.5449e-04,  1.7253e-04, -6.6896e-04,  9.1387e-04]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0216,  0.0070, -0.0044,  ..., -0.0118,  0.0052, -0.0064],\n",
       "                      [-0.0102,  0.0064, -0.0048,  ...,  0.0112, -0.0121,  0.0088],\n",
       "                      [-0.0057,  0.0007,  0.0068,  ..., -0.0150,  0.0245, -0.0015],\n",
       "                      ...,\n",
       "                      [-0.0444, -0.0583,  0.0088,  ...,  0.0330, -0.0797,  0.0086],\n",
       "                      [-0.0385, -0.0084,  0.0300,  ..., -0.0191, -0.0438, -0.0229],\n",
       "                      [-0.0292,  0.0298, -0.0217,  ...,  0.0156,  0.0468, -0.0105]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0392,  0.0023, -0.0041,  ...,  0.0088,  0.0106,  0.0101],\n",
       "                      [-0.0084,  0.0122,  0.0128,  ..., -0.0076, -0.0380,  0.0195],\n",
       "                      [ 0.0147, -0.0126,  0.0155,  ...,  0.0166,  0.0069, -0.0041],\n",
       "                      ...,\n",
       "                      [ 0.0223,  0.0296,  0.0004,  ...,  0.0279, -0.0055, -0.0158],\n",
       "                      [ 0.0026,  0.0074,  0.0020,  ...,  0.0019,  0.0123,  0.0012],\n",
       "                      [ 0.0160,  0.0086, -0.0165,  ..., -0.0046, -0.0126,  0.0285]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 4.3872e-03,  3.4043e-03,  1.0069e-02,  ...,  7.9868e-03,\n",
       "                       -7.2152e-03,  1.1063e-02],\n",
       "                      [ 9.7912e-03, -1.1605e-02,  9.4921e-03,  ...,  4.1072e-03,\n",
       "                       -7.9952e-04, -9.9535e-03],\n",
       "                      [-9.9190e-03,  1.1073e-02, -7.1211e-03,  ..., -6.2280e-03,\n",
       "                       -1.2507e-02,  1.2624e-02],\n",
       "                      [ 1.8196e-03, -4.4986e-03,  5.7760e-04,  ...,  1.6757e-02,\n",
       "                       -5.4818e-06, -6.5478e-03]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 6.6130e-04,  7.6634e-04,  7.9973e-04, -7.1497e-04],\n",
       "                      [ 9.9123e-04, -6.2169e-05,  3.3212e-04, -3.6396e-04],\n",
       "                      [ 7.2900e-04, -9.0470e-04,  7.2456e-04, -4.0759e-04],\n",
       "                      ...,\n",
       "                      [-3.3845e-04,  4.1085e-04, -2.6684e-04,  5.6053e-05],\n",
       "                      [-5.7091e-04,  1.4218e-04, -5.9606e-04,  9.1351e-04],\n",
       "                      [ 4.7485e-04, -2.5695e-05,  1.1794e-03, -1.2835e-03]])),\n",
       "             ('llm.base_model.model.model.layers.10.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0037, -0.0001, -0.0318,  ..., -0.0030,  0.0105,  0.0089],\n",
       "                      [ 0.0004, -0.0128,  0.0123,  ...,  0.0045,  0.0129,  0.0033],\n",
       "                      [ 0.0134, -0.0372, -0.0191,  ...,  0.0084, -0.0086, -0.0048],\n",
       "                      ...,\n",
       "                      [-0.0008,  0.0132, -0.0128,  ..., -0.0047,  0.0056,  0.0221],\n",
       "                      [ 0.0042, -0.0125, -0.0226,  ...,  0.0125,  0.0099,  0.0043],\n",
       "                      [ 0.0088, -0.0132, -0.0276,  ...,  0.0117,  0.0004,  0.0014]])),\n",
       "             ('llm.base_model.model.model.layers.10.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0324, -0.0441, -0.0260,  ..., -0.0043,  0.0008, -0.0106],\n",
       "                      [-0.0186, -0.0158, -0.0145,  ...,  0.0020,  0.0144,  0.0160],\n",
       "                      [-0.0148, -0.0205,  0.0103,  ...,  0.0306, -0.0012,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0470, -0.0022,  0.0113,  ...,  0.0085, -0.0312,  0.0201],\n",
       "                      [ 0.0067,  0.0198,  0.0190,  ...,  0.0050, -0.0132, -0.0032],\n",
       "                      [-0.0065, -0.0158, -0.0225,  ..., -0.0103,  0.0029, -0.0148]])),\n",
       "             ('llm.base_model.model.model.layers.10.mlp.up_proj.weight',\n",
       "              tensor([[-0.0422, -0.0034, -0.0369,  ...,  0.0106, -0.0084, -0.0231],\n",
       "                      [-0.0084,  0.0101,  0.0038,  ...,  0.0236,  0.0376, -0.0131],\n",
       "                      [-0.0002, -0.0023,  0.0121,  ...,  0.0242, -0.0315, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0212,  0.0235, -0.0011,  ..., -0.0432, -0.0013,  0.0008],\n",
       "                      [-0.0052, -0.0029, -0.0283,  ...,  0.0203, -0.0165,  0.0133],\n",
       "                      [-0.0007,  0.0142,  0.0052,  ...,  0.0019,  0.0072,  0.0144]])),\n",
       "             ('llm.base_model.model.model.layers.10.mlp.down_proj.weight',\n",
       "              tensor([[-8.7128e-03, -2.6901e-02, -3.1414e-03,  ...,  2.9678e-02,\n",
       "                       -1.7014e-02, -4.8161e-04],\n",
       "                      [-4.0245e-03,  1.9348e-02, -8.3694e-03,  ..., -8.9035e-03,\n",
       "                        9.6436e-03,  2.4915e-05],\n",
       "                      [-3.2623e-02, -2.2202e-03,  1.7609e-02,  ..., -2.3438e-02,\n",
       "                       -2.4124e-02,  8.7814e-03],\n",
       "                      ...,\n",
       "                      [ 1.4725e-02, -5.9776e-03,  3.0956e-03,  ...,  1.6174e-02,\n",
       "                        1.3290e-02,  9.1858e-03],\n",
       "                      [-1.0109e-03,  4.8767e-02, -1.5419e-02,  ...,  1.7029e-02,\n",
       "                        3.1311e-02, -3.3173e-02],\n",
       "                      [-4.7119e-02,  4.8470e-04, -2.9434e-02,  ..., -1.9012e-02,\n",
       "                       -1.3992e-02,  1.0826e-02]])),\n",
       "             ('llm.base_model.model.model.layers.10.input_layernorm.weight',\n",
       "              tensor([0.3635, 0.3601, 0.3198,  ..., 0.3403, 0.3479, 0.3374])),\n",
       "             ('llm.base_model.model.model.layers.10.post_attention_layernorm.weight',\n",
       "              tensor([0.2457, 0.2338, 0.2239,  ..., 0.2428, 0.2389, 0.2379])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0173,  0.0182, -0.0067,  ...,  0.0213, -0.0030, -0.0009],\n",
       "                      [-0.0123,  0.0078,  0.0109,  ...,  0.0153,  0.0138,  0.0005],\n",
       "                      [ 0.0023,  0.0073, -0.0236,  ..., -0.0023, -0.0104,  0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0003, -0.0052,  0.0320,  ...,  0.0350,  0.0393, -0.0300],\n",
       "                      [ 0.0417,  0.0175, -0.0120,  ..., -0.0082,  0.0162, -0.0289],\n",
       "                      [ 0.0736, -0.0205, -0.0206,  ..., -0.0211,  0.0462,  0.0585]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0019,  0.0096,  0.0125,  ...,  0.0091, -0.0054,  0.0001],\n",
       "                      [-0.0149, -0.0111, -0.0037,  ...,  0.0121, -0.0028,  0.0160],\n",
       "                      [-0.0083, -0.0075,  0.0047,  ..., -0.0073,  0.0092, -0.0018],\n",
       "                      [ 0.0023, -0.0043, -0.0058,  ..., -0.0022,  0.0114,  0.0083]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 0.0011, -0.0006,  0.0017, -0.0009],\n",
       "                      [-0.0009,  0.0005, -0.0018,  0.0009],\n",
       "                      [-0.0011,  0.0016, -0.0019,  0.0009],\n",
       "                      ...,\n",
       "                      [ 0.0005, -0.0010,  0.0009, -0.0009],\n",
       "                      [ 0.0001, -0.0008,  0.0007, -0.0008],\n",
       "                      [-0.0004,  0.0010, -0.0009,  0.0009]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0054,  0.0195,  0.0004,  ..., -0.0120,  0.0003, -0.0211],\n",
       "                      [-0.0005, -0.0028, -0.0247,  ..., -0.0099, -0.0028,  0.0260],\n",
       "                      [ 0.0134, -0.0257,  0.0073,  ...,  0.0075,  0.0046,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0090,  0.0196,  0.0037,  ..., -0.0196, -0.0127,  0.0287],\n",
       "                      [ 0.0638, -0.0111, -0.0122,  ..., -0.0043,  0.0063, -0.0076],\n",
       "                      [ 0.0071,  0.0056,  0.0187,  ..., -0.0070,  0.0601,  0.0230]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0053,  0.0043, -0.0104,  ..., -0.0210,  0.0011,  0.0047],\n",
       "                      [ 0.0023, -0.0067, -0.0121,  ...,  0.0068,  0.0061, -0.0250],\n",
       "                      [ 0.0021,  0.0086, -0.0070,  ...,  0.0144,  0.0042, -0.0229],\n",
       "                      ...,\n",
       "                      [-0.0147,  0.0049, -0.0134,  ...,  0.0057, -0.0185, -0.0037],\n",
       "                      [-0.0097,  0.0160, -0.0101,  ..., -0.0137, -0.0167,  0.0026],\n",
       "                      [ 0.0143, -0.0230,  0.0036,  ..., -0.0390, -0.0041, -0.0137]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0066,  0.0118,  0.0133,  ...,  0.0061, -0.0112,  0.0029],\n",
       "                      [ 0.0130, -0.0107,  0.0034,  ...,  0.0111, -0.0127, -0.0149],\n",
       "                      [-0.0029, -0.0045,  0.0047,  ...,  0.0095,  0.0039, -0.0043],\n",
       "                      [ 0.0127, -0.0078, -0.0051,  ...,  0.0163, -0.0044, -0.0145]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-4.6761e-04,  1.1758e-03,  2.2377e-04,  1.5930e-03],\n",
       "                      [ 7.9401e-04, -1.1513e-03, -8.1594e-04, -8.9779e-04],\n",
       "                      [ 1.3882e-03, -3.2345e-04,  7.9054e-05, -1.2535e-03],\n",
       "                      ...,\n",
       "                      [-4.6436e-04,  5.1214e-04,  1.2436e-03,  4.6357e-04],\n",
       "                      [ 8.8977e-04, -1.0440e-03, -8.4675e-04, -1.1561e-03],\n",
       "                      [-8.2935e-04,  7.3232e-04, -5.1564e-04,  8.9798e-04]])),\n",
       "             ('llm.base_model.model.model.layers.11.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0172,  0.0004,  0.0071,  ...,  0.0090,  0.0107,  0.0022],\n",
       "                      [ 0.0013, -0.0253,  0.0180,  ..., -0.0122,  0.0010, -0.0164],\n",
       "                      [-0.0085, -0.0044,  0.0190,  ...,  0.0013, -0.0014,  0.0184],\n",
       "                      ...,\n",
       "                      [ 0.0038, -0.0061,  0.0228,  ...,  0.0024,  0.0004, -0.0099],\n",
       "                      [ 0.0019,  0.0233,  0.0102,  ...,  0.0181,  0.0105, -0.0308],\n",
       "                      [-0.0047, -0.0032,  0.0026,  ..., -0.0057,  0.0024, -0.0136]])),\n",
       "             ('llm.base_model.model.model.layers.11.mlp.gate_proj.weight',\n",
       "              tensor([[-4.5135e-02, -1.0643e-02,  2.6550e-03,  ...,  4.9095e-03,\n",
       "                       -5.2757e-03,  3.7720e-02],\n",
       "                      [ 1.2624e-04, -1.1765e-02,  2.3621e-02,  ...,  1.2207e-02,\n",
       "                       -1.9562e-02, -4.2999e-02],\n",
       "                      [-7.6675e-04, -4.4464e-02, -3.7140e-02,  ..., -1.3714e-03,\n",
       "                       -4.2496e-03,  2.8572e-03],\n",
       "                      ...,\n",
       "                      [-1.7029e-02, -3.5431e-02, -1.7883e-02,  ..., -2.1038e-03,\n",
       "                       -2.7878e-02,  8.9312e-04],\n",
       "                      [ 2.1591e-03,  7.2823e-03, -2.5528e-02,  ..., -1.4450e-02,\n",
       "                        9.9564e-03, -7.2896e-05],\n",
       "                      [-5.7678e-03,  1.0826e-02,  1.1604e-02,  ...,  3.4882e-02,\n",
       "                       -3.4924e-03, -1.6724e-02]])),\n",
       "             ('llm.base_model.model.model.layers.11.mlp.up_proj.weight',\n",
       "              tensor([[-0.0116, -0.0006, -0.0263,  ...,  0.0275,  0.0043,  0.0307],\n",
       "                      [ 0.0164,  0.0004, -0.0196,  ...,  0.0098, -0.0421,  0.0039],\n",
       "                      [-0.0100, -0.0285, -0.0027,  ..., -0.0091, -0.0167,  0.0153],\n",
       "                      ...,\n",
       "                      [ 0.0415,  0.0135, -0.0065,  ..., -0.0032,  0.0016,  0.0210],\n",
       "                      [-0.0100,  0.0078,  0.0082,  ...,  0.0189,  0.0064,  0.0055],\n",
       "                      [-0.0002, -0.0024, -0.0092,  ..., -0.0138,  0.0076,  0.0270]])),\n",
       "             ('llm.base_model.model.model.layers.11.mlp.down_proj.weight',\n",
       "              tensor([[-0.0208,  0.0460,  0.0166,  ...,  0.0195,  0.0135, -0.0041],\n",
       "                      [-0.0162, -0.0060, -0.0257,  ..., -0.0309, -0.0086,  0.0158],\n",
       "                      [-0.0215, -0.0094,  0.0082,  ...,  0.0021, -0.0192, -0.0064],\n",
       "                      ...,\n",
       "                      [ 0.0182,  0.0239, -0.0128,  ...,  0.0016, -0.0002,  0.0105],\n",
       "                      [-0.0150, -0.0317, -0.0298,  ..., -0.0231, -0.0041,  0.0154],\n",
       "                      [ 0.0331,  0.0188,  0.0227,  ...,  0.0036, -0.0137,  0.0414]])),\n",
       "             ('llm.base_model.model.model.layers.11.input_layernorm.weight',\n",
       "              tensor([0.3962, 0.3914, 0.3618,  ..., 0.3848, 0.3774, 0.3674])),\n",
       "             ('llm.base_model.model.model.layers.11.post_attention_layernorm.weight',\n",
       "              tensor([0.2551, 0.2371, 0.2339,  ..., 0.2502, 0.2505, 0.2476])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0056, -0.0189,  0.0107,  ...,  0.0201, -0.0051,  0.0052],\n",
       "                      [ 0.0058,  0.0054,  0.0013,  ..., -0.0136,  0.0251,  0.0159],\n",
       "                      [ 0.0090,  0.0367, -0.0290,  ...,  0.0043,  0.0131, -0.0303],\n",
       "                      ...,\n",
       "                      [-0.0059,  0.0396, -0.0204,  ..., -0.0304, -0.0077,  0.0116],\n",
       "                      [ 0.0351, -0.0060,  0.0108,  ...,  0.0348,  0.0048, -0.0309],\n",
       "                      [ 0.0352,  0.0129, -0.0422,  ..., -0.0184,  0.0170,  0.0252]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 2.9329e-03,  7.7760e-03, -1.2119e-02,  ...,  9.9243e-03,\n",
       "                        5.1871e-03, -2.0530e-03],\n",
       "                      [-2.0629e-03, -3.1024e-03, -1.1416e-02,  ..., -6.0367e-05,\n",
       "                       -3.7066e-03,  1.1347e-02],\n",
       "                      [ 1.1319e-02, -7.6406e-03,  9.0861e-03,  ...,  2.8323e-04,\n",
       "                        3.8793e-03,  1.0789e-02],\n",
       "                      [ 3.6761e-03, -2.2671e-03,  3.9328e-03,  ...,  8.3900e-03,\n",
       "                        1.7911e-03,  4.4367e-03]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-1.2202e-03,  1.2565e-03, -1.1485e-03, -1.1266e-03],\n",
       "                      [-3.4814e-04,  1.8445e-03, -1.3421e-03, -1.1322e-04],\n",
       "                      [ 6.2530e-04, -1.1565e-03,  8.9803e-04,  6.4480e-04],\n",
       "                      ...,\n",
       "                      [ 5.6921e-04,  1.1406e-03, -9.5179e-04,  7.3546e-04],\n",
       "                      [-2.9736e-05, -8.1758e-05, -1.3528e-04,  2.0568e-04],\n",
       "                      [ 3.4201e-05, -7.9096e-04,  1.2360e-03,  1.6444e-04]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0141, -0.0032, -0.0030,  ...,  0.0160,  0.0038, -0.0064],\n",
       "                      [ 0.0037,  0.0163, -0.0063,  ...,  0.0122, -0.0161, -0.0207],\n",
       "                      [-0.0060, -0.0181,  0.0071,  ...,  0.0181, -0.0069,  0.0146],\n",
       "                      ...,\n",
       "                      [ 0.0150,  0.0279, -0.0182,  ..., -0.0375, -0.0160, -0.0208],\n",
       "                      [-0.0368,  0.0075,  0.0273,  ..., -0.0241,  0.0190, -0.0023],\n",
       "                      [-0.0005,  0.0344,  0.0105,  ...,  0.0126, -0.0459, -0.0329]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 4.9591e-03,  4.7607e-03,  3.0861e-03,  ..., -6.9962e-03,\n",
       "                        8.8272e-03, -1.8753e-02],\n",
       "                      [-2.6428e-02,  1.4923e-02, -3.0339e-05,  ..., -1.9943e-02,\n",
       "                       -6.9618e-04,  1.4404e-02],\n",
       "                      [-1.2352e-02, -1.0529e-02,  4.7836e-03,  ..., -1.9855e-03,\n",
       "                        4.2450e-02, -1.6434e-02],\n",
       "                      ...,\n",
       "                      [-2.8658e-04, -2.8973e-03, -1.8539e-02,  ..., -6.1302e-03,\n",
       "                       -1.3977e-02, -9.6083e-04],\n",
       "                      [ 1.4544e-05, -1.1459e-02, -5.8594e-03,  ...,  3.0823e-03,\n",
       "                        1.2253e-02,  5.2986e-03],\n",
       "                      [ 2.2415e-02,  2.0065e-03,  1.4572e-03,  ...,  2.0721e-02,\n",
       "                        7.8964e-03, -1.1360e-02]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0081,  0.0160,  0.0071,  ..., -0.0010, -0.0103,  0.0087],\n",
       "                      [-0.0034, -0.0037,  0.0086,  ..., -0.0116,  0.0073,  0.0061],\n",
       "                      [-0.0045, -0.0165,  0.0072,  ...,  0.0038, -0.0128, -0.0067],\n",
       "                      [-0.0064, -0.0130,  0.0137,  ..., -0.0031,  0.0119,  0.0123]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-1.1705e-03, -3.2796e-04, -7.9034e-05, -2.7822e-04],\n",
       "                      [ 1.2431e-03, -1.2644e-03, -7.8817e-04,  1.2179e-03],\n",
       "                      [-7.8389e-04, -7.4544e-04, -4.2090e-04, -1.7030e-04],\n",
       "                      ...,\n",
       "                      [ 1.2680e-04,  2.2192e-04, -3.8930e-04,  5.1048e-05],\n",
       "                      [-8.1206e-04,  4.0532e-04, -2.4409e-04,  8.8213e-06],\n",
       "                      [ 5.9722e-05, -1.4626e-04, -8.4009e-04,  8.5628e-04]])),\n",
       "             ('llm.base_model.model.model.layers.12.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0281,  0.0062, -0.0005,  ...,  0.0023,  0.0077, -0.0037],\n",
       "                      [-0.0072, -0.0087,  0.0018,  ..., -0.0126,  0.0068, -0.0199],\n",
       "                      [ 0.0029, -0.0042, -0.0042,  ...,  0.0072, -0.0281,  0.0116],\n",
       "                      ...,\n",
       "                      [ 0.0020, -0.0004,  0.0131,  ..., -0.0065, -0.0019,  0.0001],\n",
       "                      [-0.0102, -0.0326, -0.0289,  ..., -0.0046,  0.0100,  0.0182],\n",
       "                      [ 0.0175,  0.0052,  0.0114,  ...,  0.0200, -0.0113, -0.0184]])),\n",
       "             ('llm.base_model.model.model.layers.12.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0071, -0.0237,  0.0114,  ..., -0.0049,  0.0205,  0.0046],\n",
       "                      [-0.0251, -0.0269,  0.0149,  ...,  0.0138,  0.0140,  0.0150],\n",
       "                      [ 0.0052,  0.0234, -0.0055,  ..., -0.0096, -0.0421,  0.0011],\n",
       "                      ...,\n",
       "                      [-0.0006,  0.0100,  0.0120,  ..., -0.0242, -0.0006,  0.0214],\n",
       "                      [-0.0343, -0.0054,  0.0041,  ...,  0.0061,  0.0094, -0.0030],\n",
       "                      [ 0.0014, -0.0203, -0.0086,  ..., -0.0047, -0.0096, -0.0169]])),\n",
       "             ('llm.base_model.model.model.layers.12.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0030,  0.0160,  0.0074,  ..., -0.0047,  0.0172,  0.0181],\n",
       "                      [-0.0030, -0.0149, -0.0127,  ...,  0.0039, -0.0133,  0.0259],\n",
       "                      [ 0.0098, -0.0032,  0.0120,  ..., -0.0466,  0.0144,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0160, -0.0337, -0.0073,  ...,  0.0131, -0.0204,  0.0014],\n",
       "                      [ 0.0025, -0.0306, -0.0046,  ...,  0.0084,  0.0066, -0.0135],\n",
       "                      [-0.0090, -0.0168, -0.0059,  ...,  0.0375, -0.0031, -0.0336]])),\n",
       "             ('llm.base_model.model.model.layers.12.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0038, -0.0075, -0.0319,  ..., -0.0127,  0.0054,  0.0086],\n",
       "                      [ 0.0167, -0.0241,  0.0021,  ..., -0.0085, -0.0120, -0.0141],\n",
       "                      [ 0.0156,  0.0014,  0.0182,  ...,  0.0056, -0.0074, -0.0205],\n",
       "                      ...,\n",
       "                      [ 0.0167, -0.0136, -0.0443,  ...,  0.0381, -0.0184, -0.0175],\n",
       "                      [-0.0255,  0.0121,  0.0091,  ..., -0.0073,  0.0362, -0.0230],\n",
       "                      [ 0.0044,  0.0191,  0.0293,  ..., -0.0352,  0.0171, -0.0044]])),\n",
       "             ('llm.base_model.model.model.layers.12.input_layernorm.weight',\n",
       "              tensor([0.4031, 0.4004, 0.3665,  ..., 0.3767, 0.3821, 0.3840])),\n",
       "             ('llm.base_model.model.model.layers.12.post_attention_layernorm.weight',\n",
       "              tensor([0.2588, 0.2441, 0.2371,  ..., 0.2568, 0.2539, 0.2549])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0049, -0.0080, -0.0141,  ...,  0.0087, -0.0032, -0.0092],\n",
       "                      [-0.0148, -0.0115, -0.0008,  ..., -0.0031,  0.0078, -0.0033],\n",
       "                      [-0.0153,  0.0085,  0.0068,  ..., -0.0083, -0.0053,  0.0053],\n",
       "                      ...,\n",
       "                      [ 0.0431,  0.0039,  0.0015,  ...,  0.0483,  0.0192, -0.0458],\n",
       "                      [ 0.0044,  0.0106, -0.0215,  ...,  0.0119,  0.0128, -0.0082],\n",
       "                      [-0.0068, -0.0211, -0.0158,  ..., -0.0120,  0.0219, -0.0062]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0152,  0.0111,  0.0113,  ..., -0.0062, -0.0013,  0.0102],\n",
       "                      [ 0.0086, -0.0083,  0.0070,  ..., -0.0049, -0.0101,  0.0064],\n",
       "                      [ 0.0115, -0.0119, -0.0071,  ...,  0.0080, -0.0157,  0.0076],\n",
       "                      [-0.0029, -0.0150, -0.0005,  ..., -0.0048, -0.0052, -0.0152]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0009, -0.0010, -0.0006,  0.0008],\n",
       "                      [-0.0003,  0.0007, -0.0005,  0.0006],\n",
       "                      [-0.0005,  0.0007, -0.0007,  0.0003],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.0004, -0.0010,  0.0005],\n",
       "                      [-0.0007, -0.0008,  0.0009, -0.0012],\n",
       "                      [-0.0002, -0.0004, -0.0003,  0.0003]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.k_proj.weight',\n",
       "              tensor([[ 1.1314e-02,  5.2948e-03, -5.4741e-03,  ..., -1.7975e-02,\n",
       "                        2.8564e-02,  1.2146e-02],\n",
       "                      [ 1.0498e-02,  1.9608e-02, -3.2883e-03,  ...,  6.0883e-03,\n",
       "                        6.1188e-03,  3.1769e-05],\n",
       "                      [ 4.6120e-03, -8.1863e-03,  3.3295e-02,  ..., -7.4530e-04,\n",
       "                        1.4259e-02, -3.0212e-02],\n",
       "                      ...,\n",
       "                      [ 3.3295e-02,  3.4180e-02, -2.7580e-03,  ...,  7.3242e-03,\n",
       "                       -5.5542e-03, -1.5305e-02],\n",
       "                      [-3.4943e-03,  6.6795e-03,  2.8946e-02,  ..., -4.6265e-02,\n",
       "                       -1.6022e-02,  3.2959e-02],\n",
       "                      [-2.2369e-02, -4.8279e-02, -1.3115e-02,  ..., -3.2013e-02,\n",
       "                       -2.9785e-02,  7.7972e-03]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0147,  0.0038, -0.0121,  ..., -0.0022,  0.0119,  0.0164],\n",
       "                      [-0.0083,  0.0136, -0.0040,  ...,  0.0158, -0.0075, -0.0048],\n",
       "                      [ 0.0183,  0.0001, -0.0030,  ..., -0.0217,  0.0385, -0.0092],\n",
       "                      ...,\n",
       "                      [-0.0021,  0.0219, -0.0069,  ..., -0.0077,  0.0269, -0.0193],\n",
       "                      [-0.0114,  0.0110,  0.0143,  ...,  0.0006,  0.0319,  0.0082],\n",
       "                      [-0.0053, -0.0098,  0.0246,  ...,  0.0169, -0.0013,  0.0434]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0172,  0.0029,  0.0019,  ...,  0.0061, -0.0114, -0.0084],\n",
       "                      [-0.0055,  0.0070, -0.0043,  ...,  0.0115, -0.0118,  0.0164],\n",
       "                      [-0.0158, -0.0105,  0.0117,  ..., -0.0134, -0.0009,  0.0034],\n",
       "                      [-0.0124,  0.0008,  0.0131,  ...,  0.0135, -0.0129, -0.0067]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-1.4060e-03, -1.2091e-03,  1.0094e-03,  9.9528e-04],\n",
       "                      [ 7.0337e-05,  3.6210e-04, -2.5204e-04, -3.1005e-04],\n",
       "                      [-8.6757e-04,  3.2234e-05,  1.4732e-04, -7.5160e-05],\n",
       "                      ...,\n",
       "                      [-4.8637e-04, -1.2658e-03,  1.2679e-03,  1.3254e-03],\n",
       "                      [-9.2830e-04, -6.4771e-04,  3.5837e-04,  4.6057e-04],\n",
       "                      [ 7.5651e-04, -1.3201e-04,  1.5959e-04,  1.4513e-04]])),\n",
       "             ('llm.base_model.model.model.layers.13.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0044,  0.0007, -0.0055,  ...,  0.0002, -0.0048, -0.0037],\n",
       "                      [ 0.0246,  0.0106,  0.0044,  ..., -0.0120, -0.0086,  0.0049],\n",
       "                      [ 0.0072,  0.0100,  0.0007,  ...,  0.0056, -0.0256, -0.0104],\n",
       "                      ...,\n",
       "                      [-0.0069,  0.0093,  0.0146,  ..., -0.0117, -0.0080, -0.0159],\n",
       "                      [ 0.0033,  0.0016,  0.0297,  ..., -0.0010, -0.0244, -0.0257],\n",
       "                      [ 0.0114,  0.0058,  0.0087,  ...,  0.0142, -0.0071, -0.0201]])),\n",
       "             ('llm.base_model.model.model.layers.13.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0206,  0.0071, -0.0061,  ...,  0.0075,  0.0062, -0.0138],\n",
       "                      [-0.0252,  0.0374,  0.0206,  ...,  0.0390, -0.0057, -0.0230],\n",
       "                      [ 0.0069, -0.0223, -0.0115,  ...,  0.0023, -0.0172, -0.0124],\n",
       "                      ...,\n",
       "                      [ 0.0205, -0.0107,  0.0152,  ..., -0.0064,  0.0173,  0.0157],\n",
       "                      [ 0.0217, -0.0015,  0.0107,  ...,  0.0150,  0.0051, -0.0269],\n",
       "                      [ 0.0044,  0.0371,  0.0215,  ..., -0.0043,  0.0191,  0.0283]])),\n",
       "             ('llm.base_model.model.model.layers.13.mlp.up_proj.weight',\n",
       "              tensor([[-0.0347,  0.0224, -0.0075,  ...,  0.0045,  0.0149, -0.0011],\n",
       "                      [ 0.0137, -0.0090,  0.0348,  ...,  0.0399,  0.0282,  0.0049],\n",
       "                      [ 0.0197, -0.0281,  0.0196,  ..., -0.0051,  0.0024, -0.0037],\n",
       "                      ...,\n",
       "                      [-0.0043,  0.0020,  0.0239,  ...,  0.0079, -0.0274,  0.0136],\n",
       "                      [-0.0085, -0.0191,  0.0078,  ...,  0.0154,  0.0561,  0.0035],\n",
       "                      [ 0.0093, -0.0249,  0.0144,  ..., -0.0207, -0.0020,  0.0223]])),\n",
       "             ('llm.base_model.model.model.layers.13.mlp.down_proj.weight',\n",
       "              tensor([[-0.0086, -0.0014, -0.0068,  ...,  0.0324, -0.0304, -0.0241],\n",
       "                      [-0.0106,  0.0540, -0.0474,  ..., -0.0078,  0.0013, -0.0103],\n",
       "                      [-0.0002, -0.0044,  0.0183,  ...,  0.0065, -0.0291, -0.0062],\n",
       "                      ...,\n",
       "                      [ 0.0133, -0.0006,  0.0280,  ...,  0.0073, -0.0205,  0.0345],\n",
       "                      [ 0.0096,  0.0034,  0.0131,  ..., -0.0070,  0.0111, -0.0125],\n",
       "                      [-0.0003, -0.0300,  0.0334,  ...,  0.0058,  0.0056,  0.0354]])),\n",
       "             ('llm.base_model.model.model.layers.13.input_layernorm.weight',\n",
       "              tensor([0.4143, 0.4026, 0.3711,  ..., 0.3857, 0.3809, 0.3916])),\n",
       "             ('llm.base_model.model.model.layers.13.post_attention_layernorm.weight',\n",
       "              tensor([0.2642, 0.2502, 0.2450,  ..., 0.2637, 0.2678, 0.2607])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0062,  0.0006,  0.0211,  ..., -0.0058,  0.0091,  0.0312],\n",
       "                      [ 0.0045,  0.0118, -0.0107,  ..., -0.0360, -0.0146, -0.0292],\n",
       "                      [-0.0040, -0.0068,  0.0091,  ...,  0.0134,  0.0100, -0.0286],\n",
       "                      ...,\n",
       "                      [-0.0134, -0.0022, -0.0296,  ..., -0.0051,  0.0132, -0.0064],\n",
       "                      [ 0.0231, -0.0372,  0.0538,  ..., -0.0128,  0.0097, -0.0049],\n",
       "                      [-0.0119, -0.0006, -0.0107,  ...,  0.0132,  0.0153, -0.0486]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0116,  0.0016, -0.0018,  ..., -0.0065,  0.0055, -0.0090],\n",
       "                      [ 0.0138, -0.0095,  0.0122,  ...,  0.0073, -0.0037, -0.0124],\n",
       "                      [ 0.0152,  0.0095,  0.0033,  ..., -0.0010,  0.0049,  0.0071],\n",
       "                      [ 0.0044, -0.0167, -0.0159,  ...,  0.0086,  0.0037, -0.0049]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.2499e-04,  4.9056e-04,  3.1374e-04,  5.4108e-04],\n",
       "                      [-1.7087e-03,  4.9651e-05,  6.8778e-04, -1.7368e-03],\n",
       "                      [ 1.4940e-03, -1.0069e-03, -1.2803e-03,  1.5450e-03],\n",
       "                      ...,\n",
       "                      [-1.1376e-03,  1.2118e-03,  1.3815e-03, -1.0459e-03],\n",
       "                      [ 6.6028e-04, -7.2826e-04, -6.6058e-04,  6.1582e-04],\n",
       "                      [-1.7258e-03,  9.2733e-04,  1.1333e-03, -2.1696e-03]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0108, -0.0038,  0.0098,  ..., -0.0082,  0.0200,  0.0408],\n",
       "                      [ 0.0283,  0.0257, -0.0202,  ..., -0.0055, -0.0178,  0.0063],\n",
       "                      [-0.0202,  0.0010,  0.0229,  ...,  0.0234,  0.0122, -0.0011],\n",
       "                      ...,\n",
       "                      [-0.0301,  0.0082,  0.0271,  ..., -0.0006, -0.0052, -0.0211],\n",
       "                      [-0.0285,  0.0049,  0.0143,  ..., -0.0356, -0.0051,  0.0005],\n",
       "                      [-0.0164,  0.0307,  0.0236,  ...,  0.0656,  0.0157, -0.0337]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 7.0915e-03,  5.0583e-03, -4.0955e-02,  ..., -2.8717e-02,\n",
       "                       -5.2948e-03,  1.3725e-02],\n",
       "                      [-2.5558e-03, -1.8936e-02,  6.0654e-04,  ...,  5.6305e-03,\n",
       "                       -1.6317e-03,  9.6262e-05],\n",
       "                      [ 2.5558e-02, -1.7899e-02, -4.6253e-05,  ..., -6.0310e-03,\n",
       "                        7.8049e-03,  1.1574e-02],\n",
       "                      ...,\n",
       "                      [ 1.6953e-02, -1.3733e-02,  1.5114e-02,  ...,  1.9928e-02,\n",
       "                       -1.1681e-02,  3.9043e-03],\n",
       "                      [-1.6037e-02,  2.7206e-02, -3.3569e-02,  ...,  4.6768e-03,\n",
       "                       -6.5956e-03, -3.0807e-02],\n",
       "                      [ 8.2703e-03,  2.2919e-02, -2.2675e-02,  ..., -8.3084e-03,\n",
       "                       -9.0408e-03,  1.8158e-02]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-5.9532e-03,  2.5865e-04, -1.3217e-03,  ..., -1.3203e-02,\n",
       "                        4.8771e-03, -6.4267e-03],\n",
       "                      [ 1.2329e-02, -1.3548e-02,  3.2232e-03,  ...,  1.1092e-02,\n",
       "                       -9.7606e-03, -4.4135e-03],\n",
       "                      [-1.3715e-02,  1.2774e-02,  3.2398e-03,  ..., -6.5953e-04,\n",
       "                        5.1020e-03, -1.4420e-03],\n",
       "                      [-5.7585e-03,  1.3416e-02,  7.4858e-03,  ...,  7.4267e-05,\n",
       "                       -1.1296e-02, -2.5188e-03]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-4.8991e-05,  7.1827e-04,  7.5916e-04, -6.8017e-04],\n",
       "                      [-1.4397e-03, -8.9342e-04, -1.5623e-03,  1.3914e-03],\n",
       "                      [-9.7535e-04, -1.3598e-03, -1.0872e-03,  9.6101e-04],\n",
       "                      ...,\n",
       "                      [-8.6031e-04, -8.7536e-04, -2.3826e-04,  4.6209e-04],\n",
       "                      [-1.1020e-03, -2.0669e-03, -9.7474e-04,  1.4686e-03],\n",
       "                      [-7.5223e-04, -1.5796e-03, -1.0683e-03,  1.3083e-03]])),\n",
       "             ('llm.base_model.model.model.layers.14.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0099,  0.0071, -0.0208,  ..., -0.0029,  0.0037, -0.0113],\n",
       "                      [ 0.0012,  0.0285,  0.0086,  ...,  0.0208, -0.0086, -0.0005],\n",
       "                      [ 0.0042,  0.0067, -0.0036,  ...,  0.0032,  0.0215,  0.0111],\n",
       "                      ...,\n",
       "                      [ 0.0224, -0.0049,  0.0039,  ..., -0.0146, -0.0018,  0.0095],\n",
       "                      [-0.0025, -0.0021, -0.0183,  ..., -0.0027,  0.0367,  0.0181],\n",
       "                      [-0.0105, -0.0114, -0.0146,  ..., -0.0073,  0.0047,  0.0015]])),\n",
       "             ('llm.base_model.model.model.layers.14.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0152,  0.0082, -0.0112,  ...,  0.0048, -0.0173, -0.0083],\n",
       "                      [ 0.0206,  0.0062, -0.0425,  ...,  0.0384,  0.0179, -0.0104],\n",
       "                      [ 0.0030,  0.0128,  0.0078,  ..., -0.0125,  0.0045, -0.0109],\n",
       "                      ...,\n",
       "                      [ 0.0080,  0.0175, -0.0188,  ..., -0.0058, -0.0075, -0.0040],\n",
       "                      [-0.0081,  0.0161,  0.0216,  ..., -0.0154,  0.0144,  0.0086],\n",
       "                      [ 0.0140, -0.0002,  0.0203,  ..., -0.0065, -0.0293,  0.0219]])),\n",
       "             ('llm.base_model.model.model.layers.14.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0013,  0.0115,  0.0187,  ..., -0.0269,  0.0081,  0.0083],\n",
       "                      [ 0.0286,  0.0141, -0.0276,  ...,  0.0133,  0.0213,  0.0135],\n",
       "                      [ 0.0004,  0.0033,  0.0324,  ..., -0.0009,  0.0193, -0.0054],\n",
       "                      ...,\n",
       "                      [-0.0149,  0.0079, -0.0481,  ..., -0.0068, -0.0048, -0.0059],\n",
       "                      [-0.0257,  0.0231, -0.0065,  ..., -0.0113,  0.0229, -0.0167],\n",
       "                      [ 0.0047,  0.0247,  0.0108,  ...,  0.0106, -0.0133,  0.0070]])),\n",
       "             ('llm.base_model.model.model.layers.14.mlp.down_proj.weight',\n",
       "              tensor([[ 8.6441e-03,  2.3804e-02,  6.9084e-03,  ..., -3.2104e-02,\n",
       "                       -9.3842e-03, -2.1191e-03],\n",
       "                      [ 1.8539e-02,  2.3315e-02, -1.7441e-02,  ...,  7.3471e-03,\n",
       "                        2.2173e-05,  1.6022e-02],\n",
       "                      [ 2.3842e-03, -4.3335e-02,  2.0294e-02,  ..., -1.1969e-03,\n",
       "                       -2.8488e-02,  1.2062e-02],\n",
       "                      ...,\n",
       "                      [-2.8172e-03,  1.9669e-02, -1.0849e-02,  ..., -6.1111e-03,\n",
       "                       -1.8097e-02, -1.6876e-02],\n",
       "                      [ 1.5533e-02,  3.3539e-02,  3.1494e-02,  ..., -5.9280e-03,\n",
       "                       -1.5106e-02,  3.2379e-02],\n",
       "                      [-2.1591e-02,  1.1330e-02, -1.3268e-02,  ..., -3.1677e-02,\n",
       "                        9.7733e-03,  1.6296e-02]])),\n",
       "             ('llm.base_model.model.model.layers.14.input_layernorm.weight',\n",
       "              tensor([0.4160, 0.4272, 0.3772,  ..., 0.4065, 0.3977, 0.3894])),\n",
       "             ('llm.base_model.model.model.layers.14.post_attention_layernorm.weight',\n",
       "              tensor([0.2727, 0.2620, 0.2605,  ..., 0.2776, 0.2734, 0.2703])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0060, -0.0188, -0.0072,  ...,  0.0101, -0.0085,  0.0125],\n",
       "                      [ 0.0260, -0.0217,  0.0092,  ..., -0.0021,  0.0045,  0.0073],\n",
       "                      [ 0.0070, -0.0070,  0.0040,  ...,  0.0156, -0.0023, -0.0118],\n",
       "                      ...,\n",
       "                      [-0.0464, -0.0336,  0.0103,  ..., -0.0118, -0.0112,  0.0301],\n",
       "                      [-0.0179, -0.0545,  0.0184,  ...,  0.0153, -0.0072,  0.0045],\n",
       "                      [ 0.0197,  0.0185,  0.0282,  ..., -0.0008, -0.0208, -0.0170]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-7.6842e-03,  1.6996e-02,  5.0994e-03,  ..., -8.9539e-04,\n",
       "                       -1.6806e-02,  1.4382e-02],\n",
       "                      [-9.8895e-05, -8.5807e-03,  1.3559e-02,  ...,  1.5763e-02,\n",
       "                       -2.8976e-03,  1.4260e-03],\n",
       "                      [-2.4516e-03,  9.8012e-03,  6.8953e-03,  ...,  2.5208e-03,\n",
       "                        9.6962e-03,  3.8635e-03],\n",
       "                      [ 1.6872e-02,  1.6247e-02,  2.2125e-03,  ..., -1.1318e-02,\n",
       "                       -5.0827e-03,  1.6632e-02]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 4.4237e-04, -4.3923e-04,  4.2138e-04, -4.5968e-04],\n",
       "                      [ 4.1264e-04, -8.6383e-05,  6.5696e-04, -5.4906e-04],\n",
       "                      [ 3.8415e-04, -5.9655e-04,  7.7340e-04, -8.0806e-04],\n",
       "                      ...,\n",
       "                      [-7.0552e-04, -7.6283e-04,  7.8899e-04, -7.3905e-04],\n",
       "                      [ 6.5045e-04,  5.7252e-04, -4.9947e-04,  5.7007e-04],\n",
       "                      [ 5.7194e-04,  1.0225e-03, -1.1159e-03,  8.3899e-04]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0217, -0.0050, -0.0101,  ..., -0.0055,  0.0048,  0.0025],\n",
       "                      [ 0.0128, -0.0094, -0.0074,  ...,  0.0030,  0.0041, -0.0140],\n",
       "                      [ 0.0043,  0.0046, -0.0034,  ..., -0.0060,  0.0134, -0.0095],\n",
       "                      ...,\n",
       "                      [-0.0464, -0.0503,  0.0267,  ...,  0.0111,  0.0084, -0.0084],\n",
       "                      [ 0.0087,  0.0049,  0.0110,  ...,  0.0292, -0.0133,  0.0170],\n",
       "                      [-0.0228, -0.0087,  0.0324,  ..., -0.0005, -0.0198, -0.0036]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0079, -0.0005,  0.0048,  ...,  0.0088,  0.0109,  0.0163],\n",
       "                      [-0.0112, -0.0079,  0.0157,  ...,  0.0179,  0.0031,  0.0232],\n",
       "                      [ 0.0054, -0.0367, -0.0069,  ..., -0.0323,  0.0071,  0.0032],\n",
       "                      ...,\n",
       "                      [-0.0048, -0.0043,  0.0135,  ...,  0.0094,  0.0210, -0.0164],\n",
       "                      [ 0.0056,  0.0040, -0.0273,  ...,  0.0123,  0.0164, -0.0035],\n",
       "                      [ 0.0253,  0.0044,  0.0197,  ..., -0.0219,  0.0019,  0.0071]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0059,  0.0090, -0.0133,  ...,  0.0111,  0.0138,  0.0039],\n",
       "                      [ 0.0081, -0.0010, -0.0066,  ..., -0.0137, -0.0058,  0.0174],\n",
       "                      [-0.0115,  0.0039,  0.0071,  ..., -0.0064, -0.0109,  0.0177],\n",
       "                      [ 0.0014, -0.0004,  0.0006,  ..., -0.0079,  0.0057, -0.0013]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-5.6894e-04, -7.5493e-04, -1.0670e-04,  9.8107e-04],\n",
       "                      [ 3.1937e-04, -1.1526e-03, -9.6226e-04,  6.9365e-04],\n",
       "                      [ 5.6786e-04,  1.2680e-03,  9.5520e-04, -1.4483e-03],\n",
       "                      ...,\n",
       "                      [-9.0596e-04,  5.7293e-06,  1.7495e-04, -1.6371e-04],\n",
       "                      [-1.7420e-04, -1.2434e-03, -1.2884e-03,  1.1811e-03],\n",
       "                      [-3.0415e-04, -8.1872e-04, -7.8276e-04,  8.4376e-04]])),\n",
       "             ('llm.base_model.model.model.layers.15.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0019,  0.0071, -0.0149,  ...,  0.0144, -0.0099,  0.0234],\n",
       "                      [-0.0061, -0.0068, -0.0255,  ...,  0.0117, -0.0334,  0.0190],\n",
       "                      [ 0.0063, -0.0083, -0.0042,  ...,  0.0034, -0.0029,  0.0051],\n",
       "                      ...,\n",
       "                      [-0.0089, -0.0243,  0.0143,  ..., -0.0078, -0.0248, -0.0093],\n",
       "                      [-0.0034, -0.0058, -0.0011,  ...,  0.0133,  0.0027, -0.0052],\n",
       "                      [-0.0244,  0.0035,  0.0257,  ..., -0.0057, -0.0349, -0.0281]])),\n",
       "             ('llm.base_model.model.model.layers.15.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0116,  0.0300, -0.0143,  ...,  0.0121, -0.0230,  0.0282],\n",
       "                      [ 0.0094, -0.0085,  0.0334,  ..., -0.0128,  0.0102,  0.0106],\n",
       "                      [ 0.0070, -0.0110, -0.0102,  ...,  0.0263, -0.0521, -0.0162],\n",
       "                      ...,\n",
       "                      [-0.0102,  0.0014,  0.0323,  ..., -0.0066,  0.0119,  0.0090],\n",
       "                      [-0.0074, -0.0173,  0.0064,  ..., -0.0096, -0.0147, -0.0371],\n",
       "                      [-0.0004, -0.0162,  0.0015,  ...,  0.0008, -0.0004,  0.0063]])),\n",
       "             ('llm.base_model.model.model.layers.15.mlp.up_proj.weight',\n",
       "              tensor([[-0.0128, -0.0131,  0.0240,  ...,  0.0189,  0.0178, -0.0469],\n",
       "                      [-0.0148,  0.0345,  0.0316,  ...,  0.0041,  0.0033,  0.0043],\n",
       "                      [-0.0434, -0.0017, -0.0087,  ..., -0.0063,  0.0143, -0.0101],\n",
       "                      ...,\n",
       "                      [-0.0120, -0.0215, -0.0091,  ...,  0.0090,  0.0032, -0.0055],\n",
       "                      [ 0.0387, -0.0086,  0.0146,  ..., -0.0091,  0.0169,  0.0024],\n",
       "                      [-0.0054, -0.0211, -0.0213,  ...,  0.0044, -0.0165, -0.0022]])),\n",
       "             ('llm.base_model.model.model.layers.15.mlp.down_proj.weight',\n",
       "              tensor([[-0.0116, -0.0144, -0.0281,  ...,  0.0235,  0.0114, -0.0116],\n",
       "                      [ 0.0051, -0.0150, -0.0247,  ..., -0.0115, -0.0227,  0.0183],\n",
       "                      [ 0.0408,  0.0492, -0.0250,  ..., -0.0116,  0.0359,  0.0190],\n",
       "                      ...,\n",
       "                      [-0.0130, -0.0432,  0.0109,  ...,  0.0069, -0.0023,  0.0046],\n",
       "                      [-0.0345, -0.0182, -0.0017,  ..., -0.0293, -0.0174,  0.0040],\n",
       "                      [ 0.0026,  0.0300, -0.0097,  ..., -0.0120, -0.0284, -0.0231]])),\n",
       "             ('llm.base_model.model.model.layers.15.input_layernorm.weight',\n",
       "              tensor([0.4080, 0.4021, 0.3777,  ..., 0.3853, 0.3843, 0.3904])),\n",
       "             ('llm.base_model.model.model.layers.15.post_attention_layernorm.weight',\n",
       "              tensor([0.2861, 0.2712, 0.2732,  ..., 0.2861, 0.2827, 0.2805])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0101,  0.0085, -0.0218,  ...,  0.0065,  0.0255, -0.0068],\n",
       "                      [ 0.0203, -0.0418,  0.0191,  ...,  0.0158,  0.0083, -0.0220],\n",
       "                      [-0.0137,  0.0005,  0.0040,  ..., -0.0225, -0.0081, -0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0250, -0.0316,  0.0005,  ..., -0.0223,  0.0247, -0.0187],\n",
       "                      [-0.0152, -0.0107,  0.0264,  ...,  0.0018, -0.0191,  0.0139],\n",
       "                      [ 0.0062,  0.0160,  0.0168,  ..., -0.0058, -0.0277, -0.0115]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0002, -0.0101,  0.0050,  ..., -0.0100,  0.0029, -0.0023],\n",
       "                      [-0.0059,  0.0108, -0.0043,  ...,  0.0031, -0.0160, -0.0078],\n",
       "                      [-0.0041, -0.0045,  0.0081,  ...,  0.0048,  0.0070,  0.0033],\n",
       "                      [ 0.0044,  0.0074,  0.0132,  ...,  0.0110, -0.0039, -0.0100]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 0.0014, -0.0013,  0.0013,  0.0014],\n",
       "                      [-0.0006,  0.0004, -0.0004, -0.0006],\n",
       "                      [ 0.0009, -0.0009,  0.0007,  0.0007],\n",
       "                      ...,\n",
       "                      [-0.0008,  0.0009, -0.0008, -0.0005],\n",
       "                      [-0.0003,  0.0004, -0.0004, -0.0002],\n",
       "                      [-0.0008,  0.0009, -0.0008, -0.0007]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0191,  0.0183,  0.0089,  ...,  0.0070,  0.0182,  0.0234],\n",
       "                      [ 0.0222, -0.0350,  0.0084,  ..., -0.0011, -0.0270, -0.0019],\n",
       "                      [ 0.0297, -0.0037, -0.0149,  ..., -0.0211,  0.0033, -0.0380],\n",
       "                      ...,\n",
       "                      [ 0.0160,  0.0108, -0.0127,  ..., -0.0223, -0.0249, -0.0552],\n",
       "                      [ 0.0173,  0.0109,  0.0117,  ...,  0.0268,  0.0141,  0.0131],\n",
       "                      [-0.0375,  0.0529,  0.0639,  ..., -0.0011, -0.0166,  0.0322]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0098,  0.0017, -0.0062,  ...,  0.0083, -0.0013, -0.0060],\n",
       "                      [-0.0560, -0.0067, -0.0066,  ...,  0.0064,  0.0171, -0.0290],\n",
       "                      [-0.0042, -0.0037, -0.0055,  ..., -0.0244,  0.0431,  0.0157],\n",
       "                      ...,\n",
       "                      [ 0.0086, -0.0020,  0.0140,  ..., -0.0145,  0.0065,  0.0189],\n",
       "                      [-0.0204,  0.0012,  0.0056,  ...,  0.0340, -0.0031,  0.0132],\n",
       "                      [ 0.0145,  0.0100,  0.0079,  ..., -0.0100, -0.0002, -0.0316]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0072, -0.0129,  0.0161,  ..., -0.0109,  0.0063, -0.0085],\n",
       "                      [-0.0079, -0.0016, -0.0056,  ...,  0.0053, -0.0144, -0.0098],\n",
       "                      [ 0.0107,  0.0136,  0.0173,  ..., -0.0109,  0.0008,  0.0081],\n",
       "                      [-0.0073,  0.0122, -0.0035,  ..., -0.0096,  0.0044,  0.0162]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0013, -0.0010, -0.0010, -0.0002],\n",
       "                      [-0.0004, -0.0003, -0.0003, -0.0006],\n",
       "                      [ 0.0008,  0.0009,  0.0008,  0.0006],\n",
       "                      ...,\n",
       "                      [-0.0014, -0.0023, -0.0010,  0.0018],\n",
       "                      [ 0.0007, -0.0005,  0.0007, -0.0008],\n",
       "                      [-0.0012, -0.0009, -0.0009,  0.0012]])),\n",
       "             ('llm.base_model.model.model.layers.16.self_attn.o_proj.weight',\n",
       "              tensor([[ 4.5044e-02,  5.2309e-04, -1.9684e-02,  ...,  5.4970e-03,\n",
       "                       -1.4633e-02,  4.7231e-04],\n",
       "                      [-2.4857e-02,  9.9564e-03, -2.5482e-02,  ..., -5.5656e-03,\n",
       "                       -8.7023e-04, -1.3905e-03],\n",
       "                      [-2.9526e-02, -8.8577e-03, -6.8474e-03,  ...,  2.5826e-03,\n",
       "                        2.8397e-02,  1.2291e-02],\n",
       "                      ...,\n",
       "                      [-5.8289e-03, -1.7258e-02,  7.8087e-03,  ...,  6.2523e-03,\n",
       "                       -2.0477e-02, -3.2306e-05],\n",
       "                      [-4.6196e-03,  2.3270e-02,  3.2501e-02,  ..., -3.7098e-03,\n",
       "                        8.7585e-03, -1.4854e-02],\n",
       "                      [-1.7670e-02,  4.6043e-03,  3.1357e-03,  ..., -2.6083e-04,\n",
       "                       -4.1313e-03,  1.1225e-03]])),\n",
       "             ('llm.base_model.model.model.layers.16.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0191, -0.0182, -0.0221,  ...,  0.0057, -0.0046,  0.0118],\n",
       "                      [ 0.0306,  0.0174, -0.0087,  ...,  0.0121,  0.0073,  0.0173],\n",
       "                      [-0.0099,  0.0173, -0.0032,  ...,  0.0073, -0.0026, -0.0249],\n",
       "                      ...,\n",
       "                      [-0.0039,  0.0191,  0.0035,  ...,  0.0226,  0.0242,  0.0067],\n",
       "                      [ 0.0025, -0.0058,  0.0107,  ...,  0.0180,  0.0188,  0.0213],\n",
       "                      [ 0.0329,  0.0202,  0.0359,  ..., -0.0360,  0.0232, -0.0118]])),\n",
       "             ('llm.base_model.model.model.layers.16.mlp.up_proj.weight',\n",
       "              tensor([[-0.0381,  0.0113,  0.0043,  ...,  0.0193, -0.0149,  0.0062],\n",
       "                      [ 0.0133, -0.0153,  0.0087,  ...,  0.0177, -0.0239, -0.0095],\n",
       "                      [-0.0092, -0.0212, -0.0069,  ..., -0.0115,  0.0091,  0.0246],\n",
       "                      ...,\n",
       "                      [ 0.0043,  0.0233, -0.0092,  ...,  0.0010, -0.0096, -0.0173],\n",
       "                      [-0.0136,  0.0229, -0.0202,  ...,  0.0108, -0.0161,  0.0129],\n",
       "                      [ 0.0026,  0.0032, -0.0035,  ..., -0.0003, -0.0248, -0.0221]])),\n",
       "             ('llm.base_model.model.model.layers.16.mlp.down_proj.weight',\n",
       "              tensor([[-0.0209, -0.0030,  0.0189,  ...,  0.0292, -0.0043,  0.0029],\n",
       "                      [-0.0225, -0.0014, -0.0110,  ...,  0.0275,  0.0015, -0.0013],\n",
       "                      [-0.0150,  0.0036, -0.0119,  ...,  0.0227, -0.0066, -0.0062],\n",
       "                      ...,\n",
       "                      [ 0.0139, -0.0230, -0.0242,  ...,  0.0107,  0.0161,  0.0023],\n",
       "                      [ 0.0153,  0.0046, -0.0112,  ..., -0.0132, -0.0130, -0.0057],\n",
       "                      [ 0.0104, -0.0158, -0.0262,  ...,  0.0281,  0.0039, -0.0143]])),\n",
       "             ('llm.base_model.model.model.layers.16.input_layernorm.weight',\n",
       "              tensor([0.4106, 0.4165, 0.3870,  ..., 0.3872, 0.4033, 0.4016])),\n",
       "             ('llm.base_model.model.model.layers.16.post_attention_layernorm.weight',\n",
       "              tensor([0.3030, 0.2900, 0.2932,  ..., 0.3035, 0.3076, 0.2996])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-1.4900e-02, -1.3527e-02,  1.3657e-02,  ..., -8.6594e-03,\n",
       "                       -1.0094e-02, -3.7975e-03],\n",
       "                      [ 1.0498e-02, -9.1171e-03,  1.6373e-02,  ..., -1.7023e-03,\n",
       "                       -2.2217e-02,  1.4677e-03],\n",
       "                      [-1.3939e-02, -1.5688e-03, -1.0994e-02,  ...,  1.8280e-02,\n",
       "                       -1.0208e-02,  6.2585e-05],\n",
       "                      ...,\n",
       "                      [ 3.6865e-02, -2.9297e-02,  5.5481e-02,  ..., -1.4114e-02,\n",
       "                       -1.6937e-02,  1.2436e-02],\n",
       "                      [ 2.1667e-02, -2.3941e-02,  4.6906e-02,  ...,  1.2619e-02,\n",
       "                       -1.6357e-02, -6.1646e-02],\n",
       "                      [ 1.8234e-02, -1.0201e-02,  1.3733e-02,  ...,  2.8641e-02,\n",
       "                        2.0065e-03,  5.7709e-02]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-1.5500e-02, -1.4675e-02, -8.0519e-03,  ..., -1.0231e-02,\n",
       "                        5.9125e-03,  7.2091e-05],\n",
       "                      [-4.4949e-03, -1.0006e-04,  1.0484e-02,  ...,  3.4591e-03,\n",
       "                       -9.4665e-03,  1.1797e-02],\n",
       "                      [-5.8777e-03, -9.6162e-03,  1.0122e-02,  ..., -5.6315e-03,\n",
       "                       -1.3068e-02, -8.1413e-03],\n",
       "                      [ 1.3491e-02, -6.1217e-03,  6.1693e-03,  ...,  1.6927e-02,\n",
       "                        2.0853e-03,  7.9847e-03]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.0260e-03,  6.7397e-04, -1.0808e-03, -9.6264e-04],\n",
       "                      [-7.8573e-04, -4.7894e-04,  7.7127e-04,  8.7073e-04],\n",
       "                      [ 2.2329e-04,  3.8217e-04, -4.4999e-05, -4.2948e-06],\n",
       "                      ...,\n",
       "                      [-1.4959e-03, -1.5881e-03,  1.7579e-03,  1.3907e-03],\n",
       "                      [ 8.3337e-04,  1.7112e-04, -5.3053e-04, -5.7351e-04],\n",
       "                      [ 7.3431e-04,  1.6968e-03, -1.0184e-03, -9.7818e-04]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0125,  0.0040,  0.0060,  ..., -0.0030,  0.0143,  0.0070],\n",
       "                      [ 0.0065,  0.0096,  0.0049,  ...,  0.0129, -0.0030, -0.0115],\n",
       "                      [ 0.0039, -0.0087,  0.0042,  ...,  0.0212, -0.0092, -0.0106],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.0606, -0.0138,  ..., -0.0140,  0.0521, -0.0709],\n",
       "                      [ 0.0252,  0.0225,  0.0134,  ..., -0.0149, -0.0230, -0.0203],\n",
       "                      [-0.0394, -0.0452, -0.0019,  ...,  0.0318,  0.0245, -0.0072]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0136,  0.0078,  0.0070,  ...,  0.0233, -0.0071, -0.0043],\n",
       "                      [-0.0025, -0.0122, -0.0087,  ...,  0.0093, -0.0239, -0.0148],\n",
       "                      [ 0.0133,  0.0091, -0.0014,  ...,  0.0040, -0.0084, -0.0247],\n",
       "                      ...,\n",
       "                      [ 0.0088, -0.0049,  0.0145,  ...,  0.0087,  0.0052, -0.0156],\n",
       "                      [ 0.0172,  0.0038, -0.0400,  ..., -0.0238,  0.0012, -0.0310],\n",
       "                      [-0.0100, -0.0070, -0.0011,  ...,  0.0093,  0.0115,  0.0090]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0132,  0.0152, -0.0162,  ...,  0.0097, -0.0013,  0.0047],\n",
       "                      [ 0.0120,  0.0129, -0.0126,  ..., -0.0105, -0.0009, -0.0101],\n",
       "                      [-0.0142, -0.0137, -0.0010,  ..., -0.0156,  0.0101,  0.0071],\n",
       "                      [-0.0069, -0.0050, -0.0102,  ..., -0.0068,  0.0108, -0.0141]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 2.1291e-04,  2.8305e-04, -1.1954e-04,  2.8496e-04],\n",
       "                      [-1.0054e-03, -9.9715e-04, -4.9840e-05, -8.7656e-04],\n",
       "                      [ 1.1531e-03,  1.0312e-03,  4.4314e-05,  9.5298e-04],\n",
       "                      ...,\n",
       "                      [ 1.2012e-03,  1.3586e-03,  5.4846e-04,  1.1708e-03],\n",
       "                      [-6.5216e-04, -9.3369e-04,  2.3153e-04, -8.5907e-04],\n",
       "                      [-3.0258e-04, -1.8711e-04,  5.0661e-04, -2.3998e-04]])),\n",
       "             ('llm.base_model.model.model.layers.17.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0031, -0.0055,  0.0058,  ..., -0.0188,  0.0042, -0.0098],\n",
       "                      [-0.0153, -0.0235,  0.0232,  ...,  0.0263, -0.0078,  0.0219],\n",
       "                      [ 0.0123, -0.0142, -0.0044,  ..., -0.0165, -0.0028, -0.0172],\n",
       "                      ...,\n",
       "                      [-0.0095,  0.0119, -0.0175,  ..., -0.0269, -0.0308, -0.0203],\n",
       "                      [-0.0108,  0.0115, -0.0045,  ..., -0.0219, -0.0030,  0.0114],\n",
       "                      [-0.0197, -0.0104,  0.0126,  ...,  0.0310, -0.0185,  0.0141]])),\n",
       "             ('llm.base_model.model.model.layers.17.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0347,  0.0237,  0.0143,  ...,  0.0066, -0.0060,  0.0058],\n",
       "                      [-0.0039,  0.0323,  0.0149,  ...,  0.0159, -0.0018,  0.0084],\n",
       "                      [ 0.0138,  0.0125, -0.0238,  ...,  0.0041,  0.0239, -0.0045],\n",
       "                      ...,\n",
       "                      [-0.0117, -0.0114, -0.0159,  ..., -0.0080, -0.0143, -0.0058],\n",
       "                      [ 0.0055, -0.0023,  0.0011,  ...,  0.0050,  0.0394, -0.0036],\n",
       "                      [-0.0026,  0.0200,  0.0140,  ..., -0.0139,  0.0097, -0.0034]])),\n",
       "             ('llm.base_model.model.model.layers.17.mlp.up_proj.weight',\n",
       "              tensor([[-5.5466e-03, -2.3804e-02, -8.2016e-03,  ...,  8.8196e-03,\n",
       "                        1.3260e-02, -1.5198e-02],\n",
       "                      [-2.1027e-02,  1.7288e-02,  1.9455e-02,  ..., -3.9597e-03,\n",
       "                       -2.2964e-03,  7.6027e-03],\n",
       "                      [-4.8161e-05, -1.1473e-03, -5.0850e-03,  ...,  1.1528e-02,\n",
       "                       -2.1347e-02,  1.1528e-02],\n",
       "                      ...,\n",
       "                      [ 1.1230e-02,  1.5961e-02,  8.0719e-03,  ...,  8.0109e-03,\n",
       "                       -1.1818e-02, -1.1444e-02],\n",
       "                      [-9.7580e-03, -1.8829e-02, -1.1658e-02,  ..., -5.0125e-03,\n",
       "                       -1.9943e-02,  7.0419e-03],\n",
       "                      [ 5.7526e-03,  4.6043e-03, -1.1873e-03,  ...,  2.7466e-03,\n",
       "                       -3.6804e-02, -1.4778e-02]])),\n",
       "             ('llm.base_model.model.model.layers.17.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0241, -0.0194,  0.0072,  ...,  0.0060, -0.0072, -0.0058],\n",
       "                      [ 0.0238,  0.0230,  0.0157,  ...,  0.0030, -0.0109,  0.0299],\n",
       "                      [-0.0264, -0.0175, -0.0115,  ...,  0.0100, -0.0095,  0.0046],\n",
       "                      ...,\n",
       "                      [ 0.0072, -0.0179, -0.0079,  ..., -0.0126, -0.0002, -0.0275],\n",
       "                      [ 0.0049,  0.0015, -0.0067,  ..., -0.0194, -0.0258,  0.0225],\n",
       "                      [ 0.0015, -0.0213,  0.0171,  ..., -0.0301, -0.0104,  0.0025]])),\n",
       "             ('llm.base_model.model.model.layers.17.input_layernorm.weight',\n",
       "              tensor([0.4258, 0.4268, 0.4019,  ..., 0.4204, 0.4236, 0.4055])),\n",
       "             ('llm.base_model.model.model.layers.17.post_attention_layernorm.weight',\n",
       "              tensor([0.3208, 0.3142, 0.3110,  ..., 0.3208, 0.3242, 0.3145])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0090,  0.0055,  0.0033,  ..., -0.0112, -0.0428,  0.0060],\n",
       "                      [ 0.0019, -0.0094,  0.0137,  ..., -0.0056,  0.0170,  0.0425],\n",
       "                      [ 0.0050, -0.0184, -0.0170,  ..., -0.0005, -0.0105,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0317,  0.0150, -0.0058,  ...,  0.0264,  0.0068,  0.0163],\n",
       "                      [ 0.0665, -0.0162, -0.0271,  ...,  0.0557,  0.0332,  0.0116],\n",
       "                      [ 0.0270,  0.0165, -0.0005,  ...,  0.0211,  0.0446, -0.0475]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0011, -0.0148,  0.0054,  ..., -0.0050,  0.0132,  0.0064],\n",
       "                      [ 0.0120, -0.0122,  0.0120,  ...,  0.0030, -0.0002, -0.0043],\n",
       "                      [-0.0024,  0.0137,  0.0120,  ...,  0.0154,  0.0054,  0.0147],\n",
       "                      [ 0.0030, -0.0022,  0.0017,  ..., -0.0081,  0.0108, -0.0104]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0010,  0.0007,  0.0009,  0.0010],\n",
       "                      [-0.0008,  0.0009,  0.0008,  0.0008],\n",
       "                      [-0.0012,  0.0013,  0.0006,  0.0008],\n",
       "                      ...,\n",
       "                      [ 0.0009, -0.0011, -0.0010,  0.0002],\n",
       "                      [ 0.0010, -0.0012, -0.0005,  0.0005],\n",
       "                      [ 0.0007, -0.0003, -0.0006,  0.0002]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0124,  0.0271, -0.0110,  ...,  0.0155, -0.0137, -0.0239],\n",
       "                      [ 0.0084, -0.0174,  0.0105,  ...,  0.0206,  0.0242,  0.0012],\n",
       "                      [ 0.0098, -0.0012,  0.0034,  ...,  0.0330, -0.0133,  0.0249],\n",
       "                      ...,\n",
       "                      [-0.1091, -0.0204, -0.0670,  ...,  0.0235, -0.0018, -0.0451],\n",
       "                      [ 0.0473,  0.0404, -0.0120,  ...,  0.0414,  0.0678, -0.0352],\n",
       "                      [-0.0461, -0.0447, -0.0476,  ...,  0.0324, -0.0138, -0.0282]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0264,  0.0158, -0.0214,  ...,  0.0016,  0.0285,  0.0092],\n",
       "                      [ 0.0121,  0.0040, -0.0063,  ..., -0.0209,  0.0372,  0.0019],\n",
       "                      [-0.0039,  0.0112, -0.0051,  ...,  0.0086, -0.0021, -0.0107],\n",
       "                      ...,\n",
       "                      [ 0.0140,  0.0143, -0.0046,  ..., -0.0042, -0.0194, -0.0060],\n",
       "                      [ 0.0012, -0.0034,  0.0024,  ...,  0.0114,  0.0093,  0.0328],\n",
       "                      [-0.0018,  0.0074,  0.0064,  ..., -0.0045, -0.0119, -0.0028]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-9.7998e-03, -8.6083e-03, -4.9991e-03,  ...,  1.6232e-02,\n",
       "                       -4.1783e-03, -2.1749e-03],\n",
       "                      [ 6.5794e-05, -7.6920e-03, -7.2199e-03,  ..., -2.3808e-03,\n",
       "                        3.2547e-03, -2.2158e-03],\n",
       "                      [-1.1872e-02, -1.4616e-03,  1.4474e-02,  ..., -2.1102e-04,\n",
       "                        1.2232e-02,  1.3182e-02],\n",
       "                      [-1.9204e-03, -6.5809e-04, -8.6003e-03,  ..., -9.6788e-03,\n",
       "                       -4.7213e-03,  5.3768e-03]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 0.0008,  0.0018,  0.0004,  0.0015],\n",
       "                      [-0.0010, -0.0010, -0.0009, -0.0010],\n",
       "                      [-0.0010, -0.0010, -0.0007, -0.0010],\n",
       "                      ...,\n",
       "                      [ 0.0014,  0.0009,  0.0005,  0.0010],\n",
       "                      [-0.0012, -0.0002, -0.0012, -0.0013],\n",
       "                      [-0.0016,  0.0002,  0.0013, -0.0014]])),\n",
       "             ('llm.base_model.model.model.layers.18.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0173,  0.0121, -0.0142,  ...,  0.0089,  0.0290,  0.0177],\n",
       "                      [-0.0047, -0.0345,  0.0077,  ...,  0.0036, -0.0074, -0.0273],\n",
       "                      [-0.0050, -0.0171,  0.0151,  ...,  0.0265,  0.0179,  0.0308],\n",
       "                      ...,\n",
       "                      [-0.0340, -0.0151, -0.0243,  ...,  0.0200,  0.0123,  0.0054],\n",
       "                      [ 0.0215,  0.0542,  0.0140,  ...,  0.0092, -0.0069, -0.0334],\n",
       "                      [-0.0147, -0.0459, -0.0186,  ..., -0.0136,  0.0087, -0.0155]])),\n",
       "             ('llm.base_model.model.model.layers.18.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0137, -0.0059,  0.0112,  ..., -0.0002,  0.0153,  0.0017],\n",
       "                      [-0.0397,  0.0089, -0.0168,  ..., -0.0045, -0.0121, -0.0016],\n",
       "                      [-0.0205,  0.0082,  0.0397,  ..., -0.0241, -0.0020,  0.0032],\n",
       "                      ...,\n",
       "                      [-0.0380, -0.0290, -0.0301,  ..., -0.0262, -0.0195, -0.0215],\n",
       "                      [ 0.0050,  0.0215,  0.0200,  ..., -0.0104, -0.0013,  0.0089],\n",
       "                      [ 0.0037, -0.0029,  0.0062,  ...,  0.0075, -0.0061,  0.0019]])),\n",
       "             ('llm.base_model.model.model.layers.18.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0108,  0.0088,  0.0324,  ...,  0.0047,  0.0179, -0.0106],\n",
       "                      [-0.0130,  0.0286, -0.0324,  ..., -0.0020, -0.0016,  0.0078],\n",
       "                      [-0.0232, -0.0111,  0.0096,  ...,  0.0136,  0.0162,  0.0238],\n",
       "                      ...,\n",
       "                      [-0.0002,  0.0099,  0.0080,  ...,  0.0186, -0.0041,  0.0059],\n",
       "                      [-0.0076, -0.0012, -0.0103,  ...,  0.0179,  0.0233,  0.0366],\n",
       "                      [ 0.0079,  0.0248,  0.0100,  ..., -0.0146,  0.0167,  0.0117]])),\n",
       "             ('llm.base_model.model.model.layers.18.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0236,  0.0099, -0.0320,  ...,  0.0381,  0.0128,  0.0164],\n",
       "                      [ 0.0219,  0.0069,  0.0242,  ..., -0.0050, -0.0027, -0.0046],\n",
       "                      [ 0.0063, -0.0198, -0.0339,  ...,  0.0161, -0.0027,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0093,  0.0120,  0.0172,  ...,  0.0222,  0.0019, -0.0089],\n",
       "                      [-0.0200,  0.0038,  0.0157,  ...,  0.0088,  0.0346,  0.0005],\n",
       "                      [ 0.0002,  0.0222,  0.0180,  ..., -0.0079,  0.0213,  0.0143]])),\n",
       "             ('llm.base_model.model.model.layers.18.input_layernorm.weight',\n",
       "              tensor([0.4490, 0.4497, 0.4285,  ..., 0.4316, 0.4429, 0.4263])),\n",
       "             ('llm.base_model.model.model.layers.18.post_attention_layernorm.weight',\n",
       "              tensor([0.3406, 0.3311, 0.3298,  ..., 0.3369, 0.3398, 0.3359])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0027,  0.0070, -0.0097,  ..., -0.0176, -0.0069,  0.0140],\n",
       "                      [-0.0053, -0.0087,  0.0029,  ..., -0.0035,  0.0273, -0.0064],\n",
       "                      [ 0.0059,  0.0230,  0.0063,  ...,  0.0102,  0.0203,  0.0019],\n",
       "                      ...,\n",
       "                      [-0.0246, -0.0196, -0.0039,  ..., -0.0431, -0.0007,  0.0275],\n",
       "                      [ 0.0067,  0.0369,  0.0241,  ...,  0.0557,  0.0148, -0.0279],\n",
       "                      [-0.0138,  0.0276,  0.0525,  ..., -0.0033, -0.0397, -0.0141]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0068,  0.0132,  0.0140,  ..., -0.0019,  0.0028, -0.0069],\n",
       "                      [-0.0044,  0.0070,  0.0108,  ..., -0.0062, -0.0034,  0.0046],\n",
       "                      [-0.0150, -0.0095, -0.0134,  ...,  0.0014, -0.0126, -0.0146],\n",
       "                      [ 0.0052,  0.0120,  0.0007,  ...,  0.0121, -0.0128,  0.0058]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-6.4919e-04, -5.8774e-04, -4.2902e-04, -1.8498e-04],\n",
       "                      [ 3.0793e-04, -1.9579e-04, -4.6942e-04,  7.1611e-04],\n",
       "                      [-6.6561e-05,  1.2603e-03, -4.0155e-04,  1.0861e-03],\n",
       "                      ...,\n",
       "                      [-3.2851e-04,  1.6198e-04, -1.4345e-04,  9.4416e-05],\n",
       "                      [ 1.8224e-04,  6.8653e-04,  4.5584e-04,  8.8887e-04],\n",
       "                      [ 1.0879e-03, -8.8450e-04,  1.0604e-03, -8.5749e-04]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0181,  0.0110,  0.0013,  ..., -0.0069,  0.0009, -0.0159],\n",
       "                      [-0.0205,  0.0231, -0.0186,  ...,  0.0164,  0.0046,  0.0146],\n",
       "                      [-0.0211,  0.0072, -0.0179,  ...,  0.0013,  0.0125,  0.0174],\n",
       "                      ...,\n",
       "                      [-0.0014,  0.0426, -0.0137,  ..., -0.0178,  0.0220, -0.0311],\n",
       "                      [-0.0712, -0.0330, -0.0033,  ...,  0.0192,  0.0126, -0.0130],\n",
       "                      [-0.0174,  0.0077, -0.0207,  ..., -0.0216,  0.0144,  0.0358]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0034, -0.0063, -0.0027,  ...,  0.0065, -0.0053,  0.0076],\n",
       "                      [ 0.0010,  0.0220,  0.0002,  ...,  0.0364, -0.0156,  0.0015],\n",
       "                      [-0.0461, -0.0263, -0.0040,  ..., -0.0048, -0.0087,  0.0118],\n",
       "                      ...,\n",
       "                      [ 0.0011, -0.0380, -0.0019,  ...,  0.0004,  0.0056, -0.0195],\n",
       "                      [ 0.0149, -0.0030, -0.0234,  ..., -0.0097, -0.0093, -0.0050],\n",
       "                      [-0.0014,  0.0244, -0.0003,  ..., -0.0264, -0.0138,  0.0149]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0002,  0.0069, -0.0137,  ...,  0.0058, -0.0156,  0.0073],\n",
       "                      [-0.0046, -0.0145, -0.0019,  ...,  0.0135, -0.0035, -0.0132],\n",
       "                      [-0.0100,  0.0019,  0.0013,  ..., -0.0140,  0.0036,  0.0016],\n",
       "                      [ 0.0085, -0.0118, -0.0135,  ..., -0.0057, -0.0129, -0.0152]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 7.6854e-05, -5.3913e-04,  3.0224e-04,  4.4127e-04],\n",
       "                      [ 1.0588e-03, -3.4147e-04, -3.7198e-04, -4.3615e-04],\n",
       "                      [-3.6008e-04,  1.8155e-05,  1.5857e-04, -5.9066e-05],\n",
       "                      ...,\n",
       "                      [-7.4302e-04, -8.0616e-04,  8.9721e-04,  6.6015e-04],\n",
       "                      [ 3.1086e-04,  3.1991e-04, -1.7446e-04,  8.5675e-05],\n",
       "                      [ 9.1032e-04,  1.1292e-03, -1.3595e-03, -1.0634e-03]])),\n",
       "             ('llm.base_model.model.model.layers.19.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0206, -0.0557,  0.0238,  ...,  0.0013,  0.0026, -0.0238],\n",
       "                      [ 0.0262, -0.0074,  0.0047,  ..., -0.0133,  0.0079, -0.0045],\n",
       "                      [-0.0037, -0.0130, -0.0254,  ...,  0.0044,  0.0102, -0.0016],\n",
       "                      ...,\n",
       "                      [ 0.0143, -0.0057, -0.0064,  ...,  0.0099, -0.0184,  0.0116],\n",
       "                      [ 0.0075, -0.0029, -0.0131,  ..., -0.0087, -0.0183, -0.0002],\n",
       "                      [ 0.0084,  0.0207,  0.0090,  ..., -0.0177, -0.0109,  0.0134]])),\n",
       "             ('llm.base_model.model.model.layers.19.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0132,  0.0065,  0.0077,  ...,  0.0030,  0.0039, -0.0025],\n",
       "                      [ 0.0092,  0.0197,  0.0047,  ...,  0.0043,  0.0136, -0.0366],\n",
       "                      [-0.0058, -0.0052, -0.0189,  ..., -0.0392, -0.0091,  0.0156],\n",
       "                      ...,\n",
       "                      [ 0.0009,  0.0009,  0.0023,  ..., -0.0208, -0.0030,  0.0005],\n",
       "                      [-0.0488,  0.0019, -0.0028,  ..., -0.0043, -0.0218,  0.0147],\n",
       "                      [-0.0241, -0.0242,  0.0120,  ..., -0.0008,  0.0084,  0.0024]])),\n",
       "             ('llm.base_model.model.model.layers.19.mlp.up_proj.weight',\n",
       "              tensor([[ 9.0301e-05, -7.9041e-03,  8.2169e-03,  ...,  3.3302e-03,\n",
       "                        1.0979e-02,  5.7793e-03],\n",
       "                      [-9.3536e-03, -1.2169e-03, -8.9188e-03,  ...,  2.3392e-02,\n",
       "                       -2.0782e-02, -1.2192e-02],\n",
       "                      [ 1.6159e-02,  6.5384e-03,  1.8661e-02,  ..., -1.5884e-02,\n",
       "                       -1.2138e-02,  5.0751e-02],\n",
       "                      ...,\n",
       "                      [ 1.1505e-02,  1.5411e-02, -6.7139e-03,  ...,  1.9958e-02,\n",
       "                       -1.5930e-02,  3.7048e-02],\n",
       "                      [ 4.1122e-03,  2.6199e-02,  3.6438e-02,  ..., -1.5480e-02,\n",
       "                        3.2379e-02, -1.2917e-02],\n",
       "                      [ 2.9564e-03, -1.8951e-02, -1.2505e-02,  ..., -3.1948e-03,\n",
       "                        1.5516e-03,  1.0086e-02]])),\n",
       "             ('llm.base_model.model.model.layers.19.mlp.down_proj.weight',\n",
       "              tensor([[-4.1695e-03, -1.8997e-02,  5.4893e-03,  ...,  4.0016e-03,\n",
       "                       -1.6464e-02,  1.8402e-02],\n",
       "                      [-9.5062e-03, -4.0802e-02, -2.6978e-02,  ...,  8.6517e-03,\n",
       "                        8.0109e-03, -7.9269e-03],\n",
       "                      [-2.1576e-02, -1.9211e-02,  2.6489e-02,  ...,  5.3253e-03,\n",
       "                       -8.3313e-03,  7.4844e-03],\n",
       "                      ...,\n",
       "                      [-8.8120e-03, -3.4389e-03,  1.7395e-02,  ...,  1.5381e-02,\n",
       "                        1.9058e-02,  5.6922e-05],\n",
       "                      [ 6.8283e-03, -1.3748e-02, -4.3030e-02,  ...,  2.5635e-02,\n",
       "                       -7.9422e-03, -1.4847e-02],\n",
       "                      [ 8.8120e-03, -6.1569e-03, -2.8473e-02,  ...,  1.4858e-03,\n",
       "                        7.8430e-03,  7.6180e-03]])),\n",
       "             ('llm.base_model.model.model.layers.19.input_layernorm.weight',\n",
       "              tensor([0.4529, 0.4556, 0.4390,  ..., 0.4280, 0.4324, 0.4377])),\n",
       "             ('llm.base_model.model.model.layers.19.post_attention_layernorm.weight',\n",
       "              tensor([0.3545, 0.3391, 0.3430,  ..., 0.3494, 0.3508, 0.3479])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0028, -0.0044,  0.0170,  ...,  0.0110,  0.0010, -0.0233],\n",
       "                      [ 0.0043, -0.0217,  0.0115,  ..., -0.0075, -0.0094,  0.0080],\n",
       "                      [ 0.0024, -0.0061, -0.0092,  ...,  0.0130, -0.0003, -0.0048],\n",
       "                      ...,\n",
       "                      [-0.0245, -0.0408,  0.0106,  ..., -0.0012,  0.0228,  0.0065],\n",
       "                      [-0.0681, -0.0190,  0.0127,  ...,  0.0072,  0.0185,  0.0057],\n",
       "                      [ 0.0180, -0.0010, -0.0063,  ..., -0.0149, -0.0090, -0.0028]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0009,  0.0005,  0.0099,  ...,  0.0165,  0.0123,  0.0080],\n",
       "                      [-0.0138, -0.0137,  0.0044,  ..., -0.0057,  0.0055, -0.0086],\n",
       "                      [ 0.0138, -0.0069, -0.0096,  ..., -0.0026, -0.0016, -0.0148],\n",
       "                      [-0.0100,  0.0093,  0.0084,  ..., -0.0110,  0.0039, -0.0094]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0008,  0.0005,  0.0006, -0.0006],\n",
       "                      [-0.0008,  0.0007,  0.0009, -0.0006],\n",
       "                      [-0.0014,  0.0015,  0.0013, -0.0015],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.0009, -0.0009, -0.0003],\n",
       "                      [ 0.0010, -0.0005, -0.0001,  0.0007],\n",
       "                      [ 0.0011, -0.0012, -0.0011,  0.0010]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0053,  0.0061,  0.0064,  ..., -0.0020,  0.0011,  0.0061],\n",
       "                      [ 0.0021,  0.0094,  0.0030,  ..., -0.0005, -0.0030,  0.0121],\n",
       "                      [ 0.0069,  0.0056, -0.0063,  ..., -0.0038,  0.0048,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0007, -0.0036, -0.0225,  ..., -0.0220,  0.0232,  0.0285],\n",
       "                      [-0.0170,  0.0202, -0.0032,  ...,  0.0223,  0.0210,  0.0594],\n",
       "                      [-0.0139, -0.0259, -0.0113,  ...,  0.0275, -0.0279,  0.0484]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-3.2120e-03, -1.4183e-02,  1.6174e-02,  ..., -2.6379e-03,\n",
       "                        1.2787e-02,  1.2039e-02],\n",
       "                      [-7.0915e-03, -4.3060e-02, -3.7980e-04,  ..., -1.1826e-02,\n",
       "                       -2.6488e-04,  1.1612e-02],\n",
       "                      [-8.0948e-03, -1.2390e-02,  3.6001e-04,  ..., -1.8951e-02,\n",
       "                       -7.7009e-05,  3.9339e-04],\n",
       "                      ...,\n",
       "                      [ 6.8741e-03, -8.2092e-03, -3.7975e-03,  ...,  2.0462e-02,\n",
       "                       -4.1885e-03,  6.1035e-03],\n",
       "                      [ 1.7776e-02,  1.0605e-02, -1.0307e-02,  ...,  3.0537e-03,\n",
       "                        1.5320e-02, -9.2545e-03],\n",
       "                      [ 1.4400e-03, -5.7564e-03,  2.4765e-02,  ..., -7.6141e-03,\n",
       "                       -1.1787e-02, -4.1046e-02]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0130,  0.0020,  0.0074,  ..., -0.0093, -0.0041,  0.0060],\n",
       "                      [ 0.0083, -0.0081,  0.0096,  ...,  0.0113, -0.0012, -0.0037],\n",
       "                      [ 0.0003, -0.0044, -0.0117,  ...,  0.0127,  0.0104, -0.0040],\n",
       "                      [-0.0113,  0.0031, -0.0150,  ...,  0.0104,  0.0113,  0.0164]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.0502e-04,  1.3209e-04,  3.8766e-04, -5.9487e-05],\n",
       "                      [ 1.4170e-03, -1.4799e-03, -1.5212e-03,  9.3850e-04],\n",
       "                      [ 9.4578e-04, -9.7087e-04, -1.0725e-03,  8.5661e-04],\n",
       "                      ...,\n",
       "                      [-9.4997e-04,  5.3634e-05,  1.2771e-03, -8.2490e-04],\n",
       "                      [ 2.4153e-04, -1.4780e-03, -2.3788e-04,  3.6761e-04],\n",
       "                      [ 1.0532e-03, -1.4990e-03, -1.6400e-03,  1.3247e-03]])),\n",
       "             ('llm.base_model.model.model.layers.20.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0071,  0.0038,  0.0302,  ..., -0.0039,  0.0173, -0.0101],\n",
       "                      [ 0.0104, -0.0114, -0.0078,  ...,  0.0016, -0.0124,  0.0211],\n",
       "                      [ 0.0121, -0.0027, -0.0127,  ..., -0.0264,  0.0004,  0.0074],\n",
       "                      ...,\n",
       "                      [-0.0125,  0.0019,  0.0050,  ...,  0.0144, -0.0168,  0.0116],\n",
       "                      [ 0.0034,  0.0132, -0.0171,  ...,  0.0120, -0.0256,  0.0025],\n",
       "                      [ 0.0189, -0.0255, -0.0043,  ...,  0.0155, -0.0222,  0.0113]])),\n",
       "             ('llm.base_model.model.model.layers.20.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0008, -0.0063, -0.0228,  ...,  0.0232, -0.0110,  0.0142],\n",
       "                      [-0.0190,  0.0052, -0.0115,  ..., -0.0030, -0.0116,  0.0178],\n",
       "                      [-0.0123, -0.0087,  0.0584,  ..., -0.0182,  0.0223, -0.0032],\n",
       "                      ...,\n",
       "                      [ 0.0017, -0.0060,  0.0248,  ..., -0.0233,  0.0064, -0.0003],\n",
       "                      [ 0.0101,  0.0076,  0.0122,  ...,  0.0209, -0.0004,  0.0131],\n",
       "                      [-0.0072, -0.0254, -0.0158,  ..., -0.0007, -0.0273, -0.0056]])),\n",
       "             ('llm.base_model.model.model.layers.20.mlp.up_proj.weight',\n",
       "              tensor([[-0.0599, -0.0024,  0.0018,  ...,  0.0134, -0.0121, -0.0110],\n",
       "                      [-0.0099,  0.0047, -0.0094,  ..., -0.0454, -0.0175,  0.0360],\n",
       "                      [ 0.0133,  0.0321,  0.0151,  ...,  0.0091, -0.0201,  0.0097],\n",
       "                      ...,\n",
       "                      [-0.0131,  0.0252, -0.0103,  ..., -0.0170, -0.0038,  0.0022],\n",
       "                      [ 0.0163, -0.0284, -0.0168,  ...,  0.0044, -0.0245, -0.0386],\n",
       "                      [ 0.0146, -0.0242,  0.0283,  ..., -0.0089, -0.0200, -0.0091]])),\n",
       "             ('llm.base_model.model.model.layers.20.mlp.down_proj.weight',\n",
       "              tensor([[-0.0030,  0.0248, -0.0044,  ..., -0.0090, -0.0119, -0.0307],\n",
       "                      [ 0.0014,  0.0177, -0.0073,  ...,  0.0088, -0.0201,  0.0247],\n",
       "                      [-0.0100,  0.0130, -0.0220,  ..., -0.0066,  0.0216, -0.0179],\n",
       "                      ...,\n",
       "                      [-0.0326,  0.0287,  0.0037,  ...,  0.0124, -0.0023, -0.0021],\n",
       "                      [-0.0113,  0.0062, -0.0184,  ..., -0.0106,  0.0179, -0.0122],\n",
       "                      [ 0.0114, -0.0027,  0.0024,  ..., -0.0005, -0.0076, -0.0042]])),\n",
       "             ('llm.base_model.model.model.layers.20.input_layernorm.weight',\n",
       "              tensor([0.4541, 0.4683, 0.4390,  ..., 0.4355, 0.4365, 0.4475])),\n",
       "             ('llm.base_model.model.model.layers.20.post_attention_layernorm.weight',\n",
       "              tensor([0.3643, 0.3596, 0.3533,  ..., 0.3655, 0.3611, 0.3582])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0172, -0.0046,  0.0137,  ..., -0.0048,  0.0047, -0.0059],\n",
       "                      [ 0.0162, -0.0042, -0.0049,  ...,  0.0102,  0.0026,  0.0198],\n",
       "                      [-0.0112, -0.0078,  0.0004,  ...,  0.0276, -0.0067,  0.0023],\n",
       "                      ...,\n",
       "                      [ 0.0025, -0.0080,  0.0297,  ..., -0.0105, -0.0496,  0.0107],\n",
       "                      [-0.0132,  0.0182,  0.0195,  ...,  0.0258,  0.0349, -0.0049],\n",
       "                      [-0.0748, -0.0100, -0.0069,  ..., -0.0095,  0.0160, -0.0411]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 9.1786e-03, -5.0588e-03, -8.3193e-03,  ...,  6.0026e-03,\n",
       "                       -4.7712e-03, -4.3443e-03],\n",
       "                      [ 6.5255e-03, -2.9030e-03,  9.6160e-03,  ..., -7.6029e-03,\n",
       "                       -5.9937e-03,  6.0098e-03],\n",
       "                      [-1.0302e-02, -8.2131e-03, -2.5503e-03,  ...,  2.0120e-05,\n",
       "                       -8.8363e-03, -8.1830e-03],\n",
       "                      [ 1.2911e-02, -1.6923e-03,  1.2028e-02,  ...,  8.1052e-03,\n",
       "                        7.9760e-03,  5.6403e-03]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-3.4391e-04, -8.2113e-04, -5.9973e-04, -7.9063e-04],\n",
       "                      [-2.9504e-04, -6.3003e-04,  6.9314e-05, -6.4778e-04],\n",
       "                      [-5.3083e-04,  2.9268e-04,  2.8974e-04, -8.4774e-05],\n",
       "                      ...,\n",
       "                      [ 2.3762e-04, -2.2280e-04, -3.5359e-04, -3.2902e-04],\n",
       "                      [ 7.9127e-04, -8.3431e-04, -3.4936e-04, -5.4053e-04],\n",
       "                      [-7.7704e-04,  7.4077e-04,  7.0806e-04,  8.4874e-04]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.k_proj.weight',\n",
       "              tensor([[ 4.4746e-03,  1.0208e-02,  5.2719e-03,  ...,  9.7504e-03,\n",
       "                        9.9361e-05,  4.3449e-03],\n",
       "                      [-2.3861e-03,  1.0574e-02,  1.5434e-02,  ...,  7.7705e-03,\n",
       "                        4.9362e-03,  1.3390e-02],\n",
       "                      [ 1.0880e-02,  4.2763e-03,  3.1677e-02,  ...,  1.5976e-02,\n",
       "                       -1.3914e-03,  5.4779e-03],\n",
       "                      ...,\n",
       "                      [-2.0065e-02,  2.0676e-02,  5.3825e-03,  ...,  2.0325e-02,\n",
       "                       -3.4729e-02,  4.5380e-02],\n",
       "                      [ 3.5405e-05,  5.2376e-03, -1.3214e-02,  ..., -1.7517e-02,\n",
       "                        2.9770e-02, -5.9166e-03],\n",
       "                      [-2.3239e-02,  5.7220e-03, -2.0706e-02,  ...,  1.7347e-03,\n",
       "                       -2.0798e-02,  6.1157e-02]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0015,  0.0061, -0.0017,  ..., -0.0050,  0.0197, -0.0251],\n",
       "                      [-0.0295,  0.0266, -0.0062,  ...,  0.0214, -0.0205,  0.0267],\n",
       "                      [ 0.0219,  0.0017, -0.0024,  ..., -0.0211,  0.0197, -0.0081],\n",
       "                      ...,\n",
       "                      [-0.0056, -0.0251,  0.0344,  ...,  0.0034, -0.0013, -0.0169],\n",
       "                      [-0.0179, -0.0112,  0.0150,  ...,  0.0062, -0.0026,  0.0177],\n",
       "                      [-0.0088,  0.0194, -0.0132,  ...,  0.0050, -0.0178,  0.0011]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0022, -0.0096,  0.0055,  ...,  0.0093, -0.0122, -0.0019],\n",
       "                      [-0.0028,  0.0018, -0.0123,  ...,  0.0086,  0.0071,  0.0083],\n",
       "                      [-0.0043,  0.0154,  0.0153,  ...,  0.0005,  0.0008, -0.0101],\n",
       "                      [ 0.0118,  0.0151, -0.0083,  ..., -0.0066,  0.0148, -0.0154]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 2.0873e-03,  1.5778e-03, -1.2606e-03, -1.2124e-03],\n",
       "                      [ 1.6988e-03,  1.4708e-03, -1.8140e-03, -1.6837e-03],\n",
       "                      [ 1.2168e-03, -2.6626e-05, -8.5694e-04, -8.2594e-04],\n",
       "                      ...,\n",
       "                      [-3.4419e-04, -3.8657e-04,  3.5019e-04,  5.3193e-04],\n",
       "                      [-4.0846e-04, -6.1843e-04,  7.7625e-04,  7.1192e-04],\n",
       "                      [ 5.9232e-04,  1.4166e-03, -1.2273e-03, -1.0864e-03]])),\n",
       "             ('llm.base_model.model.model.layers.21.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0134, -0.0004,  0.0125,  ..., -0.0089,  0.0270,  0.0021],\n",
       "                      [-0.0044,  0.0222, -0.0104,  ..., -0.0299,  0.0111, -0.0062],\n",
       "                      [-0.0176, -0.0129,  0.0041,  ...,  0.0254,  0.0304,  0.0158],\n",
       "                      ...,\n",
       "                      [ 0.0071, -0.0078, -0.0124,  ...,  0.0217,  0.0083,  0.0188],\n",
       "                      [ 0.0227, -0.0085,  0.0136,  ..., -0.0076,  0.0084, -0.0191],\n",
       "                      [-0.0218,  0.0152, -0.0142,  ...,  0.0334, -0.0188,  0.0032]])),\n",
       "             ('llm.base_model.model.model.layers.21.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0027, -0.0192,  0.0101,  ..., -0.0296,  0.0410,  0.0153],\n",
       "                      [ 0.0152,  0.0114,  0.0094,  ..., -0.0356,  0.0490,  0.0057],\n",
       "                      [ 0.0154,  0.0075,  0.0031,  ..., -0.0404, -0.0058, -0.0194],\n",
       "                      ...,\n",
       "                      [ 0.0133, -0.0255, -0.0291,  ...,  0.0359, -0.0262, -0.0016],\n",
       "                      [-0.0023,  0.0322,  0.0084,  ...,  0.0097, -0.0212,  0.0050],\n",
       "                      [ 0.0018, -0.0114, -0.0040,  ..., -0.0153,  0.0025,  0.0058]])),\n",
       "             ('llm.base_model.model.model.layers.21.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0258, -0.0302, -0.0199,  ...,  0.0206,  0.0394, -0.0105],\n",
       "                      [-0.0244, -0.0131,  0.0002,  ...,  0.0347,  0.0425,  0.0033],\n",
       "                      [ 0.0165, -0.0045,  0.0002,  ...,  0.0044, -0.0123, -0.0067],\n",
       "                      ...,\n",
       "                      [-0.0477, -0.0047,  0.0174,  ...,  0.0174, -0.0096, -0.0099],\n",
       "                      [-0.0012, -0.0132,  0.0087,  ..., -0.0229, -0.0074,  0.0038],\n",
       "                      [-0.0088, -0.0264, -0.0178,  ..., -0.0063, -0.0044, -0.0285]])),\n",
       "             ('llm.base_model.model.model.layers.21.mlp.down_proj.weight',\n",
       "              tensor([[ 1.1452e-02,  1.5656e-02, -2.3746e-03,  ...,  1.8372e-02,\n",
       "                        1.8799e-02,  4.9095e-03],\n",
       "                      [ 1.5335e-02, -3.9139e-03, -1.4420e-02,  ...,  2.5311e-03,\n",
       "                       -1.4053e-02, -1.2802e-02],\n",
       "                      [-8.2092e-03,  1.4181e-03,  1.4412e-02,  ..., -1.8902e-03,\n",
       "                        3.6072e-02,  2.2308e-02],\n",
       "                      ...,\n",
       "                      [-1.2871e-02,  3.7781e-02,  2.4261e-02,  ..., -3.2845e-03,\n",
       "                        2.5845e-03,  7.6141e-03],\n",
       "                      [ 1.5358e-02, -7.1108e-05, -3.1757e-03,  ..., -5.0323e-02,\n",
       "                       -1.5991e-02,  8.7585e-03],\n",
       "                      [ 7.0267e-03,  2.8801e-03,  2.3300e-02,  ..., -1.3809e-02,\n",
       "                        1.8600e-02, -2.2537e-02]])),\n",
       "             ('llm.base_model.model.model.layers.21.input_layernorm.weight',\n",
       "              tensor([0.4792, 0.4854, 0.4680,  ..., 0.4580, 0.4707, 0.4761])),\n",
       "             ('llm.base_model.model.model.layers.21.post_attention_layernorm.weight',\n",
       "              tensor([0.3728, 0.3704, 0.3645,  ..., 0.3809, 0.3716, 0.3726])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0235, -0.0148, -0.0086,  ...,  0.0460, -0.0369,  0.0269],\n",
       "                      [-0.0404, -0.0153, -0.0011,  ..., -0.0388,  0.0138, -0.0403],\n",
       "                      [-0.0325,  0.0226, -0.0157,  ...,  0.0240,  0.0142, -0.0212],\n",
       "                      ...,\n",
       "                      [ 0.0147,  0.0179,  0.0113,  ...,  0.0164,  0.0535, -0.0025],\n",
       "                      [-0.0272, -0.0026, -0.0267,  ...,  0.0497,  0.0032, -0.0222],\n",
       "                      [ 0.0271, -0.0113,  0.0103,  ..., -0.0529,  0.0109,  0.0249]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-1.4680e-04,  4.6455e-03,  1.9292e-03,  ...,  1.4730e-02,\n",
       "                        4.9796e-05,  1.1651e-02],\n",
       "                      [-3.2574e-03, -4.8819e-03,  1.2757e-02,  ...,  1.4045e-02,\n",
       "                       -1.5687e-02, -4.9089e-03],\n",
       "                      [-4.1800e-03,  7.0687e-04,  1.1436e-03,  ..., -6.7491e-03,\n",
       "                       -7.3114e-03, -1.2427e-03],\n",
       "                      [ 1.0167e-02, -7.1550e-03, -1.1641e-02,  ..., -1.3482e-02,\n",
       "                        5.4302e-03,  8.7973e-04]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0005, -0.0005, -0.0005, -0.0003],\n",
       "                      [ 0.0005,  0.0003,  0.0005,  0.0007],\n",
       "                      [-0.0006, -0.0005, -0.0001, -0.0009],\n",
       "                      ...,\n",
       "                      [ 0.0004,  0.0005, -0.0007,  0.0004],\n",
       "                      [ 0.0003,  0.0004, -0.0008,  0.0004],\n",
       "                      [-0.0007, -0.0007,  0.0007, -0.0005]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0187, -0.0019, -0.0064,  ...,  0.0148, -0.0161, -0.0196],\n",
       "                      [ 0.0027, -0.0133,  0.0312,  ..., -0.0231,  0.0337, -0.0146],\n",
       "                      [-0.0182,  0.0343, -0.0444,  ...,  0.0601, -0.0062, -0.0073],\n",
       "                      ...,\n",
       "                      [ 0.0215,  0.0072, -0.0284,  ..., -0.0217, -0.0157,  0.0162],\n",
       "                      [-0.0133, -0.0455, -0.0079,  ..., -0.0021, -0.0070, -0.0028],\n",
       "                      [ 0.0278,  0.0073,  0.0325,  ...,  0.0301, -0.0334,  0.0164]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0181,  0.0036, -0.0041,  ..., -0.0475, -0.0247,  0.0224],\n",
       "                      [-0.0320, -0.0135,  0.0078,  ..., -0.0239, -0.0318, -0.0074],\n",
       "                      [ 0.0272, -0.0236, -0.0099,  ...,  0.0466, -0.0009, -0.0156],\n",
       "                      ...,\n",
       "                      [-0.0104, -0.0450, -0.0246,  ...,  0.0147, -0.0073,  0.0145],\n",
       "                      [-0.0392, -0.0131,  0.0229,  ..., -0.0164,  0.0081, -0.0119],\n",
       "                      [-0.0035,  0.0211, -0.0388,  ...,  0.0083, -0.0001,  0.0236]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0017, -0.0054, -0.0031,  ...,  0.0008, -0.0043,  0.0091],\n",
       "                      [-0.0054, -0.0052,  0.0017,  ...,  0.0161, -0.0021, -0.0059],\n",
       "                      [-0.0122, -0.0038,  0.0034,  ..., -0.0068,  0.0129, -0.0112],\n",
       "                      [-0.0024, -0.0044, -0.0168,  ...,  0.0008, -0.0073,  0.0016]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-0.0017,  0.0018,  0.0016, -0.0015],\n",
       "                      [-0.0014,  0.0016,  0.0014, -0.0015],\n",
       "                      [-0.0007,  0.0011,  0.0007, -0.0015],\n",
       "                      ...,\n",
       "                      [-0.0006,  0.0008, -0.0001, -0.0008],\n",
       "                      [-0.0004,  0.0015,  0.0007, -0.0012],\n",
       "                      [ 0.0007, -0.0019, -0.0010,  0.0014]])),\n",
       "             ('llm.base_model.model.model.layers.22.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0240,  0.0165, -0.0217,  ..., -0.0036, -0.0281,  0.0086],\n",
       "                      [ 0.0349,  0.0134,  0.0057,  ...,  0.0072, -0.0127, -0.0196],\n",
       "                      [ 0.0150,  0.0063, -0.0091,  ..., -0.0269,  0.0057, -0.0010],\n",
       "                      ...,\n",
       "                      [-0.0025, -0.0122, -0.0092,  ..., -0.0146, -0.0180,  0.0051],\n",
       "                      [ 0.0208, -0.0110, -0.0215,  ..., -0.0173, -0.0072,  0.0115],\n",
       "                      [ 0.0037, -0.0219,  0.0254,  ...,  0.0099,  0.0150,  0.0125]])),\n",
       "             ('llm.base_model.model.model.layers.22.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0148, -0.0154,  0.0239,  ...,  0.0129,  0.0230, -0.0347],\n",
       "                      [ 0.0104, -0.0029,  0.0008,  ...,  0.0020,  0.0047,  0.0130],\n",
       "                      [ 0.0051, -0.0130,  0.0069,  ...,  0.0141,  0.0068, -0.0059],\n",
       "                      ...,\n",
       "                      [-0.0037, -0.0005,  0.0020,  ..., -0.0144,  0.0032, -0.0015],\n",
       "                      [-0.0001,  0.0231, -0.0251,  ..., -0.0022,  0.0146, -0.0234],\n",
       "                      [-0.0062,  0.0040,  0.0014,  ..., -0.0138,  0.0196,  0.0157]])),\n",
       "             ('llm.base_model.model.model.layers.22.mlp.up_proj.weight',\n",
       "              tensor([[ 3.2349e-02,  2.1454e-02,  5.2757e-03,  ...,  1.2993e-02,\n",
       "                        3.0914e-02, -3.3760e-03],\n",
       "                      [ 8.3160e-03,  8.3694e-03,  1.9394e-02,  ..., -1.2726e-02,\n",
       "                       -3.1796e-03,  1.0786e-03],\n",
       "                      [ 6.5308e-03, -3.1097e-02, -4.1382e-02,  ...,  2.5879e-02,\n",
       "                        1.0330e-02,  6.5804e-03],\n",
       "                      ...,\n",
       "                      [-1.0193e-02,  4.1151e-04, -1.8280e-02,  ..., -3.9940e-03,\n",
       "                        7.1068e-03,  6.6147e-03],\n",
       "                      [ 1.6891e-02, -1.3199e-02, -2.0630e-02,  ..., -3.1158e-02,\n",
       "                        9.8572e-03, -1.9073e-02],\n",
       "                      [-4.1275e-03,  7.4804e-05, -4.2648e-03,  ..., -4.2297e-02,\n",
       "                       -5.7739e-02,  1.5251e-02]])),\n",
       "             ('llm.base_model.model.model.layers.22.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0111, -0.0098,  0.0146,  ..., -0.0136,  0.0063, -0.0406],\n",
       "                      [ 0.0030,  0.0191, -0.0082,  ..., -0.0112,  0.0113, -0.0264],\n",
       "                      [-0.0074, -0.0065,  0.0077,  ...,  0.0191,  0.0138,  0.0207],\n",
       "                      ...,\n",
       "                      [ 0.0244, -0.0074, -0.0454,  ..., -0.0039, -0.0162, -0.0197],\n",
       "                      [-0.0131, -0.0479,  0.0128,  ...,  0.0207, -0.0253,  0.0339],\n",
       "                      [ 0.0132, -0.0011, -0.0348,  ..., -0.0018, -0.0194,  0.0082]])),\n",
       "             ('llm.base_model.model.model.layers.22.input_layernorm.weight',\n",
       "              tensor([0.4856, 0.4846, 0.4756,  ..., 0.4695, 0.4875, 0.4856])),\n",
       "             ('llm.base_model.model.model.layers.22.post_attention_layernorm.weight',\n",
       "              tensor([0.3853, 0.3835, 0.3835,  ..., 0.3911, 0.3870, 0.3901])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0022, -0.0148,  0.0013,  ..., -0.0171, -0.0029,  0.0008],\n",
       "                      [ 0.0101, -0.0021,  0.0107,  ..., -0.0167, -0.0039,  0.0060],\n",
       "                      [-0.0046,  0.0064,  0.0190,  ...,  0.0027, -0.0150,  0.0073],\n",
       "                      ...,\n",
       "                      [-0.0220,  0.0626,  0.0091,  ..., -0.0371, -0.0609, -0.0278],\n",
       "                      [-0.0379, -0.0327,  0.0220,  ..., -0.0170, -0.0010,  0.0099],\n",
       "                      [ 0.0107, -0.0573, -0.0025,  ...,  0.0102,  0.0409, -0.0081]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0056, -0.0142,  0.0129,  ...,  0.0030,  0.0111,  0.0102],\n",
       "                      [-0.0077,  0.0153, -0.0014,  ...,  0.0067,  0.0116,  0.0064],\n",
       "                      [ 0.0102,  0.0057,  0.0110,  ...,  0.0153, -0.0039,  0.0077],\n",
       "                      [ 0.0107,  0.0046, -0.0002,  ...,  0.0079, -0.0056, -0.0043]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-1.2104e-04, -3.3556e-04, -1.0711e-04,  6.5887e-05],\n",
       "                      [ 1.1369e-04,  1.2385e-04, -2.5366e-04, -4.7281e-05],\n",
       "                      [-1.2795e-04, -1.9936e-04, -3.3435e-04, -8.8787e-05],\n",
       "                      ...,\n",
       "                      [ 4.7797e-04,  3.2168e-04,  2.1635e-04,  4.7608e-04],\n",
       "                      [ 2.3304e-04,  3.4502e-04,  4.0261e-04,  3.9953e-04],\n",
       "                      [-1.1569e-04, -1.1486e-04, -2.2616e-04, -2.0275e-04]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0035,  0.0066,  0.0036,  ...,  0.0027, -0.0154,  0.0049],\n",
       "                      [-0.0172, -0.0012, -0.0143,  ...,  0.0159,  0.0144, -0.0036],\n",
       "                      [ 0.0087,  0.0041, -0.0107,  ...,  0.0172,  0.0139, -0.0090],\n",
       "                      ...,\n",
       "                      [ 0.0046,  0.0302,  0.0542,  ..., -0.0311, -0.0136, -0.0179],\n",
       "                      [-0.0006, -0.0306, -0.0121,  ..., -0.0227, -0.0229,  0.0137],\n",
       "                      [-0.0143, -0.0074, -0.0232,  ...,  0.0048,  0.0009, -0.0132]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0042,  0.0333, -0.0046,  ..., -0.0063, -0.0077, -0.0170],\n",
       "                      [ 0.0002, -0.0148, -0.0195,  ...,  0.0048, -0.0132,  0.0037],\n",
       "                      [ 0.0083, -0.0161, -0.0286,  ...,  0.0129, -0.0485, -0.0299],\n",
       "                      ...,\n",
       "                      [ 0.0106,  0.0053,  0.0046,  ..., -0.0018,  0.0266,  0.0120],\n",
       "                      [ 0.0181,  0.0264,  0.0080,  ..., -0.0016, -0.0067, -0.0149],\n",
       "                      [-0.0183, -0.0117, -0.0568,  ...,  0.0100,  0.0075, -0.0304]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0041,  0.0137, -0.0097,  ...,  0.0149, -0.0028, -0.0021],\n",
       "                      [-0.0173,  0.0068, -0.0145,  ...,  0.0013, -0.0069,  0.0070],\n",
       "                      [ 0.0153, -0.0013, -0.0056,  ...,  0.0078,  0.0168,  0.0046],\n",
       "                      [ 0.0072, -0.0028, -0.0061,  ..., -0.0008, -0.0053, -0.0086]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.0299e-03,  1.0819e-03, -4.2939e-04,  1.3986e-03],\n",
       "                      [ 1.0139e-03,  1.1485e-03, -2.6927e-04,  1.4431e-03],\n",
       "                      [ 4.0400e-04,  3.1222e-04,  4.9025e-04,  4.2986e-04],\n",
       "                      ...,\n",
       "                      [ 9.7357e-04,  1.0888e-03,  1.2788e-03,  1.3298e-03],\n",
       "                      [-2.9082e-04, -3.8150e-04, -1.7252e-04, -1.1849e-04],\n",
       "                      [-3.3588e-05, -2.8536e-04,  2.6654e-04,  2.1117e-04]])),\n",
       "             ('llm.base_model.model.model.layers.23.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0068, -0.0044, -0.0166,  ..., -0.0168,  0.0142, -0.0077],\n",
       "                      [-0.0103, -0.0163, -0.0066,  ..., -0.0025,  0.0142, -0.0009],\n",
       "                      [ 0.0181,  0.0024,  0.0301,  ..., -0.0126,  0.0052, -0.0205],\n",
       "                      ...,\n",
       "                      [ 0.0334, -0.0049,  0.0375,  ..., -0.0190,  0.0137,  0.0028],\n",
       "                      [-0.0068,  0.0220, -0.0121,  ..., -0.0056, -0.0134, -0.0057],\n",
       "                      [ 0.0100, -0.0055, -0.0123,  ..., -0.0047,  0.0011, -0.0295]])),\n",
       "             ('llm.base_model.model.model.layers.23.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0104,  0.0273,  0.0020,  ..., -0.0021,  0.0351,  0.0118],\n",
       "                      [-0.0082,  0.0483, -0.0126,  ...,  0.0057, -0.0205,  0.0170],\n",
       "                      [-0.0345,  0.0200,  0.0027,  ...,  0.0172, -0.0611,  0.0185],\n",
       "                      ...,\n",
       "                      [-0.0060,  0.0101,  0.0010,  ..., -0.0091,  0.0090,  0.0031],\n",
       "                      [-0.0226,  0.0338, -0.0035,  ...,  0.0023,  0.0146, -0.0275],\n",
       "                      [ 0.0031,  0.0084,  0.0139,  ..., -0.0085,  0.0029, -0.0092]])),\n",
       "             ('llm.base_model.model.model.layers.23.mlp.up_proj.weight',\n",
       "              tensor([[ 3.0731e-02,  1.5205e-02,  3.0655e-02,  ...,  2.9716e-03,\n",
       "                       -2.7679e-02, -7.7858e-03],\n",
       "                      [ 1.3685e-03,  2.4166e-03, -1.4137e-02,  ..., -5.5733e-03,\n",
       "                       -1.6434e-02,  1.1368e-02],\n",
       "                      [-1.7746e-02,  4.3144e-03, -2.3499e-02,  ...,  1.7395e-02,\n",
       "                        1.1787e-02, -5.5847e-03],\n",
       "                      ...,\n",
       "                      [-1.1047e-02, -1.2787e-02,  1.6861e-02,  ...,  8.4152e-03,\n",
       "                        4.2145e-02,  4.7112e-03],\n",
       "                      [-3.1471e-04,  9.0561e-03, -3.8727e-02,  ...,  1.8906e-02,\n",
       "                        5.7144e-03,  1.6190e-02],\n",
       "                      [ 8.7814e-03,  1.3786e-02, -4.9629e-03,  ...,  2.3305e-05,\n",
       "                       -2.0844e-02,  1.7029e-02]])),\n",
       "             ('llm.base_model.model.model.layers.23.mlp.down_proj.weight',\n",
       "              tensor([[-3.4809e-04,  6.8893e-03, -1.7441e-02,  ..., -3.2379e-02,\n",
       "                       -1.3969e-02,  2.8503e-02],\n",
       "                      [ 6.5041e-03,  2.2247e-02, -6.3438e-03,  ...,  2.6108e-02,\n",
       "                        2.5436e-02, -8.2254e-05],\n",
       "                      [-5.5275e-03, -1.3451e-02, -2.1637e-02,  ...,  5.2681e-03,\n",
       "                        3.6194e-02, -1.2383e-02],\n",
       "                      ...,\n",
       "                      [ 6.6681e-03, -6.3210e-03,  1.2344e-02,  ...,  1.8356e-02,\n",
       "                       -7.8630e-04, -1.7258e-02],\n",
       "                      [ 2.5711e-02, -1.1040e-02, -1.0262e-03,  ..., -7.6904e-03,\n",
       "                        5.3864e-03, -6.0129e-04],\n",
       "                      [-3.7193e-03, -3.1891e-02, -1.1597e-02,  ..., -9.5901e-03,\n",
       "                        1.2787e-02, -8.1100e-03]])),\n",
       "             ('llm.base_model.model.model.layers.23.input_layernorm.weight',\n",
       "              tensor([0.5127, 0.5229, 0.5093,  ..., 0.5034, 0.5200, 0.5249])),\n",
       "             ('llm.base_model.model.model.layers.23.post_attention_layernorm.weight',\n",
       "              tensor([0.4009, 0.3938, 0.3958,  ..., 0.3975, 0.4011, 0.4026])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0192, -0.0135,  0.0128,  ...,  0.0398, -0.0196,  0.0033],\n",
       "                      [ 0.0226,  0.0124,  0.0064,  ..., -0.0111,  0.0163, -0.0084],\n",
       "                      [-0.0014, -0.0091, -0.0204,  ...,  0.0086, -0.0111,  0.0169],\n",
       "                      ...,\n",
       "                      [-0.0056,  0.0008, -0.0215,  ...,  0.0129,  0.0003, -0.0057],\n",
       "                      [-0.0212,  0.0115,  0.0064,  ...,  0.0202, -0.0397,  0.0050],\n",
       "                      [-0.0224, -0.0352, -0.0191,  ..., -0.0114,  0.0269,  0.0681]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0055,  0.0099,  0.0088,  ...,  0.0069,  0.0032, -0.0094],\n",
       "                      [-0.0043,  0.0134, -0.0130,  ..., -0.0132,  0.0098, -0.0065],\n",
       "                      [ 0.0041,  0.0027,  0.0038,  ..., -0.0007, -0.0130, -0.0047],\n",
       "                      [ 0.0042, -0.0045,  0.0104,  ..., -0.0078,  0.0062,  0.0024]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.4944e-03,  1.8750e-03,  1.8400e-03,  1.7987e-03],\n",
       "                      [-5.2883e-04, -1.1627e-03, -1.0483e-03, -9.0782e-04],\n",
       "                      [ 3.8064e-04,  6.1162e-04,  4.5609e-04,  6.2586e-04],\n",
       "                      ...,\n",
       "                      [ 1.3245e-03,  1.4633e-03,  1.6998e-03,  1.1197e-03],\n",
       "                      [ 4.6850e-04, -5.9626e-04, -5.9575e-04, -2.6666e-04],\n",
       "                      [-1.0815e-03, -2.9747e-04, -8.1651e-04, -2.3586e-06]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0213,  0.0037, -0.0098,  ...,  0.0127, -0.0059,  0.0028],\n",
       "                      [ 0.0124, -0.0192,  0.0100,  ..., -0.0232,  0.0220,  0.0092],\n",
       "                      [ 0.0096,  0.0026, -0.0439,  ...,  0.0180,  0.0147, -0.0143],\n",
       "                      ...,\n",
       "                      [ 0.0290,  0.0074,  0.0405,  ...,  0.0122,  0.0212, -0.0445],\n",
       "                      [-0.0047,  0.0217,  0.0191,  ...,  0.0335, -0.0167, -0.0004],\n",
       "                      [-0.0216, -0.0175, -0.0055,  ...,  0.0031, -0.0069,  0.0586]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 2.6566e-02, -1.9424e-02, -5.9166e-03,  ..., -3.2196e-03,\n",
       "                       -8.4782e-04, -3.2444e-03],\n",
       "                      [ 3.3325e-02, -2.2293e-02, -1.0239e-02,  ..., -6.3538e-02,\n",
       "                       -4.1107e-02, -1.9547e-02],\n",
       "                      [-5.0598e-02, -1.6861e-02, -1.5778e-02,  ..., -8.4610e-03,\n",
       "                       -1.1383e-02,  4.1504e-03],\n",
       "                      ...,\n",
       "                      [ 5.2392e-05, -1.7685e-02,  1.5175e-02,  ...,  2.7481e-02,\n",
       "                       -3.2234e-03,  2.7161e-02],\n",
       "                      [-2.3174e-03, -1.3077e-02, -1.5366e-02,  ...,  3.1525e-02,\n",
       "                       -5.3329e-03,  9.1934e-03],\n",
       "                      [ 1.3954e-02,  1.8753e-02,  2.2705e-02,  ...,  2.3697e-02,\n",
       "                       -1.5076e-02, -8.8959e-03]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0072, -0.0037,  0.0005,  ...,  0.0074,  0.0007, -0.0170],\n",
       "                      [ 0.0039, -0.0137, -0.0084,  ...,  0.0045,  0.0114, -0.0151],\n",
       "                      [ 0.0069, -0.0083, -0.0034,  ...,  0.0119,  0.0009, -0.0131],\n",
       "                      [ 0.0079, -0.0013, -0.0038,  ...,  0.0013,  0.0041,  0.0092]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 2.0855e-04, -7.1590e-05,  3.2709e-04,  3.1123e-04],\n",
       "                      [ 1.3718e-03,  1.3217e-03, -1.3085e-03, -1.2870e-03],\n",
       "                      [-9.5219e-04, -7.2151e-04,  1.9214e-04, -6.4872e-05],\n",
       "                      ...,\n",
       "                      [ 7.8918e-04,  7.0265e-04, -2.7704e-04, -2.8664e-04],\n",
       "                      [ 3.1180e-04,  4.7028e-04, -4.2624e-04, -3.9232e-04],\n",
       "                      [ 4.9083e-04,  8.4915e-04, -9.6168e-04, -1.2531e-03]])),\n",
       "             ('llm.base_model.model.model.layers.24.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0123,  0.0188,  0.0257,  ...,  0.0086,  0.0022, -0.0158],\n",
       "                      [-0.0096,  0.0278,  0.0141,  ...,  0.0193,  0.0271, -0.0282],\n",
       "                      [-0.0076, -0.0005,  0.0101,  ..., -0.0237,  0.0030, -0.0071],\n",
       "                      ...,\n",
       "                      [-0.0029,  0.0146,  0.0161,  ..., -0.0061, -0.0087,  0.0038],\n",
       "                      [ 0.0534,  0.0055, -0.0054,  ...,  0.0025, -0.0207, -0.0037],\n",
       "                      [ 0.0056,  0.0124,  0.0098,  ...,  0.0044, -0.0223,  0.0152]])),\n",
       "             ('llm.base_model.model.model.layers.24.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0284, -0.0121,  0.0138,  ..., -0.0123, -0.0037, -0.0004],\n",
       "                      [ 0.0003, -0.0136, -0.0260,  ...,  0.0067,  0.0007, -0.0138],\n",
       "                      [ 0.0005, -0.0319,  0.0246,  ..., -0.0077, -0.0470, -0.0171],\n",
       "                      ...,\n",
       "                      [-0.0010, -0.0300,  0.0060,  ..., -0.0039,  0.0129, -0.0068],\n",
       "                      [ 0.0159,  0.0161,  0.0042,  ...,  0.0067, -0.0006, -0.0037],\n",
       "                      [-0.0366,  0.0297,  0.0001,  ...,  0.0320, -0.0154, -0.0448]])),\n",
       "             ('llm.base_model.model.model.layers.24.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0026, -0.0020,  0.0215,  ...,  0.0240,  0.0008,  0.0285],\n",
       "                      [-0.0047,  0.0156, -0.0267,  ..., -0.0083,  0.0008, -0.0200],\n",
       "                      [ 0.0095, -0.0497,  0.0153,  ...,  0.0434,  0.0194, -0.0345],\n",
       "                      ...,\n",
       "                      [ 0.0148, -0.0310, -0.0081,  ...,  0.0002,  0.0169,  0.0124],\n",
       "                      [ 0.0351, -0.0075,  0.0131,  ...,  0.0039,  0.0153, -0.0084],\n",
       "                      [-0.0034, -0.0164,  0.0232,  ...,  0.0239,  0.0354,  0.0204]])),\n",
       "             ('llm.base_model.model.model.layers.24.mlp.down_proj.weight',\n",
       "              tensor([[-0.0070, -0.0152, -0.0314,  ..., -0.0010,  0.0039, -0.0189],\n",
       "                      [ 0.0263, -0.0106,  0.0169,  ..., -0.0035,  0.0110, -0.0475],\n",
       "                      [ 0.0207,  0.0170, -0.0338,  ...,  0.0027,  0.0233,  0.0044],\n",
       "                      ...,\n",
       "                      [-0.0068,  0.0106, -0.0187,  ..., -0.0347, -0.0146, -0.0226],\n",
       "                      [ 0.0109,  0.0240,  0.0055,  ...,  0.0235, -0.0249,  0.0194],\n",
       "                      [-0.0194, -0.0069,  0.0059,  ...,  0.0112, -0.0081, -0.0317]])),\n",
       "             ('llm.base_model.model.model.layers.24.input_layernorm.weight',\n",
       "              tensor([0.4954, 0.5210, 0.5107,  ..., 0.4875, 0.5161, 0.5068])),\n",
       "             ('llm.base_model.model.model.layers.24.post_attention_layernorm.weight',\n",
       "              tensor([0.4106, 0.4070, 0.4094,  ..., 0.4119, 0.4158, 0.4114])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0029, -0.0132, -0.0190,  ...,  0.0055, -0.0127,  0.0055],\n",
       "                      [-0.0103,  0.0035,  0.0130,  ..., -0.0125, -0.0005, -0.0087],\n",
       "                      [-0.0029,  0.0057,  0.0035,  ..., -0.0027, -0.0180, -0.0160],\n",
       "                      ...,\n",
       "                      [ 0.0432,  0.0470,  0.0038,  ...,  0.0028,  0.0149, -0.0296],\n",
       "                      [-0.0571, -0.0577, -0.0077,  ..., -0.0161, -0.0222,  0.0060],\n",
       "                      [ 0.0388, -0.0419, -0.0247,  ...,  0.0039,  0.0175, -0.0308]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0043,  0.0019,  0.0119,  ...,  0.0010, -0.0011,  0.0113],\n",
       "                      [-0.0014, -0.0135, -0.0126,  ..., -0.0167, -0.0048,  0.0074],\n",
       "                      [ 0.0108, -0.0143, -0.0136,  ...,  0.0085,  0.0158,  0.0107],\n",
       "                      [ 0.0014, -0.0021,  0.0136,  ...,  0.0084,  0.0002, -0.0085]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-1.7592e-04, -3.9813e-04, -4.5536e-04, -2.2695e-04],\n",
       "                      [-3.2613e-04, -1.8675e-04, -8.0217e-05, -3.0830e-04],\n",
       "                      [ 8.0359e-05,  1.0859e-04, -6.1082e-06, -5.6270e-05],\n",
       "                      ...,\n",
       "                      [ 5.6986e-04, -3.1229e-04, -5.9611e-05, -2.8089e-04],\n",
       "                      [ 1.0422e-03, -1.9969e-04,  2.8623e-05, -4.9510e-05],\n",
       "                      [ 2.7585e-04,  8.4262e-04, -1.3317e-04,  9.8023e-04]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.k_proj.weight',\n",
       "              tensor([[-1.0269e-02, -1.5480e-02, -5.5389e-03,  ...,  3.0231e-04,\n",
       "                        5.8746e-03, -3.0842e-03],\n",
       "                      [-2.0493e-02, -8.5526e-03,  9.6359e-03,  ..., -5.6076e-03,\n",
       "                       -2.0264e-02,  1.1536e-02],\n",
       "                      [-7.3433e-03,  2.2163e-03, -1.7881e-07,  ...,  7.0343e-03,\n",
       "                       -4.9973e-03,  7.4921e-03],\n",
       "                      ...,\n",
       "                      [ 4.4441e-03,  5.0323e-02, -1.2360e-02,  ..., -5.6305e-02,\n",
       "                       -5.6396e-02,  3.5278e-02],\n",
       "                      [ 3.4821e-02, -3.7781e-02,  1.6909e-03,  ..., -1.6909e-03,\n",
       "                        8.5983e-03,  1.5175e-02],\n",
       "                      [-1.1635e-02, -2.4384e-02,  1.3828e-03,  ...,  3.6072e-02,\n",
       "                        9.3002e-03, -2.0355e-02]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0089,  0.0115,  0.0049,  ...,  0.0219, -0.0153, -0.0112],\n",
       "                      [-0.0063, -0.0071,  0.0062,  ...,  0.0074, -0.0341, -0.0095],\n",
       "                      [-0.0155,  0.0110, -0.0177,  ..., -0.0071, -0.0049, -0.0034],\n",
       "                      ...,\n",
       "                      [-0.0182, -0.0330, -0.0064,  ...,  0.0183,  0.0045,  0.0125],\n",
       "                      [-0.0132, -0.0001,  0.0193,  ..., -0.0029,  0.0073, -0.0223],\n",
       "                      [-0.0340, -0.0160, -0.0211,  ...,  0.0027,  0.0189,  0.0203]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0084,  0.0140,  0.0013,  ..., -0.0075,  0.0119,  0.0033],\n",
       "                      [ 0.0067, -0.0091,  0.0084,  ...,  0.0082,  0.0078,  0.0060],\n",
       "                      [-0.0049, -0.0011, -0.0029,  ...,  0.0097, -0.0017,  0.0056],\n",
       "                      [-0.0023,  0.0090, -0.0041,  ..., -0.0031, -0.0065,  0.0072]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 8.1995e-04,  1.1711e-03, -7.3650e-04, -1.0746e-03],\n",
       "                      [ 1.2727e-03,  4.2923e-04, -5.3741e-05,  2.0678e-05],\n",
       "                      [ 2.9853e-04,  4.0027e-04,  6.2718e-05, -7.0821e-05],\n",
       "                      ...,\n",
       "                      [-9.7320e-04, -1.0420e-03, -3.4166e-05,  1.2263e-03],\n",
       "                      [-3.3211e-04, -3.2860e-04,  3.2675e-04,  2.7292e-04],\n",
       "                      [ 2.0010e-04, -2.4718e-04,  4.4538e-04, -2.1866e-04]])),\n",
       "             ('llm.base_model.model.model.layers.25.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0179,  0.0142, -0.0010,  ...,  0.0161,  0.0027,  0.0133],\n",
       "                      [-0.0239, -0.0173, -0.0177,  ...,  0.0237,  0.0017, -0.0028],\n",
       "                      [-0.0051, -0.0095,  0.0181,  ..., -0.0120, -0.0148,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0169,  0.0159, -0.0026,  ...,  0.0112,  0.0125,  0.0262],\n",
       "                      [-0.0102, -0.0231, -0.0285,  ..., -0.0212, -0.0093,  0.0112],\n",
       "                      [-0.0154, -0.0084, -0.0187,  ..., -0.0418, -0.0258, -0.0151]])),\n",
       "             ('llm.base_model.model.model.layers.25.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0017, -0.0398,  0.0435,  ..., -0.0052, -0.0097,  0.0113],\n",
       "                      [-0.0201, -0.0036, -0.0091,  ...,  0.0241,  0.0355,  0.0141],\n",
       "                      [-0.0146,  0.0271,  0.0074,  ...,  0.0138,  0.0071,  0.0248],\n",
       "                      ...,\n",
       "                      [-0.0401,  0.0030,  0.0096,  ..., -0.0044, -0.0192,  0.0056],\n",
       "                      [ 0.0182, -0.0059,  0.0588,  ...,  0.0249,  0.0236,  0.0076],\n",
       "                      [-0.0098, -0.0037, -0.0110,  ...,  0.0462,  0.0045, -0.0081]])),\n",
       "             ('llm.base_model.model.model.layers.25.mlp.up_proj.weight',\n",
       "              tensor([[-0.0285, -0.0058,  0.0149,  ...,  0.0060,  0.0083, -0.0175],\n",
       "                      [-0.0205,  0.0010,  0.0101,  ..., -0.0046,  0.0105, -0.0006],\n",
       "                      [ 0.0290,  0.0021,  0.0292,  ..., -0.0136, -0.0217, -0.0041],\n",
       "                      ...,\n",
       "                      [ 0.0075,  0.0071,  0.0403,  ...,  0.0067, -0.0308, -0.0183],\n",
       "                      [-0.0292,  0.0116, -0.0318,  ..., -0.0412, -0.0298,  0.0010],\n",
       "                      [-0.0144,  0.0007,  0.0286,  ...,  0.0214,  0.0071,  0.0222]])),\n",
       "             ('llm.base_model.model.model.layers.25.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0285, -0.0096,  0.0143,  ...,  0.0183, -0.0051,  0.0291],\n",
       "                      [-0.0170,  0.0018,  0.0008,  ...,  0.0125, -0.0032,  0.0233],\n",
       "                      [ 0.0148,  0.0086, -0.0008,  ..., -0.0199,  0.0065, -0.0162],\n",
       "                      ...,\n",
       "                      [ 0.0141, -0.0157, -0.0276,  ..., -0.0470,  0.0015,  0.0233],\n",
       "                      [ 0.0015, -0.0070,  0.0025,  ...,  0.0036,  0.0055,  0.0009],\n",
       "                      [-0.0094, -0.0096,  0.0115,  ..., -0.0338, -0.0049, -0.0069]])),\n",
       "             ('llm.base_model.model.model.layers.25.input_layernorm.weight',\n",
       "              tensor([0.5469, 0.5552, 0.5425,  ..., 0.5513, 0.5635, 0.5518])),\n",
       "             ('llm.base_model.model.model.layers.25.post_attention_layernorm.weight',\n",
       "              tensor([0.4175, 0.4163, 0.4209,  ..., 0.4268, 0.4241, 0.4229])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0342, -0.0047, -0.0103,  ..., -0.0068,  0.0370, -0.0004],\n",
       "                      [-0.0081, -0.0169,  0.0116,  ..., -0.0002, -0.0210,  0.0117],\n",
       "                      [-0.0025,  0.0034,  0.0099,  ...,  0.0049, -0.0392, -0.0178],\n",
       "                      ...,\n",
       "                      [-0.0011, -0.0111, -0.0098,  ...,  0.0154,  0.0202,  0.0013],\n",
       "                      [ 0.0038, -0.0250, -0.0279,  ...,  0.0155, -0.0053, -0.0103],\n",
       "                      [-0.0161,  0.0527,  0.0285,  ..., -0.0118, -0.0598, -0.0451]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0083,  0.0122, -0.0034,  ...,  0.0135,  0.0127, -0.0135],\n",
       "                      [-0.0103,  0.0003, -0.0117,  ...,  0.0112, -0.0069, -0.0006],\n",
       "                      [-0.0002, -0.0050,  0.0155,  ..., -0.0029, -0.0157, -0.0017],\n",
       "                      [-0.0156,  0.0076,  0.0091,  ...,  0.0038, -0.0104, -0.0169]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 4.1767e-04,  6.5417e-04,  2.8745e-04, -5.4280e-04],\n",
       "                      [ 6.1707e-04, -1.5678e-04, -2.5970e-04, -3.9911e-04],\n",
       "                      [ 6.3042e-05, -4.4641e-04, -2.9010e-05,  5.4293e-04],\n",
       "                      ...,\n",
       "                      [ 1.7578e-05, -6.6822e-04, -1.0173e-03,  1.1839e-03],\n",
       "                      [-9.6681e-04,  5.8862e-05,  4.1984e-04,  1.0241e-04],\n",
       "                      [-6.2753e-04,  6.0620e-04,  7.9886e-04, -1.2505e-03]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0253,  0.0184, -0.0156,  ..., -0.0250,  0.0333, -0.0023],\n",
       "                      [-0.0256,  0.0094,  0.0159,  ..., -0.0009,  0.0199,  0.0308],\n",
       "                      [ 0.0107,  0.0276, -0.0042,  ..., -0.0246, -0.0620, -0.0046],\n",
       "                      ...,\n",
       "                      [ 0.0255,  0.0209,  0.0051,  ..., -0.0467, -0.0520,  0.0252],\n",
       "                      [-0.0320, -0.0361, -0.0090,  ...,  0.0450,  0.0224, -0.0001],\n",
       "                      [-0.0156,  0.0226, -0.0127,  ..., -0.0006, -0.0198, -0.0129]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0579, -0.0270, -0.0248,  ..., -0.0156,  0.0071, -0.0127],\n",
       "                      [-0.0544, -0.0208,  0.0241,  ...,  0.0057, -0.0073,  0.0064],\n",
       "                      [ 0.0015,  0.0015, -0.0275,  ..., -0.0095, -0.0059, -0.0306],\n",
       "                      ...,\n",
       "                      [-0.0220, -0.0135,  0.0016,  ...,  0.0458, -0.0034,  0.0095],\n",
       "                      [ 0.0076, -0.0336, -0.0065,  ..., -0.0145, -0.0172, -0.0008],\n",
       "                      [ 0.0075,  0.0224, -0.0135,  ...,  0.0093,  0.0008,  0.0230]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0053,  0.0095, -0.0032,  ..., -0.0038,  0.0062, -0.0127],\n",
       "                      [ 0.0076, -0.0074, -0.0078,  ...,  0.0057,  0.0109, -0.0100],\n",
       "                      [-0.0160,  0.0140,  0.0129,  ...,  0.0036,  0.0075, -0.0026],\n",
       "                      [-0.0104, -0.0053,  0.0130,  ..., -0.0129, -0.0141, -0.0130]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-7.1281e-04, -9.9880e-05, -1.6005e-04, -2.4884e-04],\n",
       "                      [-1.3922e-03, -8.8408e-04, -8.7158e-04, -9.9040e-04],\n",
       "                      [ 1.9573e-03,  1.5675e-03,  1.5926e-03,  1.7548e-03],\n",
       "                      ...,\n",
       "                      [-1.0632e-03, -9.1706e-04, -9.9089e-04, -9.8290e-04],\n",
       "                      [-2.7229e-04, -9.8899e-05, -1.8019e-04, -2.5651e-04],\n",
       "                      [-1.7463e-03, -1.3506e-03, -1.3742e-03, -1.5440e-03]])),\n",
       "             ('llm.base_model.model.model.layers.26.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0138,  0.0020, -0.0314,  ..., -0.0031,  0.0147,  0.0284],\n",
       "                      [ 0.0060,  0.0509,  0.0077,  ..., -0.0020,  0.0493, -0.0071],\n",
       "                      [-0.0089,  0.0145, -0.0211,  ..., -0.0162,  0.0030, -0.0049],\n",
       "                      ...,\n",
       "                      [ 0.0295,  0.0031,  0.0127,  ...,  0.0009,  0.0151,  0.0021],\n",
       "                      [-0.0113,  0.0086, -0.0093,  ...,  0.0135, -0.0064, -0.0484],\n",
       "                      [ 0.0156,  0.0010,  0.0028,  ..., -0.0238,  0.0220, -0.0228]])),\n",
       "             ('llm.base_model.model.model.layers.26.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0132, -0.0088,  0.0126,  ...,  0.0264,  0.0275, -0.0409],\n",
       "                      [-0.0069,  0.0150, -0.0181,  ..., -0.0295, -0.0266,  0.0177],\n",
       "                      [ 0.0027,  0.0027, -0.0007,  ...,  0.0075, -0.0074, -0.0185],\n",
       "                      ...,\n",
       "                      [-0.0042,  0.0365, -0.0098,  ...,  0.0004, -0.0333, -0.0185],\n",
       "                      [-0.0188,  0.0136,  0.0237,  ...,  0.0165,  0.0183,  0.0060],\n",
       "                      [ 0.0180, -0.0022, -0.0063,  ..., -0.0249, -0.0048, -0.0056]])),\n",
       "             ('llm.base_model.model.model.layers.26.mlp.up_proj.weight',\n",
       "              tensor([[-0.0168,  0.0405, -0.0014,  ...,  0.0128, -0.0109, -0.0072],\n",
       "                      [-0.0359, -0.0137,  0.0015,  ...,  0.0292, -0.0028,  0.0114],\n",
       "                      [ 0.0043, -0.0130, -0.0285,  ...,  0.0148, -0.0160, -0.0060],\n",
       "                      ...,\n",
       "                      [ 0.0076, -0.0250,  0.0033,  ...,  0.0131,  0.0369, -0.0098],\n",
       "                      [-0.0432, -0.0031,  0.0558,  ...,  0.0298,  0.0024,  0.0036],\n",
       "                      [ 0.0004, -0.0179,  0.0171,  ..., -0.0140,  0.0103, -0.0058]])),\n",
       "             ('llm.base_model.model.model.layers.26.mlp.down_proj.weight',\n",
       "              tensor([[-1.0498e-02, -1.0574e-02, -1.3008e-02,  ...,  3.1372e-02,\n",
       "                        1.3817e-02,  7.5951e-03],\n",
       "                      [ 1.3268e-02,  1.2352e-02,  3.2005e-03,  ...,  5.7526e-02,\n",
       "                        2.2827e-02, -2.7435e-02],\n",
       "                      [-1.7944e-02,  9.8572e-03, -2.5375e-02,  ..., -1.1024e-02,\n",
       "                        2.1408e-02,  1.0902e-02],\n",
       "                      ...,\n",
       "                      [-1.3306e-02, -8.8196e-03, -1.5671e-02,  ...,  8.9874e-03,\n",
       "                        4.0131e-02,  1.5736e-05],\n",
       "                      [-2.0035e-02, -1.4740e-02, -2.4170e-02,  ...,  7.3166e-03,\n",
       "                        9.6817e-03,  1.7242e-02],\n",
       "                      [ 5.3406e-03, -5.7297e-03, -7.5912e-03,  ...,  1.0033e-02,\n",
       "                        1.7380e-02,  1.2962e-02]])),\n",
       "             ('llm.base_model.model.model.layers.26.input_layernorm.weight',\n",
       "              tensor([0.5156, 0.5347, 0.5366,  ..., 0.5190, 0.5444, 0.5308])),\n",
       "             ('llm.base_model.model.model.layers.26.post_attention_layernorm.weight',\n",
       "              tensor([0.4365, 0.4324, 0.4358,  ..., 0.4436, 0.4414, 0.4395])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0319,  0.0195,  0.0072,  ..., -0.0019,  0.0116,  0.0383],\n",
       "                      [-0.0183,  0.0396,  0.0253,  ..., -0.0219,  0.0057,  0.0058],\n",
       "                      [-0.0150, -0.0262,  0.0065,  ...,  0.0038, -0.0281,  0.0325],\n",
       "                      ...,\n",
       "                      [-0.0537,  0.0302, -0.0054,  ...,  0.0227, -0.0163, -0.0179],\n",
       "                      [ 0.0031,  0.0338,  0.0169,  ...,  0.0066,  0.0030,  0.0262],\n",
       "                      [-0.0238, -0.0140,  0.0071,  ...,  0.0201,  0.0155, -0.0093]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0061,  0.0109,  0.0141,  ..., -0.0042,  0.0030, -0.0144],\n",
       "                      [ 0.0080,  0.0107, -0.0011,  ..., -0.0073,  0.0059,  0.0074],\n",
       "                      [-0.0140, -0.0074, -0.0150,  ..., -0.0094,  0.0071,  0.0086],\n",
       "                      [-0.0097,  0.0062,  0.0064,  ...,  0.0056, -0.0026, -0.0049]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-6.4033e-05,  6.3604e-05,  1.5607e-04, -2.7898e-04],\n",
       "                      [-3.2356e-04,  1.7877e-04, -4.0716e-04, -1.5714e-04],\n",
       "                      [-4.3278e-06,  6.7700e-04, -5.4102e-05, -9.1705e-05],\n",
       "                      ...,\n",
       "                      [-5.4006e-04,  9.3292e-04, -7.9945e-04, -7.5477e-04],\n",
       "                      [-3.3563e-04,  3.8414e-04, -4.2558e-05, -2.8410e-04],\n",
       "                      [-1.2164e-04, -1.2672e-04, -5.7529e-05, -1.0129e-04]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.k_proj.weight',\n",
       "              tensor([[-7.4577e-03, -5.1346e-03,  1.0399e-02,  ..., -3.8338e-03,\n",
       "                       -1.5480e-02,  9.7275e-03],\n",
       "                      [-9.0790e-04,  5.9471e-03,  1.8265e-02,  ...,  4.2175e-02,\n",
       "                       -8.1100e-03, -8.4381e-03],\n",
       "                      [ 1.1452e-02, -1.8204e-02,  4.9973e-03,  ..., -9.1493e-05,\n",
       "                       -5.8746e-03, -3.9597e-03],\n",
       "                      ...,\n",
       "                      [-5.2948e-03, -1.5366e-02,  3.4058e-02,  ...,  6.9809e-03,\n",
       "                       -2.8946e-02, -1.3609e-03],\n",
       "                      [ 2.5757e-02, -1.8784e-02, -4.4281e-02,  ...,  6.1035e-02,\n",
       "                       -1.1543e-02,  4.7607e-02],\n",
       "                      [ 3.0533e-02,  1.5137e-02, -5.4398e-03,  ..., -3.3447e-02,\n",
       "                       -3.8544e-02,  1.1665e-02]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0199, -0.0052, -0.0356,  ...,  0.0322,  0.0365, -0.0110],\n",
       "                      [ 0.0186,  0.0180,  0.0091,  ...,  0.0012, -0.0164,  0.0129],\n",
       "                      [-0.0282,  0.0037,  0.0214,  ..., -0.0116,  0.0490, -0.0271],\n",
       "                      ...,\n",
       "                      [ 0.0100, -0.0190, -0.0207,  ...,  0.0192, -0.0152, -0.0113],\n",
       "                      [-0.0002, -0.0214, -0.0300,  ..., -0.0118, -0.0090, -0.0157],\n",
       "                      [ 0.0219, -0.0247, -0.0171,  ..., -0.0278, -0.0310,  0.0181]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0015, -0.0144,  0.0066,  ..., -0.0090, -0.0113, -0.0143],\n",
       "                      [ 0.0003, -0.0162,  0.0073,  ..., -0.0102,  0.0123,  0.0100],\n",
       "                      [ 0.0158,  0.0034, -0.0126,  ..., -0.0127,  0.0078,  0.0079],\n",
       "                      [ 0.0083, -0.0043,  0.0116,  ..., -0.0111, -0.0131,  0.0084]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 0.0012,  0.0013, -0.0013,  0.0012],\n",
       "                      [-0.0003, -0.0004,  0.0002, -0.0004],\n",
       "                      [ 0.0016,  0.0016, -0.0014,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0008, -0.0009,  0.0007, -0.0004],\n",
       "                      [ 0.0007,  0.0006, -0.0007,  0.0005],\n",
       "                      [-0.0008, -0.0010,  0.0010, -0.0011]])),\n",
       "             ('llm.base_model.model.model.layers.27.self_attn.o_proj.weight',\n",
       "              tensor([[ 2.5387e-03, -9.6970e-03,  6.9122e-03,  ...,  3.1677e-02,\n",
       "                        9.0866e-03, -2.8152e-02],\n",
       "                      [ 2.9202e-03,  3.2654e-02, -2.0905e-02,  ..., -1.4221e-02,\n",
       "                       -9.7885e-03,  1.2941e-03],\n",
       "                      [-1.3666e-03, -1.4999e-02, -1.6586e-02,  ...,  1.7059e-02,\n",
       "                        6.4430e-03, -5.2490e-03],\n",
       "                      ...,\n",
       "                      [ 2.4002e-02, -5.4321e-03, -1.3573e-02,  ...,  1.4427e-02,\n",
       "                        4.6295e-02, -1.4782e-05],\n",
       "                      [ 3.2135e-02, -2.3087e-02, -1.2108e-02,  ...,  4.7946e-04,\n",
       "                       -4.9629e-03,  2.3270e-02],\n",
       "                      [ 4.0222e-02,  1.9104e-02,  2.6093e-02,  ..., -1.3191e-02,\n",
       "                        3.4409e-03, -1.8219e-02]])),\n",
       "             ('llm.base_model.model.model.layers.27.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0374,  0.0167, -0.0117,  ...,  0.0127,  0.0025, -0.0114],\n",
       "                      [-0.0220,  0.0062, -0.0201,  ...,  0.0287,  0.0296,  0.0343],\n",
       "                      [ 0.0094,  0.0159, -0.0084,  ..., -0.0150, -0.0240,  0.0302],\n",
       "                      ...,\n",
       "                      [ 0.0285,  0.0169,  0.0028,  ..., -0.0070,  0.0187, -0.0102],\n",
       "                      [-0.0185,  0.0283, -0.0264,  ..., -0.0032, -0.0151,  0.0081],\n",
       "                      [ 0.0076, -0.0178, -0.0101,  ..., -0.0075, -0.0160,  0.0010]])),\n",
       "             ('llm.base_model.model.model.layers.27.mlp.up_proj.weight',\n",
       "              tensor([[-0.0046,  0.0173,  0.0268,  ..., -0.0015,  0.0121, -0.0386],\n",
       "                      [-0.0162,  0.0019, -0.0235,  ...,  0.0204, -0.0151, -0.0238],\n",
       "                      [ 0.0281,  0.0107,  0.0417,  ...,  0.0282, -0.0063, -0.0152],\n",
       "                      ...,\n",
       "                      [-0.0088,  0.0268,  0.0298,  ..., -0.0179,  0.0194, -0.0346],\n",
       "                      [ 0.0144,  0.0301,  0.0093,  ...,  0.0151, -0.0147, -0.0149],\n",
       "                      [-0.0051, -0.0081, -0.0094,  ..., -0.0093, -0.0177,  0.0038]])),\n",
       "             ('llm.base_model.model.model.layers.27.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0098, -0.0197,  0.0302,  ..., -0.0185,  0.0127,  0.0004],\n",
       "                      [-0.0074,  0.0133, -0.0148,  ..., -0.0206, -0.0250,  0.0076],\n",
       "                      [ 0.0342,  0.0113,  0.0060,  ..., -0.0331,  0.0041,  0.0297],\n",
       "                      ...,\n",
       "                      [-0.0064,  0.0130,  0.0132,  ...,  0.0119, -0.0510,  0.0311],\n",
       "                      [-0.0207, -0.0032, -0.0170,  ...,  0.0199, -0.0048,  0.0234],\n",
       "                      [ 0.0039,  0.0139, -0.0059,  ...,  0.0275, -0.0055,  0.0032]])),\n",
       "             ('llm.base_model.model.model.layers.27.input_layernorm.weight',\n",
       "              tensor([0.5415, 0.5522, 0.5503,  ..., 0.5513, 0.5522, 0.5552])),\n",
       "             ('llm.base_model.model.model.layers.27.post_attention_layernorm.weight',\n",
       "              tensor([0.4548, 0.4470, 0.4438,  ..., 0.4524, 0.4573, 0.4492])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0003, -0.0175,  0.0064,  ..., -0.0120, -0.0138, -0.0039],\n",
       "                      [ 0.0137, -0.0063, -0.0050,  ...,  0.0118,  0.0024, -0.0017],\n",
       "                      [ 0.0128,  0.0056, -0.0087,  ...,  0.0003, -0.0216,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0038,  0.0320, -0.0537,  ...,  0.0099, -0.0011, -0.0466],\n",
       "                      [ 0.0159, -0.0317, -0.0151,  ...,  0.0249,  0.0421, -0.0620],\n",
       "                      [ 0.0120,  0.0135, -0.0507,  ...,  0.0453,  0.0217, -0.0364]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0104,  0.0003,  0.0071,  ...,  0.0050, -0.0122,  0.0053],\n",
       "                      [ 0.0066, -0.0146,  0.0112,  ...,  0.0052, -0.0090,  0.0056],\n",
       "                      [ 0.0122,  0.0055, -0.0061,  ...,  0.0028,  0.0121,  0.0113],\n",
       "                      [-0.0035, -0.0120,  0.0157,  ..., -0.0054, -0.0092,  0.0041]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 4.9680e-04, -5.1655e-04,  2.9623e-04, -9.7858e-05],\n",
       "                      [-1.1285e-04,  2.8183e-04,  9.0674e-05,  6.9779e-05],\n",
       "                      [ 1.0359e-04,  3.4025e-04,  1.9233e-04,  7.5265e-05],\n",
       "                      ...,\n",
       "                      [ 2.8779e-05,  1.1593e-03, -4.2908e-04, -8.0677e-04],\n",
       "                      [ 2.8653e-04,  1.0331e-03, -1.1226e-04, -8.6486e-04],\n",
       "                      [ 8.0349e-04, -6.4290e-04,  8.4063e-04, -2.9023e-04]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0014, -0.0015,  0.0145,  ..., -0.0027,  0.0100, -0.0224],\n",
       "                      [-0.0142,  0.0020, -0.0199,  ..., -0.0144,  0.0042,  0.0071],\n",
       "                      [ 0.0087,  0.0084, -0.0182,  ..., -0.0160, -0.0068, -0.0044],\n",
       "                      ...,\n",
       "                      [-0.0322, -0.0119,  0.0042,  ..., -0.0078, -0.0459, -0.0023],\n",
       "                      [ 0.0417, -0.0213,  0.0123,  ...,  0.0153,  0.0385,  0.0304],\n",
       "                      [ 0.0213, -0.0121,  0.0045,  ..., -0.0010, -0.0216, -0.0123]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0251,  0.0091,  0.0261,  ..., -0.0193, -0.0279,  0.0174],\n",
       "                      [ 0.0194, -0.0155, -0.0084,  ..., -0.0474,  0.0331, -0.0122],\n",
       "                      [-0.0065,  0.0184, -0.0031,  ...,  0.0081, -0.0423,  0.0120],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0053, -0.0057,  ...,  0.0143, -0.0023, -0.0258],\n",
       "                      [ 0.0457,  0.0059,  0.0410,  ...,  0.0078,  0.0124, -0.0039],\n",
       "                      [ 0.0147,  0.0180, -0.0454,  ...,  0.0274,  0.0037,  0.0018]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 1.1729e-02, -7.1370e-03, -9.2935e-03,  ...,  3.7631e-03,\n",
       "                        1.1467e-02, -1.0466e-04],\n",
       "                      [-1.2902e-02,  2.1445e-03,  3.0403e-03,  ...,  3.2878e-04,\n",
       "                        1.0307e-02,  6.9115e-03],\n",
       "                      [-5.6861e-05,  3.1928e-03, -4.5512e-03,  ...,  1.7114e-02,\n",
       "                       -1.6431e-02,  1.3772e-03],\n",
       "                      [ 1.1051e-02, -7.8964e-03, -9.4051e-03,  ...,  5.2544e-03,\n",
       "                        1.1151e-02, -5.1651e-03]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 0.0013, -0.0016, -0.0012,  0.0014],\n",
       "                      [-0.0014,  0.0018,  0.0014, -0.0016],\n",
       "                      [ 0.0010, -0.0012, -0.0010,  0.0012],\n",
       "                      ...,\n",
       "                      [-0.0011,  0.0009,  0.0013, -0.0011],\n",
       "                      [-0.0013,  0.0012,  0.0013, -0.0013],\n",
       "                      [-0.0021,  0.0020,  0.0022, -0.0013]])),\n",
       "             ('llm.base_model.model.model.layers.28.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0095,  0.0235, -0.0457,  ..., -0.0455,  0.0182,  0.0004],\n",
       "                      [-0.0160, -0.0208,  0.0025,  ..., -0.0132,  0.0195,  0.0316],\n",
       "                      [ 0.0291,  0.0131, -0.0552,  ...,  0.0258,  0.0236, -0.0182],\n",
       "                      ...,\n",
       "                      [ 0.0006, -0.0092,  0.0347,  ..., -0.0128, -0.0393, -0.0069],\n",
       "                      [-0.0092, -0.0533, -0.0163,  ...,  0.0087, -0.0241, -0.0279],\n",
       "                      [-0.0463, -0.0067, -0.0126,  ..., -0.0230, -0.0028,  0.0034]])),\n",
       "             ('llm.base_model.model.model.layers.28.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0012,  0.0024, -0.0002,  ...,  0.0288, -0.0094,  0.0360],\n",
       "                      [-0.0251,  0.0181, -0.0114,  ...,  0.0120,  0.0075,  0.0269],\n",
       "                      [ 0.0152,  0.0313,  0.0239,  ...,  0.0206,  0.0034,  0.0068],\n",
       "                      ...,\n",
       "                      [-0.0132,  0.0318,  0.0063,  ...,  0.0154,  0.0118, -0.0092],\n",
       "                      [ 0.0090, -0.0295, -0.0144,  ..., -0.0157, -0.0166,  0.0012],\n",
       "                      [-0.0294,  0.0181,  0.0138,  ..., -0.0091, -0.0152,  0.0176]])),\n",
       "             ('llm.base_model.model.model.layers.28.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0190,  0.0037,  0.0240,  ...,  0.0287,  0.0179,  0.0177],\n",
       "                      [-0.0153, -0.0247, -0.0011,  ..., -0.0166, -0.0288, -0.0242],\n",
       "                      [ 0.0128,  0.0163, -0.0051,  ...,  0.0092,  0.0022, -0.0233],\n",
       "                      ...,\n",
       "                      [-0.0159, -0.0056,  0.0276,  ..., -0.0052,  0.0035,  0.0029],\n",
       "                      [-0.0241,  0.0069,  0.0010,  ...,  0.0136, -0.0057, -0.0525],\n",
       "                      [-0.0084, -0.0285, -0.0033,  ..., -0.0077,  0.0071, -0.0062]])),\n",
       "             ('llm.base_model.model.model.layers.28.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0080,  0.0394, -0.0107,  ...,  0.0082, -0.0063, -0.0268],\n",
       "                      [ 0.0038, -0.0322,  0.0176,  ..., -0.0338, -0.0060, -0.0268],\n",
       "                      [-0.0157,  0.0246, -0.0098,  ...,  0.0044,  0.0023, -0.0007],\n",
       "                      ...,\n",
       "                      [ 0.0075, -0.0127,  0.0045,  ..., -0.0231, -0.0278,  0.0118],\n",
       "                      [-0.0138, -0.0174,  0.0566,  ..., -0.0210, -0.0004,  0.0105],\n",
       "                      [-0.0257,  0.0095, -0.0124,  ...,  0.0229,  0.0341, -0.0180]])),\n",
       "             ('llm.base_model.model.model.layers.28.input_layernorm.weight',\n",
       "              tensor([0.5625, 0.5674, 0.5591,  ..., 0.5483, 0.5684, 0.5586])),\n",
       "             ('llm.base_model.model.model.layers.28.post_attention_layernorm.weight',\n",
       "              tensor([0.4631, 0.4614, 0.4561,  ..., 0.4673, 0.4607, 0.4580])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 1.9569e-03,  5.0735e-03, -5.0850e-03,  ...,  9.2983e-05,\n",
       "                       -5.7755e-03,  5.1460e-03],\n",
       "                      [-2.4902e-02, -1.9699e-02, -2.4719e-02,  ..., -1.3252e-02,\n",
       "                        4.0627e-04, -5.5046e-03],\n",
       "                      [-1.9684e-02,  3.2074e-02, -2.2590e-04,  ..., -7.9966e-04,\n",
       "                       -7.2556e-03,  1.4565e-02],\n",
       "                      ...,\n",
       "                      [-9.5673e-03,  5.9692e-02, -3.6133e-02,  ...,  1.1581e-02,\n",
       "                       -1.0582e-02, -3.1708e-02],\n",
       "                      [-2.1378e-02, -2.5528e-02,  2.0294e-02,  ..., -9.5139e-03,\n",
       "                       -2.2705e-02,  2.2064e-02],\n",
       "                      [ 1.0271e-03, -4.1016e-02, -1.2222e-02,  ...,  1.0307e-02,\n",
       "                        7.3166e-03, -4.0131e-02]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0072,  0.0038,  0.0060,  ..., -0.0143, -0.0089, -0.0108],\n",
       "                      [ 0.0125,  0.0017,  0.0133,  ..., -0.0096,  0.0100, -0.0009],\n",
       "                      [-0.0091, -0.0047,  0.0107,  ...,  0.0016,  0.0119,  0.0042],\n",
       "                      [-0.0046,  0.0049, -0.0109,  ...,  0.0096, -0.0131,  0.0074]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-8.1458e-04,  2.5599e-04, -2.9929e-04,  7.0926e-04],\n",
       "                      [-1.4769e-04,  2.7586e-04, -1.4588e-04,  2.7411e-04],\n",
       "                      [ 2.5537e-04, -5.8997e-04,  3.4219e-04, -5.6534e-04],\n",
       "                      ...,\n",
       "                      [ 6.9075e-04,  4.1137e-05,  6.2346e-04, -2.9873e-04],\n",
       "                      [ 2.3794e-04,  1.0128e-04,  1.2768e-04, -2.6851e-04],\n",
       "                      [-9.7256e-04,  1.4370e-03, -1.2391e-03,  1.5709e-03]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0380, -0.0121, -0.0169,  ..., -0.0010,  0.0060,  0.0026],\n",
       "                      [-0.0166,  0.0210, -0.0024,  ..., -0.0226,  0.0095, -0.0276],\n",
       "                      [ 0.0177,  0.0100,  0.0181,  ...,  0.0173,  0.0250,  0.0036],\n",
       "                      ...,\n",
       "                      [-0.0353,  0.0393,  0.0056,  ..., -0.0053, -0.0025, -0.0114],\n",
       "                      [ 0.0037, -0.0181, -0.0680,  ..., -0.0136, -0.0139, -0.0389],\n",
       "                      [ 0.0170, -0.0109, -0.0549,  ..., -0.0605, -0.0251,  0.0054]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 1.1375e-02,  4.7188e-03,  3.1403e-02,  ...,  2.5040e-02,\n",
       "                        2.9888e-03,  1.9638e-02],\n",
       "                      [-3.1376e-03,  2.4292e-02,  3.8849e-02,  ..., -2.1561e-02,\n",
       "                        3.0937e-03, -6.7253e-03],\n",
       "                      [-1.4664e-02,  6.9885e-03, -5.7297e-03,  ..., -2.3060e-03,\n",
       "                        2.7893e-02,  1.3535e-02],\n",
       "                      ...,\n",
       "                      [ 8.2474e-03,  2.2568e-02,  1.3458e-02,  ..., -2.4780e-02,\n",
       "                       -6.2027e-03, -1.5251e-02],\n",
       "                      [-2.1076e-04,  3.5736e-02, -2.4002e-02,  ...,  1.6586e-02,\n",
       "                        3.0991e-02, -1.2108e-02],\n",
       "                      [-1.2457e-05, -1.7395e-02,  7.0152e-03,  ...,  4.4746e-03,\n",
       "                       -1.4366e-02,  2.2751e-02]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0111, -0.0123, -0.0058,  ...,  0.0023,  0.0097,  0.0036],\n",
       "                      [-0.0029, -0.0015, -0.0087,  ...,  0.0047,  0.0052, -0.0080],\n",
       "                      [ 0.0096, -0.0010,  0.0049,  ..., -0.0091,  0.0035,  0.0023],\n",
       "                      [ 0.0124,  0.0104, -0.0009,  ..., -0.0018, -0.0010,  0.0088]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-9.2018e-04, -3.6582e-04,  1.0298e-03, -8.8920e-04],\n",
       "                      [-7.8512e-04, -7.7968e-04,  1.0356e-03, -9.9400e-04],\n",
       "                      [-1.4155e-03, -1.2102e-03,  1.4679e-03, -1.2628e-03],\n",
       "                      ...,\n",
       "                      [-1.5951e-03, -1.6916e-03,  1.7382e-03, -1.6555e-03],\n",
       "                      [-1.0429e-03, -9.9854e-04,  8.6694e-04, -8.8627e-04],\n",
       "                      [-1.9321e-04, -1.3457e-04,  1.3624e-04,  1.7742e-05]])),\n",
       "             ('llm.base_model.model.model.layers.29.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0040,  0.0370,  0.0330,  ...,  0.0025, -0.0171, -0.0065],\n",
       "                      [-0.0188, -0.0204, -0.0078,  ...,  0.0108, -0.0267,  0.0141],\n",
       "                      [ 0.0237,  0.0263, -0.0116,  ..., -0.0356,  0.0140, -0.0190],\n",
       "                      ...,\n",
       "                      [-0.0296, -0.0172,  0.0246,  ..., -0.0063, -0.0091, -0.0180],\n",
       "                      [-0.0105, -0.0080,  0.0338,  ..., -0.0014, -0.0132,  0.0063],\n",
       "                      [ 0.0106,  0.0100,  0.0053,  ...,  0.0067,  0.0147, -0.0291]])),\n",
       "             ('llm.base_model.model.model.layers.29.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0089,  0.0257, -0.0094,  ..., -0.0054, -0.0272,  0.0329],\n",
       "                      [ 0.0081,  0.0233, -0.0108,  ..., -0.0231,  0.0124,  0.0028],\n",
       "                      [ 0.0387,  0.0015, -0.0126,  ..., -0.0100,  0.0251,  0.0392],\n",
       "                      ...,\n",
       "                      [-0.0149,  0.0066, -0.0165,  ..., -0.0056,  0.0095,  0.0085],\n",
       "                      [ 0.0136,  0.0132, -0.0341,  ..., -0.0170, -0.0073,  0.0188],\n",
       "                      [ 0.0021,  0.0145,  0.0013,  ...,  0.0206, -0.0187, -0.0144]])),\n",
       "             ('llm.base_model.model.model.layers.29.mlp.up_proj.weight',\n",
       "              tensor([[-0.0013, -0.0028,  0.0068,  ...,  0.0164,  0.0054,  0.0092],\n",
       "                      [-0.0062,  0.0078,  0.0357,  ...,  0.0022, -0.0204,  0.0336],\n",
       "                      [-0.0168, -0.0232, -0.0040,  ..., -0.0459,  0.0023, -0.0383],\n",
       "                      ...,\n",
       "                      [ 0.0304,  0.0122,  0.0108,  ...,  0.0099,  0.0245,  0.0381],\n",
       "                      [-0.0107, -0.0150, -0.0044,  ...,  0.0171,  0.0155, -0.0024],\n",
       "                      [ 0.0093, -0.0029,  0.0159,  ..., -0.0072,  0.0168,  0.0053]])),\n",
       "             ('llm.base_model.model.model.layers.29.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0487,  0.0083,  0.0002,  ...,  0.0140, -0.0167, -0.0139],\n",
       "                      [ 0.0186,  0.0116,  0.0257,  ...,  0.0290,  0.0079,  0.0006],\n",
       "                      [ 0.0020, -0.0204, -0.0120,  ...,  0.0042,  0.0049, -0.0277],\n",
       "                      ...,\n",
       "                      [ 0.0130, -0.0109,  0.0088,  ..., -0.0158, -0.0048, -0.0217],\n",
       "                      [ 0.0267,  0.0179,  0.0310,  ...,  0.0110, -0.0397,  0.0034],\n",
       "                      [ 0.0130, -0.0199, -0.0070,  ..., -0.0154, -0.0089,  0.0008]])),\n",
       "             ('llm.base_model.model.model.layers.29.input_layernorm.weight',\n",
       "              tensor([0.5283, 0.5400, 0.5317,  ..., 0.5269, 0.5347, 0.5557])),\n",
       "             ('llm.base_model.model.model.layers.29.post_attention_layernorm.weight',\n",
       "              tensor([0.4678, 0.4692, 0.4673,  ..., 0.4724, 0.4753, 0.4731])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[ 0.0009, -0.0132, -0.0012,  ..., -0.0022, -0.0042, -0.0032],\n",
       "                      [ 0.0179,  0.0130,  0.0108,  ..., -0.0020, -0.0091, -0.0197],\n",
       "                      [-0.0073, -0.0223,  0.0460,  ...,  0.0150,  0.0044, -0.0325],\n",
       "                      ...,\n",
       "                      [-0.0090, -0.0051, -0.0035,  ...,  0.0128, -0.0102,  0.0055],\n",
       "                      [ 0.0006, -0.0198, -0.0172,  ...,  0.0197,  0.0136, -0.0356],\n",
       "                      [-0.0685, -0.0143,  0.0400,  ..., -0.0074, -0.0018, -0.0064]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0143,  0.0103, -0.0061,  ...,  0.0158, -0.0119,  0.0047],\n",
       "                      [ 0.0065, -0.0013,  0.0013,  ...,  0.0023, -0.0086,  0.0105],\n",
       "                      [-0.0093,  0.0015,  0.0128,  ..., -0.0110, -0.0032, -0.0118],\n",
       "                      [-0.0133,  0.0039,  0.0065,  ...,  0.0080, -0.0098, -0.0119]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[-5.2860e-04, -6.0150e-04,  5.3651e-04,  1.7390e-04],\n",
       "                      [-3.6378e-04, -1.1715e-04, -3.7276e-04, -6.9702e-05],\n",
       "                      [ 2.1356e-04,  2.5451e-04,  3.6757e-04,  8.3664e-05],\n",
       "                      ...,\n",
       "                      [ 9.6236e-04,  9.5166e-04, -6.7675e-04, -8.5137e-04],\n",
       "                      [ 4.2097e-04,  3.5278e-04, -1.0331e-03, -6.0535e-04],\n",
       "                      [ 2.2883e-04,  4.6763e-04,  3.0325e-04, -5.8228e-04]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0275, -0.0201,  0.0002,  ..., -0.0097,  0.0120,  0.0084],\n",
       "                      [ 0.0382,  0.0166,  0.0061,  ..., -0.0040, -0.0082,  0.0002],\n",
       "                      [-0.0052, -0.0138,  0.0249,  ..., -0.0009, -0.0089, -0.0014],\n",
       "                      ...,\n",
       "                      [ 0.0062,  0.0260, -0.0022,  ...,  0.0551,  0.0054, -0.0027],\n",
       "                      [ 0.0118, -0.0659,  0.0357,  ...,  0.0063, -0.0078, -0.0227],\n",
       "                      [-0.0387, -0.0151,  0.0169,  ...,  0.0032,  0.0134, -0.0194]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[-0.0018, -0.0357,  0.0249,  ..., -0.0298, -0.0350,  0.0306],\n",
       "                      [ 0.0135,  0.0248,  0.0309,  ..., -0.0127,  0.0388,  0.0060],\n",
       "                      [-0.0175,  0.0116, -0.0164,  ...,  0.0062, -0.0264, -0.0140],\n",
       "                      ...,\n",
       "                      [ 0.0182, -0.0054, -0.0011,  ..., -0.0270, -0.0018,  0.0387],\n",
       "                      [-0.0026, -0.0474,  0.0211,  ...,  0.0314, -0.0038,  0.0261],\n",
       "                      [-0.0009,  0.0055,  0.0146,  ..., -0.0107, -0.0567, -0.0255]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0058,  0.0139,  0.0053,  ..., -0.0094, -0.0128,  0.0118],\n",
       "                      [-0.0046,  0.0115, -0.0025,  ..., -0.0093,  0.0061, -0.0030],\n",
       "                      [-0.0105, -0.0024, -0.0053,  ...,  0.0077, -0.0030,  0.0033],\n",
       "                      [ 0.0127,  0.0121, -0.0095,  ..., -0.0125, -0.0040, -0.0079]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[-6.3209e-04, -1.5525e-04, -5.3040e-04,  8.0738e-04],\n",
       "                      [-1.3684e-03,  5.5743e-04, -1.3213e-03,  1.5526e-03],\n",
       "                      [ 1.5611e-03, -1.2434e-03,  1.3099e-03, -1.6009e-03],\n",
       "                      ...,\n",
       "                      [-8.6500e-04, -4.7705e-06, -9.3405e-04,  4.3844e-04],\n",
       "                      [-7.1527e-04, -1.5062e-04, -2.8467e-04, -8.6971e-04],\n",
       "                      [ 1.4727e-03, -1.6384e-03,  1.0388e-03, -1.1988e-03]])),\n",
       "             ('llm.base_model.model.model.layers.30.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0073,  0.0093, -0.0099,  ...,  0.0065, -0.0172, -0.0224],\n",
       "                      [-0.0199, -0.0203, -0.0018,  ...,  0.0165, -0.0221, -0.0206],\n",
       "                      [-0.0191, -0.0026,  0.0190,  ..., -0.0510, -0.0134, -0.0135],\n",
       "                      ...,\n",
       "                      [ 0.0071,  0.0028,  0.0048,  ..., -0.0266,  0.0097,  0.0143],\n",
       "                      [ 0.0288, -0.0111,  0.0139,  ...,  0.0285, -0.0031,  0.0074],\n",
       "                      [-0.0053,  0.0117,  0.0047,  ..., -0.0030,  0.0140, -0.0164]])),\n",
       "             ('llm.base_model.model.model.layers.30.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0332, -0.0300, -0.0063,  ...,  0.0113, -0.0076,  0.0041],\n",
       "                      [-0.0184, -0.0027,  0.0309,  ..., -0.0031, -0.0026,  0.0327],\n",
       "                      [-0.0199, -0.0101, -0.0297,  ...,  0.0128,  0.0092, -0.0043],\n",
       "                      ...,\n",
       "                      [-0.0232, -0.0113,  0.0205,  ..., -0.0138, -0.0242, -0.0137],\n",
       "                      [ 0.0318,  0.0233, -0.0120,  ...,  0.0133, -0.0393,  0.0030],\n",
       "                      [-0.0109, -0.0257, -0.0210,  ..., -0.0016,  0.0120, -0.0216]])),\n",
       "             ('llm.base_model.model.model.layers.30.mlp.up_proj.weight',\n",
       "              tensor([[-0.0027,  0.0098,  0.0124,  ...,  0.0170,  0.0221,  0.0028],\n",
       "                      [-0.0273, -0.0280,  0.0363,  ...,  0.0018, -0.0110, -0.0165],\n",
       "                      [-0.0344, -0.0224, -0.0375,  ..., -0.0160, -0.0052,  0.0155],\n",
       "                      ...,\n",
       "                      [-0.0210, -0.0117,  0.0161,  ...,  0.0165, -0.0138, -0.0216],\n",
       "                      [-0.0075,  0.0028, -0.0150,  ...,  0.0100, -0.0146,  0.0159],\n",
       "                      [-0.0071, -0.0228,  0.0011,  ..., -0.0155, -0.0002,  0.0183]])),\n",
       "             ('llm.base_model.model.model.layers.30.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0191, -0.0148, -0.0311,  ...,  0.0282, -0.0043,  0.0063],\n",
       "                      [ 0.0267, -0.0004,  0.0441,  ...,  0.0138,  0.0055, -0.0071],\n",
       "                      [ 0.0009, -0.0086, -0.0191,  ..., -0.0014,  0.0123,  0.0182],\n",
       "                      ...,\n",
       "                      [-0.0305,  0.0054, -0.0227,  ...,  0.0215, -0.0225, -0.0110],\n",
       "                      [ 0.0010, -0.0316,  0.0034,  ...,  0.0217,  0.0023,  0.0010],\n",
       "                      [-0.0068, -0.0131, -0.0249,  ...,  0.0094, -0.0025, -0.0179]])),\n",
       "             ('llm.base_model.model.model.layers.30.input_layernorm.weight',\n",
       "              tensor([0.5762, 0.5830, 0.5654,  ..., 0.5508, 0.5630, 0.5820])),\n",
       "             ('llm.base_model.model.model.layers.30.post_attention_layernorm.weight',\n",
       "              tensor([0.4795, 0.4893, 0.4788,  ..., 0.4819, 0.4819, 0.4788])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight',\n",
       "              tensor([[-0.0332,  0.0159,  0.0198,  ...,  0.0205, -0.0019, -0.0206],\n",
       "                      [-0.0085, -0.0209, -0.0329,  ...,  0.0016, -0.0044, -0.0066],\n",
       "                      [-0.0108,  0.0208,  0.0163,  ...,  0.0050,  0.0017, -0.0007],\n",
       "                      ...,\n",
       "                      [ 0.0160, -0.0073, -0.0211,  ..., -0.0111,  0.0246, -0.0224],\n",
       "                      [-0.0196,  0.0057, -0.0103,  ..., -0.0019,  0.0014,  0.0026],\n",
       "                      [-0.0533, -0.0104,  0.0331,  ...,  0.0421,  0.0126,  0.0307]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight',\n",
       "              tensor([[ 0.0127,  0.0050, -0.0066,  ..., -0.0082,  0.0040,  0.0034],\n",
       "                      [ 0.0033,  0.0128, -0.0077,  ..., -0.0134, -0.0046,  0.0075],\n",
       "                      [-0.0057,  0.0070,  0.0040,  ..., -0.0124, -0.0058, -0.0083],\n",
       "                      [ 0.0128, -0.0022,  0.0092,  ..., -0.0110, -0.0090,  0.0148]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight',\n",
       "              tensor([[ 8.0288e-04,  8.4413e-04, -5.5174e-04, -2.4712e-04],\n",
       "                      [ 2.6649e-04,  2.7946e-04,  9.7116e-05, -3.6281e-04],\n",
       "                      [-6.8633e-04, -6.4406e-04,  6.6483e-04,  7.9168e-05],\n",
       "                      ...,\n",
       "                      [-1.4655e-03, -1.1528e-03,  1.3865e-03,  1.5648e-03],\n",
       "                      [-1.4062e-03, -8.3670e-04,  6.5299e-04,  6.0861e-04],\n",
       "                      [-1.8515e-03, -1.5257e-03,  1.7356e-03,  1.7171e-03]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0109, -0.0220,  0.0166,  ...,  0.0042, -0.0030, -0.0202],\n",
       "                      [ 0.0227, -0.0135,  0.0127,  ...,  0.0116, -0.0023, -0.0073],\n",
       "                      [ 0.0094,  0.0010, -0.0095,  ..., -0.0060,  0.0105, -0.0259],\n",
       "                      ...,\n",
       "                      [ 0.0237, -0.0323, -0.0242,  ..., -0.0107, -0.0135, -0.0502],\n",
       "                      [ 0.0168,  0.0148,  0.0158,  ..., -0.0219, -0.0229,  0.0221],\n",
       "                      [-0.0764, -0.0336,  0.0095,  ..., -0.0092, -0.0015,  0.0050]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight',\n",
       "              tensor([[ 0.0139, -0.0297, -0.0063,  ...,  0.0089,  0.0010,  0.0131],\n",
       "                      [ 0.0215,  0.0086,  0.0181,  ...,  0.0055,  0.0362,  0.0128],\n",
       "                      [ 0.0120, -0.0039, -0.0173,  ...,  0.0132,  0.0012,  0.0331],\n",
       "                      ...,\n",
       "                      [-0.0027, -0.0098, -0.0137,  ..., -0.0179, -0.0022,  0.0254],\n",
       "                      [ 0.0097, -0.0236,  0.0166,  ..., -0.0096, -0.0280,  0.0117],\n",
       "                      [-0.0126, -0.0257,  0.0281,  ...,  0.0208, -0.0060,  0.0403]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight',\n",
       "              tensor([[-0.0128,  0.0136,  0.0098,  ..., -0.0067, -0.0100,  0.0036],\n",
       "                      [-0.0035, -0.0107,  0.0083,  ...,  0.0132,  0.0139, -0.0034],\n",
       "                      [ 0.0064,  0.0055, -0.0018,  ..., -0.0076,  0.0096, -0.0044],\n",
       "                      [ 0.0121, -0.0079, -0.0083,  ...,  0.0122,  0.0135, -0.0060]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight',\n",
       "              tensor([[ 1.2613e-03, -5.0304e-05,  9.5345e-05,  1.9119e-04],\n",
       "                      [-2.8407e-04,  8.2602e-04,  1.1341e-03,  2.3687e-04],\n",
       "                      [ 1.9326e-04,  4.9517e-04,  2.3830e-04,  1.6165e-04],\n",
       "                      ...,\n",
       "                      [-7.7665e-04,  9.6276e-04,  1.1017e-03,  1.1513e-03],\n",
       "                      [ 8.6610e-05, -8.5330e-04, -6.3668e-04, -1.0241e-03],\n",
       "                      [ 1.2546e-03, -4.3120e-04, -4.6550e-04, -3.6620e-04]])),\n",
       "             ('llm.base_model.model.model.layers.31.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0066,  0.0279, -0.0033,  ..., -0.0037, -0.0124, -0.0500],\n",
       "                      [-0.0092,  0.0047, -0.0268,  ...,  0.0272, -0.0182, -0.0139],\n",
       "                      [ 0.0102,  0.0002,  0.0011,  ..., -0.0166,  0.0254,  0.0085],\n",
       "                      ...,\n",
       "                      [ 0.0078, -0.0185,  0.0277,  ..., -0.0204, -0.0109, -0.0162],\n",
       "                      [ 0.0018,  0.0201, -0.0201,  ..., -0.0220, -0.0139, -0.0201],\n",
       "                      [ 0.0088,  0.0174, -0.0103,  ...,  0.0327, -0.0205,  0.0061]])),\n",
       "             ('llm.base_model.model.model.layers.31.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0037, -0.0107,  0.0315,  ...,  0.0148,  0.0169,  0.0031],\n",
       "                      [-0.0732, -0.0261,  0.0036,  ...,  0.0094, -0.0175,  0.0177],\n",
       "                      [ 0.0185,  0.0026, -0.0117,  ..., -0.0053, -0.0146, -0.0077],\n",
       "                      ...,\n",
       "                      [-0.0144, -0.0255,  0.0116,  ...,  0.0041,  0.0172,  0.0292],\n",
       "                      [ 0.0349,  0.0157, -0.0313,  ...,  0.0367, -0.0139, -0.0098],\n",
       "                      [ 0.0232, -0.0327, -0.0323,  ..., -0.0126,  0.0137,  0.0055]])),\n",
       "             ('llm.base_model.model.model.layers.31.mlp.up_proj.weight',\n",
       "              tensor([[-4.1107e-02, -1.5961e-02,  2.9907e-02,  ...,  5.9624e-03,\n",
       "                       -1.1475e-02,  3.6030e-03],\n",
       "                      [ 2.2217e-02,  3.1616e-02,  5.7373e-03,  ..., -1.7868e-02,\n",
       "                        9.4473e-05, -9.6083e-04],\n",
       "                      [-5.9662e-03,  7.9727e-03, -1.7181e-02,  ...,  1.0094e-02,\n",
       "                        2.9526e-03, -1.0803e-02],\n",
       "                      ...,\n",
       "                      [ 1.3641e-02, -1.0223e-02,  1.1940e-03,  ...,  6.6185e-04,\n",
       "                        3.4973e-02, -1.8372e-02],\n",
       "                      [ 3.5763e-03,  3.2902e-03, -2.2247e-02,  ...,  2.6306e-02,\n",
       "                        1.1307e-02, -2.0683e-04],\n",
       "                      [ 4.3030e-02, -3.9032e-02, -1.7328e-03,  ..., -6.3477e-03,\n",
       "                        3.4771e-03,  2.4292e-02]])),\n",
       "             ('llm.base_model.model.model.layers.31.mlp.down_proj.weight',\n",
       "              tensor([[-0.0009, -0.0274, -0.0075,  ..., -0.0367, -0.0146,  0.0255],\n",
       "                      [ 0.0412,  0.0016, -0.0052,  ..., -0.0028, -0.0156,  0.0131],\n",
       "                      [-0.0135, -0.0126,  0.0250,  ...,  0.0333, -0.0016,  0.0234],\n",
       "                      ...,\n",
       "                      [ 0.0035,  0.0316, -0.0008,  ...,  0.0105,  0.0063,  0.0218],\n",
       "                      [ 0.0004,  0.0481, -0.0085,  ..., -0.0069,  0.0214,  0.0224],\n",
       "                      [ 0.0258, -0.0349,  0.0156,  ...,  0.0079,  0.0019,  0.0269]])),\n",
       "             ('llm.base_model.model.model.layers.31.input_layernorm.weight',\n",
       "              tensor([0.4868, 0.4861, 0.4358,  ..., 0.4312, 0.4556, 0.4807])),\n",
       "             ('llm.base_model.model.model.layers.31.post_attention_layernorm.weight',\n",
       "              tensor([0.4331, 0.4373, 0.4414,  ..., 0.4243, 0.4097, 0.4282])),\n",
       "             ('llm.base_model.model.model.norm.weight',\n",
       "              tensor([1.8701, 1.8701, 1.8066,  ..., 1.7207, 1.8301, 1.6035])),\n",
       "             ('llm.base_model.model.lm_head.weight',\n",
       "              tensor([[-0.0036,  0.0032, -0.0072,  ...,  0.0056, -0.0080,  0.0069],\n",
       "                      [-0.0325,  0.0469, -0.0017,  ..., -0.0206,  0.0173,  0.0347],\n",
       "                      [-0.0130,  0.0034,  0.0184,  ..., -0.0283,  0.0136, -0.0086],\n",
       "                      ...,\n",
       "                      [ 0.0030,  0.0292,  0.0119,  ..., -0.0028,  0.0168,  0.0009],\n",
       "                      [ 0.0019,  0.0365, -0.0042,  ..., -0.0017,  0.0129,  0.0137],\n",
       "                      [ 0.0155, -0.0093,  0.0080,  ...,  0.0223, -0.0022,  0.0019]]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from prismatic.models.materialize import get_llm_backbone_and_tokenizer, get_vision_backbone_and_transform\n",
    "from prismatic.models.registry import GLOBAL_REGISTRY, MODEL_REGISTRY\n",
    "from prismatic.models.vlms import PrismaticVLM\n",
    "from prismatic.overwatch import initialize_overwatch\n",
    "from prismatic.models import load\n",
    "\n",
    "import torch\n",
    "from lm_eval import evaluator\n",
    "\n",
    "# Initialize Overwatch =>> Wraps `logging.Logger`\n",
    "overwatch = initialize_overwatch(__name__)\n",
    "\n",
    "\n",
    "# === HF Hub Repository ===\n",
    "# HF_HUB_REPO = \"TRI-ML/prismatic-vlms\"\n",
    "\n",
    "SELECTED_NLP_TASKS = [\"wsc273\",\"arc_easy\",\"arc_challenge\",\"winogrande\",\"lambada_standard\"] #, \"webqs\"] [\"wsc273\"]#\n",
    "\n",
    "# === Available Models ===\n",
    "def available_models() -> List[str]:\n",
    "    return list(MODEL_REGISTRY.keys())\n",
    "\n",
    "\n",
    "def available_model_names() -> List[str]:\n",
    "    return list(GLOBAL_REGISTRY.items())\n",
    "\n",
    "\n",
    "def get_model_description(model_id_or_name: str) -> str:\n",
    "    if model_id_or_name not in GLOBAL_REGISTRY:\n",
    "        raise ValueError(f\"Couldn't find `{model_id_or_name = }; check `prismatic.available_model_names()`\")\n",
    "\n",
    "    # Print Description & Return\n",
    "    print(json.dumps(description := GLOBAL_REGISTRY[model_id_or_name][\"description\"], indent=2))\n",
    "\n",
    "    return description\n",
    "\n",
    "\n",
    "# === Load Pretrained Model ===\n",
    "\n",
    "\n",
    "def load_and_write(write_checkpoint_path, model_id_or_path):\n",
    "    # if model_id_path already contains checkpoint_llm_only folder then skip\n",
    "    if os.path.exists(os.path.join(write_checkpoint_path, \"checkpoint_llm_only\")):\n",
    "        overwatch.info(f\"Checkpoint already exists at {write_checkpoint_path}\")\n",
    "        # if checkpoints_base_llm also exists then skip\n",
    "        if os.path.exists(os.path.join(write_checkpoint_path, \"checkpoints_base_llm\")):\n",
    "            overwatch.info(f\"Base checkpoint already exists at {write_checkpoint_path}\")\n",
    "            return\n",
    "        \n",
    "    vlm = load(model_id_or_path)\n",
    "    llm_hugface_save_path = os.path.join(\n",
    "        write_checkpoint_path,\n",
    "        \"checkpoint_llm_only\",\n",
    "    )\n",
    "    llm_base_path = os.path.join(\n",
    "        write_checkpoint_path,\n",
    "        \"checkpoints_base_llm\",\n",
    "    )\n",
    "    overwatch.info(f\"Writing LLM & Tokenizer to checkpoint: {llm_hugface_save_path}\")\n",
    "    llm_backbone = vlm.llm_backbone\n",
    "    llm_backbone.llm.save_pretrained(llm_hugface_save_path)\n",
    "    llm_backbone.llm.base_model.save_pretrained(llm_base_path)\n",
    "    llm_backbone.tokenizer.save_pretrained(llm_base_path)\n",
    "    llm_backbone.tokenizer.save_pretrained(llm_hugface_save_path)\n",
    "    return llm_hugface_save_path\n",
    "\n",
    "\n",
    "def nlp_evaluation(llm_checkpoint_path):\n",
    "    print(f\"\\n\\t NLP Evaluation: {llm_checkpoint_path}\")\n",
    "    task_names = SELECTED_NLP_TASKS\n",
    "    model_args = f\"pretrained={str(llm_checkpoint_path)},trust_remote_code=True\"\n",
    "    print(f\"Evaluating on {task_names} with model_args: {model_args}\")\n",
    "    \n",
    "    results = evaluator.simple_evaluate( \n",
    "            model=\"hf\",\n",
    "            model_args=model_args,\n",
    "            tasks=task_names,\n",
    "            device=\"cuda:0\",\n",
    "            log_samples=True,\n",
    "            output_path=llm_checkpoint_path\n",
    "        )\n",
    "    with open(f\"{llm_checkpoint_path}/nlp_evaluation_results.log\", \"w\") as log_file:\n",
    "        log_file.write(json.dumps(results, indent=4))\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser(description=\"Process VLM checkpoint for NLP evaluation.\")\n",
    "    # parser.add_argument('--write_path', type=str, required=True, help='Path to write the LLM checkpoint')\n",
    "    # parser.add_argument('--checkpoint_path', type=str, required=True, help='Path to the VLM checkpoint')\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "    # main(args.write_path, args.checkpoint_path)\n",
    "    runs_directory = Path(\"/localdisk/ssrivas9/prismatic-vlms/runs\")\n",
    "    for checkpoint_dir in runs_directory.iterdir():\n",
    "        if checkpoint_dir.is_dir():  # ensure it's a directory\n",
    "            write_path = checkpoint_dir\n",
    "            print(f\"\\n Processing: {checkpoint_dir}\\n\")\n",
    "            load_and_write(write_path, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
