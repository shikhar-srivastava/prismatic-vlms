{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "results_nlp = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        results_nlp = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance}}\n",
      "  \\label{tab:model_performance}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c|}{\\textbf{NLU Avg.}} & \\multicolumn{2}{c}{\\textbf{NLG Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\uparrow$ & Acc $\\uparrow$ & $\\Delta \\uparrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "LLaVA + LLaMA2 Base (7B) & 75.9 & 55.2 & 45.4 & 60.2 & 59.2 & 2.7 & 70.0 & 0.4 & 68.7 \\\\\n",
      "LLaVA + LLaMA2 Instruct (7B) & 74.5 & 56.3 & 45.9 & 56.2 & 58.2 & 0.3 & 68.8 & -2.0 & 62.3 \\\\\n",
      "LLaVA + Pythia Instruct (1.4B) & 66.2 & 38.5 & 35.5 & 46.1 & 46.6 & -1.1 & 53.0 & -8.1 & 40.9 \\\\\n",
      "LLaVA + Pythia (1.4B) & 64.0 & 39.8 & 34.4 & 44.5 & 45.7 & -4.6 & 49.5 & -12.6 & 36.3 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load the results from the JSON file\n",
    "with open('results_nlp.json') as f:\n",
    "    results_dict = json.load(f)\n",
    "\n",
    "# Define the models of interest and their corresponding baselines with labels\n",
    "models_of_interest = {\n",
    "    \"stage-final-llava-v15-pythia+1p4b\": (\"reproduction-align-pythia+1p4b\", \"LLaVA + Pythia Instruct (1.4B)\"),\n",
    "    \"stage-final-llava-v15-pythia+1p4b-instruct-old\": (\"reproduction-align-pythia+1p4b-instruct-old\", \"LLaVA + Pythia (1.4B)\"),\n",
    "    \"reproduction-llava-v15+7b+stage-finetune+x7\": (\"reproduction-llava-v15+7b+stage-align+x7\", \"LLaVA + LLaMA2 Instruct (7B)\"),\n",
    "    \"reproduction-llama2\": (\"vila_base_llm\", \"LLaVA + LLaMA2 Base (7B)\")\n",
    "}\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.1f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Prepare the data for the LaTeX tables\n",
    "table_data = []\n",
    "\n",
    "for model, (baseline, label) in models_of_interest.items():\n",
    "    accuracies = results_dict[model]\n",
    "    baseline_accuracies = results_dict[baseline]\n",
    "    \n",
    "    avg_acc_vl = sum(accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]) / 4\n",
    "    \n",
    "    nlu_deltas = {dataset: accuracies[dataset] - baseline_accuracies.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\"]}\n",
    "    avg_delta_nlu = sum(nlu_deltas[dataset] for dataset in nlu_deltas) / 4\n",
    "    avg_acc_nlu = sum(accuracies[dataset] for dataset in nlu_deltas) / 4\n",
    "    \n",
    "    delta_nlg = accuracies[\"lambada_standard\"] - baseline_accuracies.get(\"lambada_standard\", 0)\n",
    "    avg_acc_nlg = accuracies[\"lambada_standard\"]\n",
    "    \n",
    "    table_data.append((label, accuracies, avg_acc_vl, avg_delta_nlu, avg_acc_nlu, delta_nlg, avg_acc_nlg))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NLG Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[5]), reverse=True)\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance}}\n",
    "  \\\\label{tab:model_performance}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c|}{\\\\textbf{NLU Avg.}} & \\\\multicolumn{2}{c}{\\\\textbf{NLG Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\uparrow$ & Acc $\\\\uparrow$ & $\\\\Delta \\\\uparrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for label, accuracies, avg_acc_vl, avg_delta_nlu, avg_acc_nlu, delta_nlg, avg_acc_nlg in table_data:\n",
    "    latex_code += \"{label} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nlu} & {avg_acc_nlu} & {delta_nlg} & {avg_acc_nlg} \\\\\\\\\\n\".format(\n",
    "        label=label,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        avg_acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nlu=format_value(avg_delta_nlu),\n",
    "        avg_acc_nlu=format_value(avg_acc_nlu),\n",
    "        delta_nlg=format_value(delta_nlg),\n",
    "        avg_acc_nlg=format_value(avg_acc_nlg)\n",
    "    )\n",
    "\n",
    "latex_code += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
