{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Model Performance:} Avg. NLU and NLG Deltas and VL Performance of Each Mitigation Method}\n",
      "  \\label{tab:nlu_nlg_vl_performance}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|c|c|c}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\textbf{Avg. NLU $\\Delta \\downarrow$} & \\textbf{Avg. NLG $\\delta \\downarrow$} & \\textbf{VL Performance (A $\\uparrow$)} \\\\\n",
      "     \\midrule\n",
      "Pythia 0.16B & 0.94 & 12.01 & 5.29 \\\\\n",
      "Pythia 0.41B & -1.19 & 8.62 & 30.37 \\\\\n",
      "Pythia 1.0B & -1.63 & 4.95 & 43.58 \\\\\n",
      "Pythia 1.4B & 0.55 & 8.07 & 43.97 \\\\\n",
      "Pythia 2.8B & 1.74 & 9.18 & 44.20 \\\\\n",
      "Pythia 1.4B (Inst.) & -1.20 & -1.01 & 43.93 \\\\\n",
      "Phi2 3.0B & 2.60 & 4.39 & 25.33 \\\\\n",
      "Vicuna1.5 7.0B & -0.98 & 2.04 & 56.55 \\\\\n",
      "LLaMA2 7.0B & -2.15 & -0.43 & 57.22 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "# Load the JSON data from the file\n",
    "with open('results_nlp.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Define the filtering criteria and datasets\n",
    "nlu_datasets = [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\"]\n",
    "nlg_datasets = [\"lambada_standard\"]\n",
    "vl_datasets = [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]\n",
    "\n",
    "# Define explicit mappings for LLaVA Originals and Base LLMs for each model type\n",
    "model_mappings = {\n",
    "    'Pythia': {\n",
    "        'llava_original': {\n",
    "            0.16: \"stage-final-llava-v15-pythia+160m\",\n",
    "            0.41: \"stage-final-llava-v15-pythia+410m\",\n",
    "            1.0: \"stage-final-llava-v15-pythia+1b\",\n",
    "            1.4: \"stage-final-llava-v15-pythia+1p4b\",\n",
    "            2.8: \"stage-final-llava-v15-pythia+2p8b\",\n",
    "            '1.4-instruct': \"stage-final-llava-v15-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        },\n",
    "        'base_llm': {\n",
    "            0.16: \"reproduction-align-pythia+160m\",\n",
    "            0.41: \"reproduction-align-pythia+410m\",\n",
    "            1.0: \"reproduction-align-pythia+1b\",\n",
    "            1.4: \"reproduction-align-pythia+1p4b\",\n",
    "            2.8: \"reproduction-align-pythia+2p8b\",\n",
    "            '1.4-instruct': \"reproduction-align-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        }\n",
    "    },\n",
    "    'Phi2': {\n",
    "        'llava_original': {\n",
    "            'phi2+3b': \"stage-final-llava-v15-phi2+3b-repeat\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            'phi2+3b': \"reproduction-align-phi2+3b\"\n",
    "        }\n",
    "    },\n",
    "    'Vicuna1.5': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-finetune+x7\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-align+x7\"\n",
    "        }\n",
    "    },\n",
    "    'LLaMA2': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llama2\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"vila_base_llm\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to calculate NLU and NLG forgetting using harmonic mean\n",
    "def calculate_forgetting_and_performance(model_mappings, results):\n",
    "    scores = []\n",
    "    for model_type, mappings in model_mappings.items():\n",
    "        for scale, llava_model in mappings['llava_original'].items():\n",
    "            base_model = mappings['base_llm'][scale]\n",
    "            if llava_model in results and base_model in results:\n",
    "                llava_nlu_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in nlu_datasets]\n",
    "                base_nlu_scores = [results[base_model].get(dataset, np.nan) * 100 for dataset in nlu_datasets]\n",
    "                llava_nlg_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in nlg_datasets]\n",
    "                base_nlg_scores = [results[base_model].get(dataset, np.nan) * 100 for dataset in nlg_datasets]\n",
    "                vl_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in vl_datasets]\n",
    "                \n",
    "                valid_llava_nlu_scores = [score for score in llava_nlu_scores if not np.isnan(score)]\n",
    "                valid_base_nlu_scores = [score for score in base_nlu_scores if not np.isnan(score)]\n",
    "                valid_llava_nlg_scores = [score for score in llava_nlg_scores if not np.isnan(score)]\n",
    "                valid_base_nlg_scores = [score for score in base_nlg_scores if not np.isnan(score)]\n",
    "                valid_vl_scores = [score for score in vl_scores if not np.isnan(score)]\n",
    "                \n",
    "                if valid_llava_nlu_scores and valid_base_nlu_scores:\n",
    "                    llava_hmean_nlu = hmean(valid_llava_nlu_scores)\n",
    "                    base_hmean_nlu = hmean(valid_base_nlu_scores)\n",
    "                    nlu_forgetting = base_hmean_nlu - llava_hmean_nlu\n",
    "                else:\n",
    "                    nlu_forgetting = np.nan\n",
    "                \n",
    "                if valid_llava_nlg_scores and valid_base_nlg_scores:\n",
    "                    llava_hmean_nlg = hmean(valid_llava_nlg_scores)\n",
    "                    base_hmean_nlg = hmean(valid_base_nlg_scores)\n",
    "                    nlg_forgetting = base_hmean_nlg - llava_hmean_nlg\n",
    "                else:\n",
    "                    nlg_forgetting = np.nan\n",
    "                \n",
    "                avg_vl_performance = hmean(valid_vl_scores) if valid_vl_scores else np.nan\n",
    "                \n",
    "                scores.append((model_type, scale, nlu_forgetting, nlg_forgetting, avg_vl_performance))\n",
    "    return scores\n",
    "\n",
    "# Calculate forgetting and performance for each model type\n",
    "scores = calculate_forgetting_and_performance(model_mappings, results)\n",
    "\n",
    "# Rename scales for Phi and Vicuna models\n",
    "scale_rename = {\n",
    "    'phi2+3b': '3.0',\n",
    "    '7b': '7.0'\n",
    "}\n",
    "\n",
    "# Adjust the scales for the plots\n",
    "for i in range(len(scores)):\n",
    "    model_type, scale, nlu_forgetting, nlg_forgetting, vl_performance = scores[i]\n",
    "    if model_type in ['Phi2', 'Vicuna1.5', 'LLaMA2']:\n",
    "        scale = scale_rename.get(scale, scale)\n",
    "    scores[i] = (model_type, scale, nlu_forgetting, nlg_forgetting, vl_performance)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Avg. NLU and NLG Deltas and VL Performance of Each Mitigation Method}\n",
    "  \\\\label{tab:nlu_nlg_vl_performance}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|c|c|c}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\textbf{Avg. NLU $\\\\Delta \\\\downarrow$} & \\\\textbf{Avg. NLG $\\\\delta \\\\downarrow$} & \\\\textbf{VL Performance (A $\\\\uparrow$)} \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Add the scores to the LaTeX table\n",
    "for model_type, scale, nlu_forgetting, nlg_forgetting, vl_performance in scores:\n",
    "    if scale == '1.4-instruct':\n",
    "        scale = '1.4'\n",
    "        latex_code += f\"{model_type} {scale}B (Inst.) & {nlu_forgetting:.2f} & {nlg_forgetting:.2f} & {vl_performance:.2f} \\\\\\\\\\n\"\n",
    "    else:\n",
    "        latex_code += f\"{model_type} {scale}B & {nlu_forgetting:.2f} & {nlg_forgetting:.2f} & {vl_performance:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_code += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Model Performance:} Avg. NLU and NLG Deltas of Each Mitigation Method}\n",
      "  \\label{tab:nlu_nlg_performance}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|c|c|c}\n",
      "     \\toprule\n",
      "     \\textbf{Model Family} & \\textbf{Model Scale} & \\textbf{Avg. NLU $\\Delta \\downarrow$} & \\textbf{Avg. NLG $\\delta \\downarrow$} \\\\\n",
      "     \\midrule\n",
      "\\multirow{6}{*}{Pythia} \n",
      "& 0.16B & 0.94 & 12.01 \\\\\n",
      "& 0.41B & -1.19 & 8.62 \\\\\n",
      "& 1.0B & -1.63 & 4.95 \\\\\n",
      "& 1.4B & 0.55 & 8.07 \\\\\n",
      "& 2.8B & 1.74 & 9.18 \\\\\n",
      "& 1.4B (Inst.) & -1.20 & -1.01 \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Phi2} \n",
      "& 3.0B & 2.60 & 4.39 \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{Vicuna1.5} \n",
      "& 7.0B & -0.98 & 2.04 \\\\\n",
      "\\midrule\n",
      "\\multirow{1}{*}{LLaMA2} \n",
      "& 7.0B & -2.15 & -0.43 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Define the filtering criteria and datasets\n",
    "nlu_datasets = [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\"]\n",
    "nlg_datasets = [\"lambada_standard\"]\n",
    "vl_datasets = [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]\n",
    "\n",
    "# Define explicit mappings for LLaVA Originals and Base LLMs for each model type\n",
    "model_mappings = {\n",
    "    'Pythia': {\n",
    "        'llava_original': {\n",
    "            0.16: \"stage-final-llava-v15-pythia+160m\",\n",
    "            0.41: \"stage-final-llava-v15-pythia+410m\",\n",
    "            1.0: \"stage-final-llava-v15-pythia+1b\",\n",
    "            1.4: \"stage-final-llava-v15-pythia+1p4b\",\n",
    "            2.8: \"stage-final-llava-v15-pythia+2p8b\",\n",
    "            '1.4-instruct': \"stage-final-llava-v15-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        },\n",
    "        'base_llm': {\n",
    "            0.16: \"reproduction-align-pythia+160m\",\n",
    "            0.41: \"reproduction-align-pythia+410m\",\n",
    "            1.0: \"reproduction-align-pythia+1b\",\n",
    "            1.4: \"reproduction-align-pythia+1p4b\",\n",
    "            2.8: \"reproduction-align-pythia+2p8b\",\n",
    "            '1.4-instruct': \"reproduction-align-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        }\n",
    "    },\n",
    "    'Phi2': {\n",
    "        'llava_original': {\n",
    "            'phi2+3b': \"stage-final-llava-v15-phi2+3b-repeat\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            'phi2+3b': \"reproduction-align-phi2+3b\"\n",
    "        }\n",
    "    },\n",
    "    'Vicuna1.5': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-finetune+x7\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-align+x7\"\n",
    "        }\n",
    "    },\n",
    "    'LLaMA2': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llama2\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"vila_base_llm\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to calculate NLU and NLG forgetting using harmonic mean\n",
    "def calculate_forgetting_and_performance(model_mappings, results):\n",
    "    scores = []\n",
    "    for model_type, mappings in model_mappings.items():\n",
    "        for scale, llava_model in mappings['llava_original'].items():\n",
    "            base_model = mappings['base_llm'][scale]\n",
    "            if llava_model in results and base_model in results:\n",
    "                llava_nlu_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in nlu_datasets]\n",
    "                base_nlu_scores = [results[base_model].get(dataset, np.nan) * 100 for dataset in nlu_datasets]\n",
    "                llava_nlg_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in nlg_datasets]\n",
    "                base_nlg_scores = [results[base_model].get(dataset, np.nan) * 100 for dataset in nlg_datasets]\n",
    "                \n",
    "                valid_llava_nlu_scores = [score for score in llava_nlu_scores if not np.isnan(score)]\n",
    "                valid_base_nlu_scores = [score for score in base_nlu_scores if not np.isnan(score)]\n",
    "                valid_llava_nlg_scores = [score for score in llava_nlg_scores if not np.isnan(score)]\n",
    "                valid_base_nlg_scores = [score for score in base_nlg_scores if not np.isnan(score)]\n",
    "                \n",
    "                if valid_llava_nlu_scores and valid_base_nlu_scores:\n",
    "                    llava_hmean_nlu = hmean(valid_llava_nlu_scores)\n",
    "                    base_hmean_nlu = hmean(valid_base_nlu_scores)\n",
    "                    nlu_forgetting = llava_hmean_nlu - base_hmean_nlu\n",
    "                else:\n",
    "                    nlu_forgetting = np.nan\n",
    "                \n",
    "                if valid_llava_nlg_scores and valid_base_nlg_scores:\n",
    "                    llava_hmean_nlg = hmean(valid_llava_nlg_scores)\n",
    "                    base_hmean_nlg = hmean(valid_base_nlg_scores)\n",
    "                    nlg_forgetting = llava_hmean_nlg - base_hmean_nlg\n",
    "                else:\n",
    "                    nlg_forgetting = np.nan\n",
    "                \n",
    "                scores.append((model_type, scale, nlu_forgetting, nlg_forgetting))\n",
    "    return scores\n",
    "\n",
    "# Calculate forgetting and performance for each model type\n",
    "scores = calculate_forgetting_and_performance(model_mappings, results)\n",
    "\n",
    "# Rename scales for Phi and Vicuna models\n",
    "scale_rename = {\n",
    "    'phi2+3b': '3.0',\n",
    "    '7b': '7.0'\n",
    "}\n",
    "\n",
    "# Adjust the scales for the plots\n",
    "for i in range(len(scores)):\n",
    "    model_type, scale, nlu_forgetting, nlg_forgetting = scores[i]\n",
    "    if model_type in ['Phi2', 'Vicuna1.5', 'LLaMA2']:\n",
    "        scale = scale_rename.get(scale, scale)\n",
    "    scores[i] = (model_type, scale, nlu_forgetting, nlg_forgetting)\n",
    "\n",
    "# Convert all values to positive for plotting\n",
    "for i in range(len(scores)):\n",
    "    model_type, scale, nlu_forgetting, nlg_forgetting = scores[i]\n",
    "    scores[i] = (model_type, scale, -nlu_forgetting, -nlg_forgetting)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Avg. NLU and NLG Deltas of Each Mitigation Method}\n",
    "  \\\\label{tab:nlu_nlg_performance}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|c|c|c}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model Family} & \\\\textbf{Model Scale} & \\\\textbf{Avg. NLU $\\\\Delta \\\\downarrow$} & \\\\textbf{Avg. NLG $\\\\delta \\\\downarrow$} \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "current_family = None\n",
    "for model_type, scale, nlu_forgetting, nlg_forgetting in scores:\n",
    "    if model_type != current_family:\n",
    "        if current_family is not None:\n",
    "            latex_code += \"\\\\midrule\\n\"\n",
    "        current_family = model_type\n",
    "        latex_code += f\"\\\\multirow{{{len([s for s in scores if s[0] == model_type])}}}{{*}}{{{model_type}}} \\n\"\n",
    "    \n",
    "    scale_display = f\"{scale}B\" if scale != '1.4-instruct' else \"1.4B (Inst.)\"\n",
    "    latex_code += f\"& {scale_display} & {nlu_forgetting:.2f} & {nlg_forgetting:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_code += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Model Performance:} Avg. NLU and NLG Deltas of Each Mitigation Method}\n",
      "  \\label{tab:nlu_nlg_performance}\n",
      "  \\centering\n",
      "  \\begin{tabular}{llccc}\n",
      "    \\toprule\n",
      "    \\textbf{Model Family} & \\textbf{Model Scale} & \\textbf{Avg. NLU $\\Delta \\downarrow$} & \\textbf{Avg. NLG $\\delta \\downarrow$} \\\\\n",
      "    \\midrule\n",
      "    \\multirow{6}{*}{Pythia} \n",
      "    & 0.16B & 0.94 & 12.01 \\\\\n",
      "    & 0.41B & -1.19 & 8.62 \\\\\n",
      "    & 1.0B & -1.63 & 4.95 \\\\\n",
      "    & 1.4B & 0.55 & 8.07 \\\\\n",
      "    & 2.8B & 1.74 & 9.18 \\\\\n",
      "    & 1.4B (Inst.) & -1.20 & -1.01 \\\\\n",
      "    \\midrule\n",
      "    \\multirow{1}{*}{Phi2} \n",
      "    & 3.0B & 2.60 & 4.39 \\\\\n",
      "    \\midrule\n",
      "    \\multirow{1}{*}{Vicuna1.5} \n",
      "    & 7.0B & -0.98 & 2.04 \\\\\n",
      "    \\midrule\n",
      "    \\multirow{1}{*}{LLaMA2} \n",
      "    & 7.0B & -2.15 & -0.43 \\\\\n",
      "\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Define the filtering criteria and datasets\n",
    "nlu_datasets = [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\"]\n",
    "nlg_datasets = [\"lambada_standard\"]\n",
    "vl_datasets = [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]\n",
    "\n",
    "# Define explicit mappings for LLaVA Originals and Base LLMs for each model type\n",
    "model_mappings = {\n",
    "    'Pythia': {\n",
    "        'llava_original': {\n",
    "            0.16: \"stage-final-llava-v15-pythia+160m\",\n",
    "            0.41: \"stage-final-llava-v15-pythia+410m\",\n",
    "            1.0: \"stage-final-llava-v15-pythia+1b\",\n",
    "            1.4: \"stage-final-llava-v15-pythia+1p4b\",\n",
    "            2.8: \"stage-final-llava-v15-pythia+2p8b\",\n",
    "            '1.4-instruct': \"stage-final-llava-v15-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        },\n",
    "        'base_llm': {\n",
    "            0.16: \"reproduction-align-pythia+160m\",\n",
    "            0.41: \"reproduction-align-pythia+410m\",\n",
    "            1.0: \"reproduction-align-pythia+1b\",\n",
    "            1.4: \"reproduction-align-pythia+1p4b\",\n",
    "            2.8: \"reproduction-align-pythia+2p8b\",\n",
    "            '1.4-instruct': \"reproduction-align-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        }\n",
    "    },\n",
    "    'Phi2': {\n",
    "        'llava_original': {\n",
    "            'phi2+3b': \"stage-final-llava-v15-phi2+3b-repeat\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            'phi2+3b': \"reproduction-align-phi2+3b\"\n",
    "        }\n",
    "    },\n",
    "    'Vicuna1.5': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-finetune+x7\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-align+x7\"\n",
    "        }\n",
    "    },\n",
    "    'LLaMA2': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llama2\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"vila_base_llm\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to calculate NLU and NLG forgetting using harmonic mean\n",
    "def calculate_forgetting_and_performance(model_mappings, results):\n",
    "    scores = []\n",
    "    for model_type, mappings in model_mappings.items():\n",
    "        for scale, llava_model in mappings['llava_original'].items():\n",
    "            base_model = mappings['base_llm'][scale]\n",
    "            if llava_model in results and base_model in results:\n",
    "                llava_nlu_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in nlu_datasets]\n",
    "                base_nlu_scores = [results[base_model].get(dataset, np.nan) * 100 for dataset in nlu_datasets]\n",
    "                llava_nlg_scores = [results[llava_model].get(dataset, np.nan) * 100 for dataset in nlg_datasets]\n",
    "                base_nlg_scores = [results[base_model].get(dataset, np.nan) * 100 for dataset in nlg_datasets]\n",
    "                \n",
    "                valid_llava_nlu_scores = [score for score in llava_nlu_scores if not np.isnan(score)]\n",
    "                valid_base_nlu_scores = [score for score in base_nlu_scores if not np.isnan(score)]\n",
    "                valid_llava_nlg_scores = [score for score in llava_nlg_scores if not np.isnan(score)]\n",
    "                valid_base_nlg_scores = [score for score in base_nlg_scores if not np.isnan(score)]\n",
    "                \n",
    "                if valid_llava_nlu_scores and valid_base_nlu_scores:\n",
    "                    llava_hmean_nlu = hmean(valid_llava_nlu_scores)\n",
    "                    base_hmean_nlu = hmean(valid_base_nlu_scores)\n",
    "                    nlu_forgetting = llava_hmean_nlu - base_hmean_nlu\n",
    "                else:\n",
    "                    nlu_forgetting = np.nan\n",
    "                \n",
    "                if valid_llava_nlg_scores and valid_base_nlg_scores:\n",
    "                    llava_hmean_nlg = hmean(valid_llava_nlg_scores)\n",
    "                    base_hmean_nlg = hmean(valid_base_nlg_scores)\n",
    "                    nlg_forgetting = llava_hmean_nlg - base_hmean_nlg\n",
    "                else:\n",
    "                    nlg_forgetting = np.nan\n",
    "                \n",
    "                scores.append((model_type, scale, nlu_forgetting, nlg_forgetting))\n",
    "    return scores\n",
    "\n",
    "# Calculate forgetting and performance for each model type\n",
    "scores = calculate_forgetting_and_performance(model_mappings, results)\n",
    "\n",
    "# Rename scales for Phi and Vicuna models\n",
    "scale_rename = {\n",
    "    'phi2+3b': '3.0',\n",
    "    '7b': '7.0'\n",
    "}\n",
    "\n",
    "# Adjust the scales for the plots\n",
    "for i in range(len(scores)):\n",
    "    model_type, scale, nlu_forgetting, nlg_forgetting = scores[i]\n",
    "    if model_type in ['Phi2', 'Vicuna1.5', 'LLaMA2']:\n",
    "        scale = scale_rename.get(scale, scale)\n",
    "    scores[i] = (model_type, scale, nlu_forgetting, nlg_forgetting)\n",
    "\n",
    "# Convert all values to positive for plotting\n",
    "for i in range(len(scores)):\n",
    "    model_type, scale, nlu_forgetting, nlg_forgetting = scores[i]\n",
    "    scores[i] = (model_type, scale, -nlu_forgetting, -nlg_forgetting)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Avg. NLU and NLG Deltas of Each Mitigation Method}\n",
    "  \\\\label{tab:nlu_nlg_performance}\n",
    "  \\\\centering\n",
    "  \\\\begin{tabular}{llccc}\n",
    "    \\\\toprule\n",
    "    \\\\textbf{Model Family} & \\\\textbf{Model Scale} & \\\\textbf{Avg. NLU $\\\\Delta \\\\downarrow$} & \\\\textbf{Avg. NLG $\\\\delta \\\\downarrow$} \\\\\\\\\n",
    "    \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "current_family = None\n",
    "for model_type, scale, nlu_forgetting, nlg_forgetting in scores:\n",
    "    if model_type != current_family:\n",
    "        if current_family is not None:\n",
    "            latex_code += \"    \\\\midrule\\n\"\n",
    "        current_family = model_type\n",
    "        latex_code += f\"    \\\\multirow{{{len([s for s in scores if s[0] == model_type])}}}{{*}}{{{model_type}}} \\n\"\n",
    "    \n",
    "    scale_display = f\"{scale}B\" if scale != '1.4-instruct' else \"1.4B (Inst.)\"\n",
    "    latex_code += f\"    & {scale_display} & {nlu_forgetting:.2f} & {nlg_forgetting:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_code += \"\"\"\n",
    "    \\\\bottomrule\n",
    "  \\\\end{tabular}\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Model Performance:} Deltas of Each Mitigation Method for NLU and NLG Datasets}\n",
      "  \\label{tab:nlu_nlg_performance}\n",
      "  \\centering\n",
      "  \\begin{tabular}{llcccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Model Family} & \\textbf{Model Scale} & \\textbf{WSC273 $\\Delta \\downarrow$} & \\textbf{Winogrande $\\Delta \\downarrow$} & \\textbf{ARC Easy $\\Delta \\downarrow$} & \\textbf{ARC Challenge $\\Delta \\downarrow$} & \\textbf{Lambada $\\delta \\downarrow$} \\\\\n",
      "    \\midrule\n",
      "    \\multirow{6}{*}{Pythia} \n",
      "    & 0.16B  & 3.30  & -2.29  & 5.13  & -0.09  & 12.01  \\\\\n",
      "    & 0.41B  & 4.03  & 0.47  & 1.68  & -2.30  & 8.62  \\\\\n",
      "    & 1.0B  & 1.83  & -0.71  & 1.30  & -2.56  & 4.95  \\\\\n",
      "    & 1.4B  & 3.30  & 0.32  & 0.76  & 0.00  & 8.07  \\\\\n",
      "    & 2.8B  & 2.93  & -1.10  & 3.91  & 1.37  & 9.18  \\\\\n",
      "    & 1.4B (Inst.)  & -5.49  & -3.63  & -3.70  & 1.11  & -1.01  \\\\\n",
      "    \\midrule\n",
      "    \\multirow{1}{*}{Phi2} \n",
      "    & 3.0B  & -1.47  & 0.16  & 2.95  & 4.86  & 4.39  \\\\\n",
      "    \\midrule\n",
      "    \\multirow{1}{*}{Vicuna1.5} \n",
      "    & 7.0B  & 0.00  & 1.18  & -0.34  & -2.22  & 2.04  \\\\\n",
      "    \\midrule\n",
      "    \\multirow{1}{*}{LLaMA2} \n",
      "    & 7.0B  & -7.33  & -1.34  & -0.80  & -1.19  & -0.43  \\\\\n",
      "\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Define the filtering criteria and datasets\n",
    "nlu_datasets = [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\"]\n",
    "nlg_datasets = [\"lambada_standard\"]\n",
    "all_nlp_datasets = nlu_datasets + nlg_datasets\n",
    "\n",
    "# Define explicit mappings for LLaVA Originals and Base LLMs for each model type\n",
    "model_mappings = {\n",
    "    'Pythia': {\n",
    "        'llava_original': {\n",
    "            0.16: \"stage-final-llava-v15-pythia+160m\",\n",
    "            0.41: \"stage-final-llava-v15-pythia+410m\",\n",
    "            1.0: \"stage-final-llava-v15-pythia+1b\",\n",
    "            1.4: \"stage-final-llava-v15-pythia+1p4b\",\n",
    "            2.8: \"stage-final-llava-v15-pythia+2p8b\",\n",
    "            '1.4-instruct': \"stage-final-llava-v15-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        },\n",
    "        'base_llm': {\n",
    "            0.16: \"reproduction-align-pythia+160m\",\n",
    "            0.41: \"reproduction-align-pythia+410m\",\n",
    "            1.0: \"reproduction-align-pythia+1b\",\n",
    "            1.4: \"reproduction-align-pythia+1p4b\",\n",
    "            2.8: \"reproduction-align-pythia+2p8b\",\n",
    "            '1.4-instruct': \"reproduction-align-pythia+1p4b-instruct\"  # Pythia 1.4B Instruct\n",
    "        }\n",
    "    },\n",
    "    'Phi2': {\n",
    "        'llava_original': {\n",
    "            'phi2+3b': \"stage-final-llava-v15-phi2+3b-repeat\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            'phi2+3b': \"reproduction-align-phi2+3b\"\n",
    "        }\n",
    "    },\n",
    "    'Vicuna1.5': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-finetune+x7\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"reproduction-llava-v15+7b+stage-align+x7\"\n",
    "        }\n",
    "    },\n",
    "    'LLaMA2': {\n",
    "        'llava_original': {\n",
    "            '7b': \"reproduction-llama2\"\n",
    "        },\n",
    "        'base_llm': {\n",
    "            '7b': \"vila_base_llm\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to calculate deltas for each dataset\n",
    "def calculate_deltas(model_mappings, results):\n",
    "    scores = []\n",
    "    for model_type, mappings in model_mappings.items():\n",
    "        for scale, llava_model in mappings['llava_original'].items():\n",
    "            base_model = mappings['base_llm'][scale]\n",
    "            if llava_model in results and base_model in results:\n",
    "                deltas = {dataset: (results[base_model].get(dataset, np.nan) * 100 - results[llava_model].get(dataset, np.nan) * 100)\n",
    "                          for dataset in all_nlp_datasets}\n",
    "                scores.append((model_type, scale, deltas))\n",
    "    return scores\n",
    "\n",
    "# Calculate deltas for each dataset\n",
    "scores = calculate_deltas(model_mappings, results)\n",
    "\n",
    "# Rename scales for Phi and Vicuna models\n",
    "scale_rename = {\n",
    "    'phi2+3b': '3.0',\n",
    "    '7b': '7.0'\n",
    "}\n",
    "\n",
    "# Adjust the scales for the table\n",
    "for i in range(len(scores)):\n",
    "    model_type, scale, deltas = scores[i]\n",
    "    if model_type in ['Phi2', 'Vicuna1.5', 'LLaMA2']:\n",
    "        scale = scale_rename.get(scale, scale)\n",
    "    scores[i] = (model_type, scale, deltas)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Deltas of Each Mitigation Method for NLU and NLG Datasets}\n",
    "  \\\\label{tab:nlu_nlg_performance}\n",
    "  \\\\centering\n",
    "  \\\\begin{tabular}{llcccccc}\n",
    "    \\\\toprule\n",
    "    \\\\textbf{Model Family} & \\\\textbf{Model Scale} & \\\\textbf{WSC273 $\\\\Delta \\\\downarrow$} & \\\\textbf{Winogrande $\\\\Delta \\\\downarrow$} & \\\\textbf{ARC Easy $\\\\Delta \\\\downarrow$} & \\\\textbf{ARC Challenge $\\\\Delta \\\\downarrow$} & \\\\textbf{Lambada $\\\\delta \\\\downarrow$} \\\\\\\\\n",
    "    \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "current_family = None\n",
    "for model_type, scale, deltas in scores:\n",
    "    if model_type != current_family:\n",
    "        if current_family is not None:\n",
    "            latex_code += \"    \\\\midrule\\n\"\n",
    "        current_family = model_type\n",
    "        latex_code += f\"    \\\\multirow{{{len([s for s in scores if s[0] == model_type])}}}{{*}}{{{model_type}}} \\n\"\n",
    "    \n",
    "    scale_display = f\"{scale}B\" if scale != '1.4-instruct' else \"1.4B (Inst.)\"\n",
    "    latex_code += f\"    & {scale_display} \"\n",
    "    for dataset in all_nlp_datasets:\n",
    "        delta = deltas[dataset]\n",
    "        latex_code += f\" & {delta:.2f} \"\n",
    "    latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "latex_code += \"\"\"\n",
    "    \\\\bottomrule\n",
    "  \\\\end{tabular}\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
