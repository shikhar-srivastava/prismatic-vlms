{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: naive-ft, Stage: 0, VL: 0.001, NL: 0.3863352100999474\n",
      "Model: naive-ft, Stage: 1, VL: 0.4421524886376234, NL: 0.2700812156708484\n",
      "Model: naive-ft, Stage: 2, VL: 0.16669767843708932, NL: 0.34263702858390443\n",
      "Model: naive-ft, Stage: 3, VL: 0.004805223973421436, NL: 0.3151680192897782\n",
      "Model: soft, Stage: 0, VL: 0.0045000000000000005, NL: 0.38408061658239784\n",
      "Model: soft, Stage: 1, VL: 0.0015918367346938777, NL: 0.2454425568378775\n",
      "Model: soft, Stage: 2, VL: 0.10230418779859914, NL: 0.33810199662515095\n",
      "Model: soft, Stage: 3, VL: 0.003102369722228088, NL: 0.2831706057243446\n",
      "Model: lora, Stage: 0, VL: 0.002, NL: 0.3784273481481115\n",
      "Model: lora, Stage: 1, VL: 0.374638336115034, NL: 0.3799173833943919\n",
      "Model: lora, Stage: 2, VL: 0.14028927544647746, NL: 0.367197878990521\n",
      "Model: lora, Stage: 3, VL: 0.09589530345069068, NL: 0.3485350680819869\n",
      "Model: sgm, Stage: 0, VL: 0.001, NL: 0.3810485695829846\n",
      "Model: sgm, Stage: 1, VL: 0.363138591322978, NL: 0.37644060500130067\n",
      "Model: sgm, Stage: 2, VL: 0.11690132796859852, NL: 0.3782128819730278\n",
      "Model: sgm, Stage: 3, VL: 0.003228536424869774, NL: 0.3289816479866609\n",
      "Model: rehearsal1, Stage: 0, VL: 0.001, NL: 0.3863352100999474\n",
      "Model: rehearsal1, Stage: 1, VL: 0.377391536977492, NL: 0.2831597762236547\n",
      "Model: rehearsal1, Stage: 2, VL: 0.034741401479705655, NL: 0.3180421774885778\n",
      "Model: rehearsal1, Stage: 3, VL: 0.0355303716175607, NL: 0.3156863341394475\n",
      "Model: sgm-rehearsal1, Stage: 0, VL: 0.001, NL: 0.3810485695829846\n",
      "Model: sgm-rehearsal1, Stage: 1, VL: 0.3527785253329672, NL: 0.38492655078295074\n",
      "Model: sgm-rehearsal1, Stage: 2, VL: 0.12380275745484842, NL: 0.36965523080833634\n",
      "Model: sgm-rehearsal1, Stage: 3, VL: 0.10207281503268635, NL: 0.36443544021476076\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Model Performance:} Task-wise Accuracies and Forgetting of Each Mitigation Method across VL and NL tasks}\n",
      "  \\label{tab:vl_nl_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cc|cc|cc|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{2}{c|}{\\textbf{Task 0 (Instruct)}} & \\multicolumn{2}{c|}{\\textbf{Task 1 (VQA)}} & \\multicolumn{2}{c|}{\\textbf{Task 2 (OCR)}} & \\multicolumn{2}{c}{\\textbf{Task 3 (Ref)}} \\\\\n",
      "     & \\textbf{VL} & \\textbf{NL} & \\textbf{VL} & \\textbf{NL} & \\textbf{VL} & \\textbf{NL} & \\textbf{VL} & \\textbf{NL} \\\\\n",
      "     & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} & \\textbf{(A $\\uparrow$)} & \\textbf{($\\Delta \\downarrow$)} \\\\\n",
      "     \\midrule\n",
      "Original LLaVA & 0.10 & 0.58 & 44.22 & 12.21 & 16.67 & 4.95 & 0.48 & 7.70 \\\\\n",
      "\\midrule\n",
      "Soft Targets (ST) & 0.45 & 0.81 & 0.16 & 14.67 & 10.23 & 5.41 & 0.31 & 10.90 \\\\\n",
      "LoRA & 0.20 & 1.38 & 37.46 & 1.23 & 14.03 & 2.50 & 9.59 & 4.36 \\\\\n",
      "mSGM & 0.10 & 1.11 & 36.31 & 1.57 & 11.69 & 1.40 & 0.32 & 6.32 \\\\\n",
      "Rehearsal \\((1\\%)\\) & 0.10 & 0.58 & 37.74 & 10.90 & 3.47 & 7.41 & 3.55 & 7.65 \\\\\n",
      "mSGM + Rehearsal \\((1\\%)\\) & 0.10 & 1.11 & 35.28 & 0.73 & 12.38 & 2.25 & 10.21 & 2.77 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define a small epsilon value to replace zeros\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Define the dataset stages and the corresponding labels\n",
    "stages = [\"Instruct (2)\", \"VQA (3)\", \"OCR (4)\", \"Ref (5)\"]\n",
    "datasets = [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\", \"refcoco\"]\n",
    "nlu_nlg_datasets = [\"wsc273\", \"winogrande\", \"lambada_standard\", \"arc_easy\", \"arc_challenge\"]\n",
    "vl_evaluate_sequence = [[\"vqa-v2\"], [\"vqa-v2\", \"gqa\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\"], [\"vqa-v2\", \"gqa\", \"textvqa-ocr\", \"textvqa-pure\", \"refcoco\"]]\n",
    "\n",
    "# Define the mitigation methods and their sequence of model names\n",
    "cl_runs = {\n",
    "    \"naive-ft\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m\",\n",
    "        \"cl-vqa-stage-1-pythia+410m\",\n",
    "        \"cl-ocr-stage-2-pythia+410m\",\n",
    "        \"cl-ref-stage-3-pythia+410m\"\n",
    "    ],\n",
    "    \"soft\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-soft\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-soft\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-soft\",\n",
    "        \"cl-ref-stage-3-pythia+410m-soft\"\n",
    "    ],\n",
    "    \"lora\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-lora\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-lora\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-lora\",\n",
    "        \"cl-ref-stage-3-pythia+410m-lora\"\n",
    "    ],\n",
    "    \"sgm\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-sgm\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-sgm\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-sgm\",\n",
    "        \"cl-ref-stage-3-pythia+410m-sgm\"\n",
    "    ],\n",
    "    \"rehearsal1\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-rehearsal1\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-rehearsal1\",\n",
    "        \"cl-ref-stage-3-pythia+410m-rehearsal1\"\n",
    "    ],\n",
    "    \"sgm-rehearsal1\": [\n",
    "        \"cl-instruct-stage-0-pythia+410m-sgm\",\n",
    "        \"cl-vqa-stage-1-pythia+410m-sgm-rehearsal1\",\n",
    "        \"cl-ocr-stage-2-pythia+410m-sgm-rehearsal1\",\n",
    "        \"cl-ref-stage-3-pythia+410m-sgm-rehearsal1\"\n",
    "    ],\n",
    "\n",
    "}\n",
    "\n",
    "# Baseline run_id\n",
    "baseline_run_id = \"reproduction-align-pythia+410m\"\n",
    "\n",
    "# Load the JSON data from the results file\n",
    "with open('results_nlp.json', 'r') as file:\n",
    "    result = json.load(file)\n",
    "\n",
    "# Check for the existence of baseline results\n",
    "baseline_results = result.get(baseline_run_id)\n",
    "if not baseline_results:\n",
    "    raise ValueError(f\"Baseline run ID '{baseline_run_id}' not found in results.\")\n",
    "\n",
    "# Function to replace None values with a small positive value\n",
    "def replace_none_and_zeros(arr, epsilon=EPSILON):\n",
    "    return [epsilon if (x is None or np.isnan(x) or x == 0) else x for x in arr]\n",
    "\n",
    "# Calculate performance changes and averages for each CL run\n",
    "cl_performance_change = {}\n",
    "cl_performance = {}\n",
    "\n",
    "for model_name, run_ids in cl_runs.items():\n",
    "    changes = {}\n",
    "    performances = {}\n",
    "    missing_data = False\n",
    "\n",
    "    for i, run_id in enumerate(run_ids):\n",
    "        current_results = result.get(run_id)\n",
    "        if not current_results:\n",
    "            missing_data = True\n",
    "            print(f\"Run '{run_id}' missing for model '{model_name}'\")\n",
    "            break\n",
    "        \n",
    "        change = {dataset: current_results.get(dataset, np.nan) - baseline_results.get(dataset, np.nan) for dataset in baseline_results.keys()}\n",
    "        changes[f'stage_{i}'] = change\n",
    "        performances[f'stage_{i}'] = current_results\n",
    "        \n",
    "        vl_scores = replace_none_and_zeros([current_results.get(dataset, np.nan) for dataset in vl_evaluate_sequence[i]])\n",
    "        baseline_vl_scores = replace_none_and_zeros([baseline_results.get(dataset, np.nan) for dataset in vl_evaluate_sequence[i]])\n",
    "        avg_delta_vl = hmean(baseline_vl_scores) - hmean(vl_scores)\n",
    "        avg_acc_vl = hmean(vl_scores)\n",
    "        \n",
    "        nl_scores = replace_none_and_zeros([current_results.get(dataset, np.nan) for dataset in nlu_nlg_datasets])\n",
    "        baseline_nl_scores = replace_none_and_zeros([baseline_results.get(dataset, np.nan) for dataset in nlu_nlg_datasets])\n",
    "        avg_delta_nl = hmean(baseline_nl_scores) -  hmean(nl_scores)\n",
    "        avg_acc_nl = hmean(nl_scores)\n",
    "        \n",
    "        changes[f'stage_{i}_avg'] = {'VL': avg_delta_vl, 'NL': avg_delta_nl}\n",
    "        performances[f'stage_{i}_avg'] = {'VL': avg_acc_vl, 'NL': avg_acc_nl}\n",
    "        print(f\"Model: {model_name}, Stage: {i}, VL: {avg_acc_vl}, NL: {avg_acc_nl}\")\n",
    "    \n",
    "    if not missing_data:\n",
    "        cl_performance_change[model_name] = changes\n",
    "        cl_performance[model_name] = performances\n",
    "\n",
    "# Save the performance changes and averages to JSON files\n",
    "with open('cl_performance_change.json', 'w') as f:\n",
    "    json.dump(cl_performance_change, f, indent=2)\n",
    "\n",
    "with open('cl_performance.json', 'w') as f:\n",
    "    json.dump(cl_performance, f, indent=2)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "name_mapping = {\n",
    "    'olf': 'OLF',\n",
    "    'sgm': 'mSGM',\n",
    "    'sgm-rehearsal1': 'mSGM + Rehearsal \\((1\\%)\\)',\n",
    "    'sgm-olf': 'mSGM + OLF',\n",
    "    'rehearsal1': 'Rehearsal \\((1\\%)\\)',\n",
    "    'rehearsal10': 'Rehearsal \\((10\\%)\\)',\n",
    "    'rehearsal20': 'Rehearsal \\((20\\%)\\)',\n",
    "    'lora': 'LoRA',\n",
    "    'naive-ft': 'Original LLaVA',\n",
    "    'soft': 'Soft Targets (ST)',\n",
    "    'ia3': 'IA3'\n",
    "}\n",
    "\n",
    "latex_code = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{Model Performance:} Task-wise Accuracies and Forgetting of Each Mitigation Method across VL and NL tasks}\n",
    "  \\\\label{tab:vl_nl_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cc|cc|cc|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{2}{c|}{\\\\textbf{Task 0 (Instruct)}} & \\\\multicolumn{2}{c|}{\\\\textbf{Task 1 (VQA)}} & \\\\multicolumn{2}{c|}{\\\\textbf{Task 2 (OCR)}} & \\\\multicolumn{2}{c}{\\\\textbf{Task 3 (Ref)}} \\\\\\\\\n",
    "     & \\\\textbf{VL} & \\\\textbf{NL} & \\\\textbf{VL} & \\\\textbf{NL} & \\\\textbf{VL} & \\\\textbf{NL} & \\\\textbf{VL} & \\\\textbf{NL} \\\\\\\\\n",
    "     & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} & \\\\textbf{(A $\\\\uparrow$)} & \\\\textbf{($\\\\Delta \\\\downarrow$)} \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Include the Naive-FT benchmark first\n",
    "model_name = 'naive-ft'\n",
    "tasks = cl_performance[model_name]\n",
    "\n",
    "model_results = (\n",
    "    name_mapping[model_name],\n",
    "    tasks['stage_0_avg']['VL'] * 100, cl_performance_change[model_name]['stage_0_avg']['NL'] * 100,\n",
    "    tasks['stage_1_avg']['VL'] * 100, cl_performance_change[model_name]['stage_1_avg']['NL'] * 100,\n",
    "    tasks['stage_2_avg']['VL'] * 100, cl_performance_change[model_name]['stage_2_avg']['NL'] * 100,\n",
    "    tasks['stage_3_avg']['VL'] * 100, cl_performance_change[model_name]['stage_3_avg']['NL'] * 100\n",
    ")\n",
    "\n",
    "latex_code += \"{model} & {t0_vl_a:.2f} & {t0_nl_d:.2f} & {t1_vl_a:.2f} & {t1_nl_d:.2f} & {t2_vl_a:.2f} & {t2_nl_d:.2f} & {t3_vl_a:.2f} & {t3_nl_d:.2f} \\\\\\\\\\n\".format(\n",
    "    model=model_results[0],\n",
    "    t0_vl_a=model_results[1], t0_nl_d=model_results[2],\n",
    "    t1_vl_a=model_results[3], t1_nl_d=model_results[4],\n",
    "    t2_vl_a=model_results[5], t2_nl_d=model_results[6],\n",
    "    t3_vl_a=model_results[7], t3_nl_d=model_results[8]\n",
    ")\n",
    "\n",
    "latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "# Include the rest of the models\n",
    "for model_name, tasks in cl_performance.items():\n",
    "    if model_name not in name_mapping or model_name == 'naive-ft':\n",
    "        continue\n",
    "\n",
    "    model_results = (\n",
    "        name_mapping[model_name],\n",
    "        tasks['stage_0_avg']['VL'] * 100, cl_performance_change[model_name]['stage_0_avg']['NL'] * 100,\n",
    "        tasks['stage_1_avg']['VL'] * 100, cl_performance_change[model_name]['stage_1_avg']['NL'] * 100,\n",
    "        tasks['stage_2_avg']['VL'] * 100, cl_performance_change[model_name]['stage_2_avg']['NL'] * 100,\n",
    "        tasks['stage_3_avg']['VL'] * 100, cl_performance_change[model_name]['stage_3_avg']['NL'] * 100\n",
    "    )\n",
    "    \n",
    "    latex_code += \"{model} & {t0_vl_a:.2f} & {t0_nl_d:.2f} & {t1_vl_a:.2f} & {t1_nl_d:.2f} & {t2_vl_a:.2f} & {t2_nl_d:.2f} & {t3_vl_a:.2f} & {t3_nl_d:.2f} \\\\\\\\\\n\".format(\n",
    "        model=model_results[0],\n",
    "        t0_vl_a=model_results[1], t0_nl_d=model_results[2],\n",
    "        t1_vl_a=model_results[3], t1_nl_d=model_results[4],\n",
    "        t2_vl_a=model_results[5], t2_nl_d=model_results[6],\n",
    "        t3_vl_a=model_results[7], t3_nl_d=model_results[8]\n",
    "    )\n",
    "\n",
    "latex_code += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Original LLaVA}: Accuracy on each VL task after training up to stage j}\n",
      "  \\label{tab:acc_naive-ft}\n",
      "  \\begin{tabular}{l|ccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Trained on} & VQA (1) & GQA (1) & OCR (2) & OCR-only (2) & Ref (3) \\\\\n",
      "    \\midrule\n",
      "    Instruct (0) & --- & --- & --- & --- & --- \\\\\n",
      "    VQA (1) & 51.44 & 38.77 & 9.84 & 10.78 & 0.00 \\\\\n",
      "    OCR (2) & 45.13 & 30.47 & 9.86 & 11.96 & 0.00 \\\\\n",
      "    Ref (3) & 46.84 & 30.57 & 3.90 & 10.57 & 0.00 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Soft Targets (ST)}: Accuracy on each VL task after training up to stage j}\n",
      "  \\label{tab:acc_soft}\n",
      "  \\begin{tabular}{l|ccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Trained on} & VQA (1) & GQA (1) & OCR (2) & OCR-only (2) & Ref (3) \\\\\n",
      "    \\midrule\n",
      "    Instruct (0) & 0.45 & 0.00 & 1.55 & 1.15 & 0.00 \\\\\n",
      "    VQA (1) & 0.39 & 0.00 & 0.31 & 0.41 & 0.00 \\\\\n",
      "    OCR (2) & 35.64 & 26.07 & 8.03 & 5.00 & 0.00 \\\\\n",
      "    Ref (3) & 4.92 & 2.15 & 0.21 & 1.26 & 0.00 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LoRA}: Accuracy on each VL task after training up to stage j}\n",
      "  \\label{tab:acc_lora}\n",
      "  \\begin{tabular}{l|ccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Trained on} & VQA (1) & GQA (1) & OCR (2) & OCR-only (2) & Ref (3) \\\\\n",
      "    \\midrule\n",
      "    Instruct (0) & 0.20 & 0.00 & 0.49 & 0.25 & 0.00 \\\\\n",
      "    VQA (1) & 46.54 & 31.35 & 14.48 & 9.77 & 0.00 \\\\\n",
      "    OCR (2) & 41.73 & 27.93 & 9.34 & 8.46 & 0.00 \\\\\n",
      "    Ref (3) & 39.79 & 25.98 & 13.71 & 6.82 & 4.20 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{mSGM}: Accuracy on each VL task after training up to stage j}\n",
      "  \\label{tab:acc_sgm}\n",
      "  \\begin{tabular}{l|ccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Trained on} & VQA (1) & GQA (1) & OCR (2) & OCR-only (2) & Ref (3) \\\\\n",
      "    \\midrule\n",
      "    Instruct (0) & 0.10 & 0.00 & 0.13 & 0.00 & 0.00 \\\\\n",
      "    VQA (1) & 43.53 & 31.15 & 12.63 & 8.50 & 0.00 \\\\\n",
      "    OCR (2) & 36.11 & 26.66 & 6.90 & 7.57 & 0.00 \\\\\n",
      "    Ref (3) & 8.58 & 7.03 & 0.21 & 3.00 & 0.10 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{Rehearsal \\((1\\%)\\)}: Accuracy on each VL task after training up to stage j}\n",
      "  \\label{tab:acc_rehearsal1}\n",
      "  \\begin{tabular}{l|ccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Trained on} & VQA (1) & GQA (1) & OCR (2) & OCR-only (2) & Ref (3) \\\\\n",
      "    \\midrule\n",
      "    Instruct (0) & --- & --- & --- & --- & --- \\\\\n",
      "    VQA (1) & 45.52 & 32.23 & 6.59 & 9.36 & 0.00 \\\\\n",
      "    OCR (2) & 25.78 & 21.39 & 1.07 & 7.41 & 0.00 \\\\\n",
      "    Ref (3) & 23.49 & 14.75 & 1.42 & 6.87 & 2.25 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{mSGM + Rehearsal \\((1\\%)\\)}: Accuracy on each VL task after training up to stage j}\n",
      "  \\label{tab:acc_sgm-rehearsal1}\n",
      "  \\begin{tabular}{l|ccccc}\n",
      "    \\toprule\n",
      "    \\textbf{Trained on} & VQA (1) & GQA (1) & OCR (2) & OCR-only (2) & Ref (3) \\\\\n",
      "    \\midrule\n",
      "    Instruct (0) & 0.10 & 0.00 & 0.13 & 0.00 & 0.00 \\\\\n",
      "    VQA (1) & 42.85 & 29.98 & 13.41 & 8.35 & 0.00 \\\\\n",
      "    OCR (2) & 40.51 & 29.30 & 7.64 & 7.50 & 0.00 \\\\\n",
      "    Ref (3) & 39.66 & 28.81 & 13.89 & 7.99 & 4.30 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- INSERT *AFTER* the cl_performance and cl_performance_change are computed ---\n",
    "\n",
    "# List of all VL evaluation tasks (in evaluation order)\n",
    "vl_tasks = vl_evaluate_sequence[-1]  # ['vqa-v2', 'gqa', 'textvqa-ocr', 'textvqa-pure', 'refcoco']\n",
    "\n",
    "# For human‐readable labels\n",
    "task_labels = {\n",
    "    'vqa-v2':    'VQA (1)',\n",
    "    'gqa':       'GQA (1)',\n",
    "    'textvqa-ocr': 'OCR (2)',\n",
    "    'textvqa-pure': 'OCR-only (2)',\n",
    "    'refcoco':   'Ref (3)'\n",
    "}\n",
    "\n",
    "# Generate one LaTeX table per method\n",
    "for model_key, perf in cl_performance.items():\n",
    "    display_name = name_mapping.get(model_key, model_key)\n",
    "    print(f\"\\\\begin{{table*}}[h]\")\n",
    "    print(f\"  \\\\caption{{\\\\textbf{{{display_name}}}: Accuracy on each VL task after training up to stage j}}\")\n",
    "    print(f\"  \\\\label{{tab:acc_{model_key}}}\")\n",
    "    # column headers: trained stage → evaluated task\n",
    "    cols = \" & \".join([task_labels[d] for d in vl_tasks])\n",
    "    print(f\"  \\\\begin{{tabular}}{{l|{'c' * len(vl_tasks)}}}\")\n",
    "    print(f\"    \\\\toprule\")\n",
    "    print(f\"    \\\\textbf{{Trained on}} & {cols} \\\\\\\\\")\n",
    "    print(f\"    \\\\midrule\")\n",
    "    # for each training stage j\n",
    "    for i, stage_name in enumerate(stages):\n",
    "        row = [stage_name]\n",
    "        results = perf[f\"stage_{i}\"]\n",
    "        # fetch accuracy for each eval task (multiply by 100 if desired)\n",
    "        for d in vl_tasks:\n",
    "            acc = results.get(d, np.nan)\n",
    "            if np.isnan(acc):\n",
    "                row.append(\"---\")\n",
    "            else:\n",
    "                row.append(f\"{acc * 100:.2f}\")\n",
    "        print(\"    \" + \" & \".join(row) + \" \\\\\\\\\")\n",
    "    print(f\"    \\\\bottomrule\")\n",
    "    print(f\"  \\\\end{{tabular}}\")\n",
    "    print(f\"\\\\end{{table*}}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[h]\n",
      "  \\centering\n",
      "  \\caption{\\textbf{VL Accuracy After Continual Training}}\n",
      "  \\label{tab:vl_acc_subtables}\n",
      "  \\begin{tabular}{c}\n",
      "    \\toprule\n",
      "    %----------------------------\n",
      "    \\begin{subtable}{\\linewidth}\n",
      "      \\centering\n",
      "      \\caption{Original LLaVA}\n",
      "      \\begin{tabular}{l|ccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      "        & \\textbf{VQA (1)} & \\textbf{GQA (1)} & \\textbf{OCR (2)} & \\textbf{OCR-only (2)} & \\textbf{Ref (3)} \\\\\n",
      "        \\midrule\n",
      "        Instruct (0) & --- & --- & --- & --- & --- \\\\\n",
      "        VQA (1) & 51.44 & 38.77 & 9.84 & 10.78 & 0.00 \\\\\n",
      "        OCR (2) & 45.13 & 30.47 & 9.86 & 11.96 & 0.00 \\\\\n",
      "        Ref (3) & 46.84 & 30.57 & 3.90 & 10.57 & 0.00 \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subtable}\\\\[1em]\n",
      "    %----------------------------\n",
      "    \\begin{subtable}{\\linewidth}\n",
      "      \\centering\n",
      "      \\caption{Soft Targets (ST)}\n",
      "      \\begin{tabular}{l|ccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      "        & \\textbf{VQA (1)} & \\textbf{GQA (1)} & \\textbf{OCR (2)} & \\textbf{OCR-only (2)} & \\textbf{Ref (3)} \\\\\n",
      "        \\midrule\n",
      "        Instruct (0) & 0.45 & 0.00 & 1.55 & 1.15 & 0.00 \\\\\n",
      "        VQA (1) & 0.39 & 0.00 & 0.31 & 0.41 & 0.00 \\\\\n",
      "        OCR (2) & 35.64 & 26.07 & 8.03 & 5.00 & 0.00 \\\\\n",
      "        Ref (3) & 4.92 & 2.15 & 0.21 & 1.26 & 0.00 \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subtable}\\\\[1em]\n",
      "    %----------------------------\n",
      "    \\begin{subtable}{\\linewidth}\n",
      "      \\centering\n",
      "      \\caption{LoRA}\n",
      "      \\begin{tabular}{l|ccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      "        & \\textbf{VQA (1)} & \\textbf{GQA (1)} & \\textbf{OCR (2)} & \\textbf{OCR-only (2)} & \\textbf{Ref (3)} \\\\\n",
      "        \\midrule\n",
      "        Instruct (0) & 0.20 & 0.00 & 0.49 & 0.25 & 0.00 \\\\\n",
      "        VQA (1) & 46.54 & 31.35 & 14.48 & 9.77 & 0.00 \\\\\n",
      "        OCR (2) & 41.73 & 27.93 & 9.34 & 8.46 & 0.00 \\\\\n",
      "        Ref (3) & 39.79 & 25.98 & 13.71 & 6.82 & 4.20 \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subtable}\\\\[1em]\n",
      "    %----------------------------\n",
      "    \\begin{subtable}{\\linewidth}\n",
      "      \\centering\n",
      "      \\caption{mSGM}\n",
      "      \\begin{tabular}{l|ccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      "        & \\textbf{VQA (1)} & \\textbf{GQA (1)} & \\textbf{OCR (2)} & \\textbf{OCR-only (2)} & \\textbf{Ref (3)} \\\\\n",
      "        \\midrule\n",
      "        Instruct (0) & 0.10 & 0.00 & 0.13 & 0.00 & 0.00 \\\\\n",
      "        VQA (1) & 43.53 & 31.15 & 12.63 & 8.50 & 0.00 \\\\\n",
      "        OCR (2) & 36.11 & 26.66 & 6.90 & 7.57 & 0.00 \\\\\n",
      "        Ref (3) & 8.58 & 7.03 & 0.21 & 3.00 & 0.10 \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subtable}\\\\[1em]\n",
      "    %----------------------------\n",
      "    \\begin{subtable}{\\linewidth}\n",
      "      \\centering\n",
      "      \\caption{Rehearsal \\((1\\%)\\)}\n",
      "      \\begin{tabular}{l|ccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      "        & \\textbf{VQA (1)} & \\textbf{GQA (1)} & \\textbf{OCR (2)} & \\textbf{OCR-only (2)} & \\textbf{Ref (3)} \\\\\n",
      "        \\midrule\n",
      "        Instruct (0) & --- & --- & --- & --- & --- \\\\\n",
      "        VQA (1) & 45.52 & 32.23 & 6.59 & 9.36 & 0.00 \\\\\n",
      "        OCR (2) & 25.78 & 21.39 & 1.07 & 7.41 & 0.00 \\\\\n",
      "        Ref (3) & 23.49 & 14.75 & 1.42 & 6.87 & 2.25 \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subtable}\\\\[1em]\n",
      "    %----------------------------\n",
      "    \\begin{subtable}{\\linewidth}\n",
      "      \\centering\n",
      "      \\caption{mSGM + Rehearsal \\((1\\%)\\)}\n",
      "      \\begin{tabular}{l|ccccc}\n",
      "        \\toprule\n",
      "        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      "        & \\textbf{VQA (1)} & \\textbf{GQA (1)} & \\textbf{OCR (2)} & \\textbf{OCR-only (2)} & \\textbf{Ref (3)} \\\\\n",
      "        \\midrule\n",
      "        Instruct (0) & 0.10 & 0.00 & 0.13 & 0.00 & 0.00 \\\\\n",
      "        VQA (1) & 42.85 & 29.98 & 13.41 & 8.35 & 0.00 \\\\\n",
      "        OCR (2) & 40.51 & 29.30 & 7.64 & 7.50 & 0.00 \\\\\n",
      "        Ref (3) & 39.66 & 28.81 & 13.89 & 7.99 & 4.30 \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subtable}\\\\[1em]\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "# --- INSERT *AFTER* the cl_performance and cl_performance_change are computed ---\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# List of all VL evaluation tasks (in evaluation order)\n",
    "vl_tasks = vl_evaluate_sequence[-1]  # ['vqa-v2', 'gqa', 'textvqa-ocr', 'textvqa-pure', 'refcoco']\n",
    "\n",
    "# For human‐readable labels\n",
    "task_labels = {\n",
    "    'vqa-v2':      'VQA (3)',\n",
    "    'gqa':         'GQA (3)',\n",
    "    'textvqa-ocr': 'OCR (4)',\n",
    "    'textvqa-pure':'OCR-only (4)',\n",
    "    'refcoco':     'Ref (5)'\n",
    "}\n",
    "\n",
    "# Begin big table\n",
    "print(r\"\\begin{table*}[h]\")\n",
    "print(r\"  \\centering\")\n",
    "print(r\"  \\caption{\\textbf{VL Accuracy After Continual Training}}\")\n",
    "print(r\"  \\label{tab:vl_acc_subtables}\")\n",
    "# Use a single tabular to stack subtables\n",
    "print(r\"  \\begin{tabular}{c}\")\n",
    "print(r\"    \\toprule\")\n",
    "\n",
    "for model_key, perf in cl_performance.items():\n",
    "    display_name = name_mapping.get(model_key, model_key)\n",
    "    # Subtable for this method\n",
    "    print(r\"    %----------------------------\")\n",
    "    print(r\"    \\begin{subtable}{\\linewidth}\")\n",
    "    print(r\"      \\centering\")\n",
    "    print(r\"      \\caption{\" + display_name + r\"}\")\n",
    "    # Header with arrows: multirow & multicolumn\n",
    "    print(r\"      \\begin{tabular}{l|\" + \"c\"*len(vl_tasks) + r\"}\")\n",
    "    print(r\"        \\toprule\")\n",
    "    print(r\"        \\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \"\n",
    "          + rf\"\\multicolumn{{{len(vl_tasks)}}}{{c}}{{\\textbf{{Evaluated}} $\\rightarrow$}} \\\\\")\n",
    "    headers = \" & \".join([r\"\\textbf{\" + task_labels[d] + \"}\" for d in vl_tasks])\n",
    "    print(r\"        & \" + headers + r\" \\\\\")\n",
    "    print(r\"        \\midrule\")\n",
    "    # Rows: stages 0–3\n",
    "    for i, stage_name in enumerate(stages):\n",
    "        row = [stage_name]\n",
    "        results = perf[f\"stage_{i}\"]\n",
    "        for d in vl_tasks:\n",
    "            acc = results.get(d, np.nan)\n",
    "            row.append(f\"{acc * 100:.2f}\" if not np.isnan(acc) else \"---\")\n",
    "        print(\"        \" + \" & \".join(row) + r\" \\\\\")\n",
    "    print(r\"        \\bottomrule\")\n",
    "    print(r\"      \\end{tabular}\")\n",
    "    print(r\"    \\end{subtable}\\\\[1em]\")\n",
    "\n",
    "# Close big table\n",
    "print(r\"    \\bottomrule\")\n",
    "print(r\"  \\end{tabular}\")\n",
    "print(r\"\\end{table*}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{l|ccccc}\n",
      "\\caption{\\textbf{VL Accuracy After Continual Training}}\\label{tab:vl_acc_long} \\\\\n",
      "\\toprule\n",
      "\\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      " & \\textbf{VQAv2 (3)} & \\textbf{GQA (3)} & \\textbf{TextVQA-OCR (4)} & \\textbf{TextVQA-Pure (4)} & \\textbf{RefCOCO (5)} \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{\\textbf{(continued)} VL Accuracy After Continual Training} \\\\\n",
      "\\toprule\n",
      "\\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \\multicolumn{5}{c}{\\textbf{Evaluated} $\\rightarrow$} \\\\\n",
      " & \\textbf{VQAv2 (3)} & \\textbf{GQA (3)} & \\textbf{TextVQA-OCR (4)} & \\textbf{TextVQA-Pure (4)} & \\textbf{RefCOCO (5)} \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\bottomrule\n",
      "\\endfoot\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textbf{Original LLaVA}} \\\\\n",
      "\\midrule\n",
      "Instruct (2) & --- & --- & --- & --- & --- \\\\\n",
      "VQA (3) & 51.44 & 38.77 & 9.84 & 10.78 & 0.00 \\\\\n",
      "OCR (4) & 45.13 & 30.47 & 9.86 & 11.96 & 0.00 \\\\\n",
      "Ref (5) & 46.84 & 30.57 & 3.90 & 10.57 & 0.00 \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textbf{Soft Targets (ST)}} \\\\\n",
      "\\midrule\n",
      "Instruct (2) & 0.45 & 0.00 & 1.55 & 1.15 & 0.00 \\\\\n",
      "VQA (3) & 0.39 & 0.00 & 0.31 & 0.41 & 0.00 \\\\\n",
      "OCR (4) & 35.64 & 26.07 & 8.03 & 5.00 & 0.00 \\\\\n",
      "Ref (5) & 4.92 & 2.15 & 0.21 & 1.26 & 0.00 \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textbf{LoRA}} \\\\\n",
      "\\midrule\n",
      "Instruct (2) & 0.20 & 0.00 & 0.49 & 0.25 & 0.00 \\\\\n",
      "VQA (3) & 46.54 & 31.35 & 14.48 & 9.77 & 0.00 \\\\\n",
      "OCR (4) & 41.73 & 27.93 & 9.34 & 8.46 & 0.00 \\\\\n",
      "Ref (5) & 39.79 & 25.98 & 13.71 & 6.82 & 4.20 \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textbf{mSGM}} \\\\\n",
      "\\midrule\n",
      "Instruct (2) & 0.10 & 0.00 & 0.13 & 0.00 & 0.00 \\\\\n",
      "VQA (3) & 43.53 & 31.15 & 12.63 & 8.50 & 0.00 \\\\\n",
      "OCR (4) & 36.11 & 26.66 & 6.90 & 7.57 & 0.00 \\\\\n",
      "Ref (5) & 8.58 & 7.03 & 0.21 & 3.00 & 0.10 \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textbf{Rehearsal \\((1\\%)\\)}} \\\\\n",
      "\\midrule\n",
      "Instruct (2) & --- & --- & --- & --- & --- \\\\\n",
      "VQA (3) & 45.52 & 32.23 & 6.59 & 9.36 & 0.00 \\\\\n",
      "OCR (4) & 25.78 & 21.39 & 1.07 & 7.41 & 0.00 \\\\\n",
      "Ref (5) & 23.49 & 14.75 & 1.42 & 6.87 & 2.25 \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textbf{mSGM + Rehearsal \\((1\\%)\\)}} \\\\\n",
      "\\midrule\n",
      "Instruct (2) & 0.10 & 0.00 & 0.13 & 0.00 & 0.00 \\\\\n",
      "VQA (3) & 42.85 & 29.98 & 13.41 & 8.35 & 0.00 \\\\\n",
      "OCR (4) & 40.51 & 29.30 & 7.64 & 7.50 & 0.00 \\\\\n",
      "Ref (5) & 39.66 & 28.81 & 13.89 & 7.99 & 4.30 \\\\\n",
      "\\end{longtable}\n"
     ]
    }
   ],
   "source": [
    "# --- INSERT *AFTER* the cl_performance and cl_performance_change are computed ---\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vl_tasks = vl_evaluate_sequence[-1]\n",
    "task_labels = {\n",
    "    'vqa-v2':      'VQAv2 (3)',\n",
    "    'gqa':         'GQA (3)',\n",
    "    'textvqa-ocr': 'TextVQA-OCR (4)',\n",
    "    'textvqa-pure':'TextVQA-Pure (4)',\n",
    "    'refcoco':     'RefCOCO (5)'\n",
    "}\n",
    "\n",
    "# Begin longtable\n",
    "print(r\"\\begin{longtable}{l|\" + \"c\"*len(vl_tasks) + r\"}\")\n",
    "print(r\"\\caption{\\textbf{VL Accuracy After Continual Training}}\\label{tab:vl_acc_long} \\\\\")\n",
    "print(r\"\\toprule\")\n",
    "print(r\"\\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \"\n",
    "      + rf\"\\multicolumn{{{len(vl_tasks)}}}{{c}}{{\\textbf{{Evaluated}} $\\rightarrow$}} \\\\\")\n",
    "headers = \" & \".join([r\"\\textbf{\" + task_labels[d] + \"}\" for d in vl_tasks])\n",
    "print(r\" & \" + headers + r\" \\\\\")\n",
    "print(r\"\\midrule\")\n",
    "print(r\"\\endfirsthead\")\n",
    "\n",
    "# header for subsequent pages\n",
    "print(r\"\\caption[]{\\textbf{(continued)} VL Accuracy After Continual Training} \\\\\")\n",
    "print(r\"\\toprule\")\n",
    "print(r\"\\multirow{2}{*}{\\textbf{Trained on} $\\downarrow$} & \"\n",
    "      + rf\"\\multicolumn{{{len(vl_tasks)}}}{{c}}{{\\textbf{{Evaluated}} $\\rightarrow$}} \\\\\")\n",
    "print(r\" & \" + headers + r\" \\\\\")\n",
    "print(r\"\\midrule\")\n",
    "print(r\"\\endhead\")\n",
    "\n",
    "print(r\"\\bottomrule\")\n",
    "print(r\"\\endfoot\")\n",
    "\n",
    "# Print a block for each method\n",
    "for model_key, perf in cl_performance.items():\n",
    "    name = name_mapping.get(model_key, model_key)\n",
    "    # model separator\n",
    "    print(r\"\\midrule\")\n",
    "    print(r\"\\multicolumn{\" + str(len(vl_tasks)+1) + r\"}{l}{\\textbf{\" + name + r\"}} \\\\\")\n",
    "    print(r\"\\midrule\")\n",
    "    # rows for stages\n",
    "    for i, stage in enumerate(stages):\n",
    "        row = [stage]\n",
    "        results = perf[f\"stage_{i}\"]\n",
    "        for d in vl_tasks:\n",
    "            acc = results.get(d, np.nan)\n",
    "            row.append(f\"{acc*100:.2f}\" if not np.isnan(acc) else \"---\")\n",
    "        print(\" & \".join(row) + r\" \\\\\")\n",
    "# End longtable\n",
    "print(r\"\\end{longtable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
