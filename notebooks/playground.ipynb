{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/localdisk/ssrivas9/prismatic-vlms/evaluations/cl-ocr-stage-2-pythia+1b-sgm-rehearsal10/nlp/nlu/\"\n",
    "tasks = \"wsc273,arc_easy,arc_challenge,winogrande,lambada_standard\"\n",
    "tasks = tasks.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under model_path, detect all jsons that end with task name .json\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_jsons(model_path, tasks):\n",
    "    task_jsons = defaultdict(list)\n",
    "    \n",
    "    for task in tasks:\n",
    "        # For all files in the current model_path folder that end with task name .json, read them and store them here.\n",
    "        for file in os.listdir(model_path):\n",
    "            if file.endswith(task + \".jsonl\"):\n",
    "                with open(os.path.join(model_path, file), 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, list):\n",
    "                        task_jsons[task].extend(data)  # Assuming the file contains a list of JSON objects\n",
    "                    else:\n",
    "                        task_jsons[task].append(data)  # If it's a single JSON object, add it directly\n",
    "    return task_jsons\n",
    "\n",
    "jsons_dict = get_jsons(model_path, tasks)\n",
    "# For each task in the json_dict, create a new dictionary that stores \"doc_id\": \"acc\" for each doc_id. \n",
    "# Write this to a json raw-[task].json in the same model_path folder.\n",
    "\n",
    "for task, jsons in jsons_dict.items():\n",
    "    doc_acc = {}\n",
    "    for json_obj in jsons:\n",
    "        doc_id = json_obj[\"doc_id\"]\n",
    "        acc = json_obj[\"acc\"]\n",
    "        doc_acc[doc_id] = acc\n",
    "    with open(os.path.join(model_path, \"raw-\" + task + \".json\"), 'w') as f:\n",
    "        json.dump(doc_acc, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['wsc273', 'arc_easy', 'arc_challenge', 'winogrande', 'lambada_standard'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 4,\n",
       " 'doc': {'text': \"preston had been the last person to wear those chains , and i knew what i 'd see and feel if they were slipped onto my skin-the reaper 's unending hatred of me . i 'd felt enough of that emotion already in the amphitheater . i did n't want to feel anymore . `` do n't put those on me , '' i whispered . `` please . '' sergei looked at me , surprised by my low , raspy please , but he put down the chains\",\n",
       "  'domain': None},\n",
       " 'target': ' chains',\n",
       " 'arguments': [[\"preston had been the last person to wear those chains , and i knew what i 'd see and feel if they were slipped onto my skin-the reaper 's unending hatred of me . i 'd felt enough of that emotion already in the amphitheater . i did n't want to feel anymore . `` do n't put those on me , '' i whispered . `` please . '' sergei looked at me , surprised by my low , raspy please , but he put down the\",\n",
       "   ' chains']],\n",
       " 'resps': [[[-2.0096569061279297, False]]],\n",
       " 'filtered_resps': [[-2.0096569061279297, False]],\n",
       " 'perplexity': -2.0096569061279297,\n",
       " 'acc': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_dict['lambada_standard'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
