{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Soft Targets\": {\n",
      "    \"vqa-v2\": 0.3267,\n",
      "    \"textvqa-ocr\": 0.06923828124999999,\n",
      "    \"textvqa-pure\": 0.061035156249999986,\n",
      "    \"gqa\": 0.2539,\n",
      "    \"refcoco\": 0.015625,\n",
      "    \"wsc273\": 0.5128205128205128,\n",
      "    \"winogrande\": 0.5082872928176796,\n",
      "    \"lambada_standard\": 0.17019212109450804,\n",
      "    \"arc_easy\": 0.39941077441077444,\n",
      "    \"arc_challenge\": 0.2226962457337884\n",
      "  },\n",
      "  \"LoRA\": {\n",
      "    \"vqa-v2\": 0.2897,\n",
      "    \"textvqa-ocr\": 0.010156250000000002,\n",
      "    \"textvqa-pure\": 0.017382812500000004,\n",
      "    \"gqa\": 0.1797,\n",
      "    \"refcoco\": 0.0009765625,\n",
      "    \"wsc273\": 0.5457875457875457,\n",
      "    \"winogrande\": 0.4964483030781373,\n",
      "    \"lambada_standard\": 0.1946438967591694,\n",
      "    \"arc_easy\": 0.3888888888888889,\n",
      "    \"arc_challenge\": 0.2167235494880546\n",
      "  },\n",
      "  \"SGM\": {\n",
      "    \"vqa-v2\": 0.2839,\n",
      "    \"textvqa-ocr\": 0.013671875,\n",
      "    \"textvqa-pure\": 0.0271484375,\n",
      "    \"gqa\": 0.1748,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5677655677655677,\n",
      "    \"winogrande\": 0.5074980268350434,\n",
      "    \"lambada_standard\": 0.17698428100135843,\n",
      "    \"arc_easy\": 0.3998316498316498,\n",
      "    \"arc_challenge\": 0.20733788395904437\n",
      "  },\n",
      "  \"Original LLaVA\": {\n",
      "    \"vqa-v2\": 0.3032,\n",
      "    \"textvqa-ocr\": 0.0240234375,\n",
      "    \"textvqa-pure\": 0.038281249999999996,\n",
      "    \"gqa\": 0.2217,\n",
      "    \"refcoco\": 0.00390625,\n",
      "    \"wsc273\": 0.5347985347985348,\n",
      "    \"winogrande\": 0.5193370165745856,\n",
      "    \"lambada_standard\": 0.11313797787696488,\n",
      "    \"arc_easy\": 0.390993265993266,\n",
      "    \"arc_challenge\": 0.20051194539249148\n",
      "  },\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.0,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5677655677655677,\n",
      "    \"winogrande\": 0.4964483030781373,\n",
      "    \"lambada_standard\": 0.23326217737240443,\n",
      "    \"arc_easy\": 0.44234006734006737,\n",
      "    \"arc_challenge\": 0.19965870307167236\n",
      "  },\n",
      "  \"Output Layer Freezing (OLF)\": {\n",
      "    \"vqa-v2\": 0.26940000000000003,\n",
      "    \"textvqa-ocr\": 0.006640625,\n",
      "    \"textvqa-pure\": 0.0361328125,\n",
      "    \"gqa\": 0.1777,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5238095238095238,\n",
      "    \"winogrande\": 0.5343330702446725,\n",
      "    \"lambada_standard\": 0.15447312245294004,\n",
      "    \"arc_easy\": 0.36195286195286197,\n",
      "    \"arc_challenge\": 0.1962457337883959\n",
      "  },\n",
      "  \"Soft Targets + OLF\": {\n",
      "    \"vqa-v2\": 0.2113,\n",
      "    \"textvqa-ocr\": 0.02451171875,\n",
      "    \"textvqa-pure\": 0.025683593749999997,\n",
      "    \"gqa\": 0.1543,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5311355311355311,\n",
      "    \"winogrande\": 0.516179952644041,\n",
      "    \"lambada_standard\": 0.19697263729866096,\n",
      "    \"arc_easy\": 0.4036195286195286,\n",
      "    \"arc_challenge\": 0.23208191126279865\n",
      "  },\n",
      "  \"SGM + OLF\": {\n",
      "    \"vqa-v2\": 0.0097,\n",
      "    \"textvqa-ocr\": 0.011816406250000001,\n",
      "    \"textvqa-pure\": 0.0021484375,\n",
      "    \"gqa\": 0.0078000000000000005,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5604395604395604,\n",
      "    \"winogrande\": 0.5059194948697711,\n",
      "    \"lambada_standard\": 0.21036289540073744,\n",
      "    \"arc_easy\": 0.41624579124579125,\n",
      "    \"arc_challenge\": 0.2022184300341297\n",
      "  },\n",
      "  \"IA3\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.0,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.575091575091575,\n",
      "    \"winogrande\": 0.4964483030781373,\n",
      "    \"lambada_standard\": 0.18455268775470599,\n",
      "    \"arc_easy\": 0.44107744107744107,\n",
      "    \"arc_challenge\": 0.20136518771331058\n",
      "  },\n",
      "  \"LoRA (1/4 Full Rank)\": {\n",
      "    \"vqa-v2\": 0.2464,\n",
      "    \"textvqa-ocr\": 0.00927734375,\n",
      "    \"textvqa-pure\": 0.014062500000000004,\n",
      "    \"gqa\": 0.15039999999999998,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5311355311355311,\n",
      "    \"winogrande\": 0.5011838989739542,\n",
      "    \"lambada_standard\": 0.08111779545895595,\n",
      "    \"arc_easy\": 0.3653198653198653,\n",
      "    \"arc_challenge\": 0.20392491467576793\n",
      "  },\n",
      "  \"LoRA (1/4 Full Rank, Higher Alpha)\": {\n",
      "    \"vqa-v2\": 0.0646,\n",
      "    \"textvqa-ocr\": 0.0068359375,\n",
      "    \"textvqa-pure\": 0.00546875,\n",
      "    \"gqa\": 0.024399999999999998,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5384615384615384,\n",
      "    \"winogrande\": 0.4972375690607735,\n",
      "    \"lambada_standard\": 0.18707549000582185,\n",
      "    \"arc_easy\": 0.3813131313131313,\n",
      "    \"arc_challenge\": 0.2090443686006826\n",
      "  },\n",
      "  \"LoRA (1/2 Full Rank, Higher Alpha)\": {\n",
      "    \"vqa-v2\": 0.2872,\n",
      "    \"textvqa-ocr\": 0.010546875,\n",
      "    \"textvqa-pure\": 0.02666015625,\n",
      "    \"gqa\": 0.1973,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5860805860805861,\n",
      "    \"winogrande\": 0.5043409629044988,\n",
      "    \"lambada_standard\": 0.10149427517950708,\n",
      "    \"arc_easy\": 0.3872053872053872,\n",
      "    \"arc_challenge\": 0.18686006825938567\n",
      "  },\n",
      "  \"LoRA (1/2 Full Rank)\": {\n",
      "    \"vqa-v2\": 0.0013,\n",
      "    \"textvqa-ocr\": 0.001953125,\n",
      "    \"textvqa-pure\": 0.0009765625,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": NaN,\n",
      "    \"winogrande\": NaN,\n",
      "    \"lambada_standard\": NaN,\n",
      "    \"arc_easy\": NaN,\n",
      "    \"arc_challenge\": NaN\n",
      "  },\n",
      "  \"LoRA (1/2 Full Rank, RSLoRA)\": {\n",
      "    \"vqa-v2\": 0.2897,\n",
      "    \"textvqa-ocr\": 0.010156250000000002,\n",
      "    \"textvqa-pure\": 0.017382812500000004,\n",
      "    \"gqa\": 0.1797,\n",
      "    \"refcoco\": 0.0009765625,\n",
      "    \"wsc273\": 0.5457875457875457,\n",
      "    \"winogrande\": 0.4964483030781373,\n",
      "    \"lambada_standard\": 0.1946438967591694,\n",
      "    \"arc_easy\": 0.3888888888888889,\n",
      "    \"arc_challenge\": 0.2167235494880546\n",
      "  },\n",
      "  \"LoRA (1/2 Full Rank, RSLoRA, KQV Target)\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.0,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": NaN,\n",
      "    \"winogrande\": NaN,\n",
      "    \"lambada_standard\": NaN,\n",
      "    \"arc_easy\": NaN,\n",
      "    \"arc_challenge\": NaN\n",
      "  },\n",
      "  \"Soft Targets 0.001\": {\n",
      "    \"vqa-v2\": 0.25120000000000003,\n",
      "    \"textvqa-ocr\": 0.0216796875,\n",
      "    \"textvqa-pure\": 0.017285156250000003,\n",
      "    \"gqa\": 0.1484,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5164835164835165,\n",
      "    \"winogrande\": 0.505130228887135,\n",
      "    \"lambada_standard\": 0.1560256161459344,\n",
      "    \"arc_easy\": 0.37457912457912457,\n",
      "    \"arc_challenge\": 0.1962457337883959\n",
      "  },\n",
      "  \"Soft Targets 0.1\": {\n",
      "    \"vqa-v2\": 0.0338,\n",
      "    \"textvqa-ocr\": 0.011914062500000001,\n",
      "    \"textvqa-pure\": 0.01318359375,\n",
      "    \"gqa\": 0.0176,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5164835164835165,\n",
      "    \"winogrande\": 0.5248618784530387,\n",
      "    \"lambada_standard\": 0.20861633999611875,\n",
      "    \"arc_easy\": 0.39057239057239057,\n",
      "    \"arc_challenge\": 0.22440273037542663\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
      "  \\label{tab:lora_variants_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\uparrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Original LLaVA & 30.32 & 2.40 & 3.83 & 22.17 & 5.29 & 7.83 & 24.78 \\\\\n",
      "Language Only LLM & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & - & 32.61 \\\\\n",
      "\\midrule\n",
      "LoRA (1/2 Full Rank, Higher Alpha) & 28.72 & 1.05 & 2.67 & 19.73 & 2.84 & 9.33 & 23.28 \\\\\n",
      "LoRA (1/2 Full Rank, RSLoRA) & 28.97 & 1.02 & 1.74 & 17.97 & 2.42 & 1.69 & 30.92 \\\\\n",
      "LoRA (1/4 Full Rank) & 24.64 & 0.93 & 1.41 & 15.04 & 2.11 & 11.64 & 20.97 \\\\\n",
      "LoRA (1/4 Full Rank, Higher Alpha) & 6.46 & 0.68 & 0.55 & 2.44 & 1.04 & 2.53 & 30.08 \\\\\n",
      "LoRA (1/2 Full Rank) & 0.13 & 0.20 & 0.10 & 0.00 & 0.00 & - & - \\\\\n",
      "LoRA (1/2 Full Rank, RSLoRA, KQV Target) & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & - & - \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\uparrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Original LLaVA & 30.32 & 2.40 & 3.83 & 22.17 & 5.29 & 7.83 & 24.78 \\\\\n",
      "Language Only LLM & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & - & 32.61 \\\\\n",
      "\\midrule\n",
      "Soft Targets & 32.67 & 6.92 & 6.10 & 25.39 & 10.57 & 2.83 & 29.78 \\\\\n",
      "Soft Targets + OLF & 21.13 & 2.45 & 2.57 & 15.43 & 4.40 & 0.73 & 31.88 \\\\\n",
      "Soft Targets 0.001 & 25.12 & 2.17 & 1.73 & 14.84 & 3.49 & 4.97 & 27.64 \\\\\n",
      "SGM & 28.39 & 1.37 & 2.71 & 17.48 & 3.36 & 2.68 & 29.93 \\\\\n",
      "LoRA & 28.97 & 1.02 & 1.74 & 17.97 & 2.42 & 1.69 & 30.92 \\\\\n",
      "Output Layer Freezing (OLF) & 26.94 & 0.66 & 3.61 & 17.77 & 2.13 & 5.01 & 27.61 \\\\\n",
      "Soft Targets 0.1 & 3.38 & 1.19 & 1.32 & 1.76 & 1.62 & 0.67 & 31.95 \\\\\n",
      "SGM + OLF & 0.97 & 1.18 & 0.21 & 0.78 & 0.51 & 1.09 & 31.52 \\\\\n",
      "IA3 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 2.13 & 30.48 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'soft': 'stage-final-llava-v15-pythia+160m-soft',\n",
    "    'lora': 'stage-final-llava-v15-pythia+160m-lora',\n",
    "    'sgm': 'stage-final-llava-v15-pythia+160m-sgm',\n",
    "    'original': 'stage-final-llava-v15-pythia+160m',\n",
    "    'vicuna': 'reproduction-align-pythia+160m',\n",
    "    'olf': 'stage-final-llava-v15-pythia+160m-olf',\n",
    "    'softolf': 'stage-final-llava-v15-pythia+160m-softolf',\n",
    "    'sgmolf': 'stage-final-llava-v15-pythia+160m-sgmolf',\n",
    "    'ia3': 'stage-final-llava-v15-pythia+160m-ia3',\n",
    "    'lora-quarterfullrank': 'stage-final-llava-v15-pythia+160m-lora-use_rslora-rank_by_factor_4',\n",
    "    'lora-quarterfullrank-higheralpha': 'stage-final-llava-v15-pythia+160m-lora-use_rslora-rank_by_factor_4-higheralpha-16',\n",
    "    'lora-halffullrank-higheralpha': 'stage-final-llava-v15-pythia+160m-lora-use_rslora-rank_by_factor_2-higheralpha-32',\n",
    "    'lora-halffullrank': 'stage-final-llava-v15-pythia+160m-lora-rank_by_factor_2',\n",
    "    'lora-halffullrank-rslora': 'stage-final-llava-v15-pythia+160m-lora-use_rslora-rank_by_factor_2',\n",
    "    'lora-halffullrank-rslora-kqv': 'stage-final-llava-v15-pythia+160m-lora-use_rslora-higher_rank-target_modules_kqv',\n",
    "    'soft-0.001': 'stage-final-llava-v15-pythia+160m-soft-0.001',\n",
    "    'soft-0.1': 'stage-final-llava-v15-pythia+160m-soft-0.1',\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants of LoRA\n",
    "name_mapping = {\n",
    "    'soft': 'Soft Targets',\n",
    "    'softolf': 'Soft Targets + OLF',\n",
    "    'sgmolf': 'SGM + OLF',\n",
    "    'sgm': 'SGM',\n",
    "    'lora': 'LoRA',\n",
    "    'ia3': 'IA3',\n",
    "    'original': 'Original LLaVA',\n",
    "    'vicuna': 'Language Only LLM',\n",
    "    'olf': 'Output Layer Freezing (OLF)',\n",
    "    'lora-old': 'LoRA (Rank 16, Alpha 8)',\n",
    "    'lora-quarterfullrank': 'LoRA (1/4 Full Rank)',\n",
    "    'lora-quarterfullrank-higheralpha': 'LoRA (1/4 Full Rank, Higher Alpha)',\n",
    "    'lora-halffullrank-higheralpha': 'LoRA (1/2 Full Rank, Higher Alpha)',\n",
    "    'lora-halffullrank': 'LoRA (1/2 Full Rank)',\n",
    "    'lora-halffullrank-rslora': 'LoRA (1/2 Full Rank, RSLoRA)',\n",
    "    'lora-halffullrank-rslora-kqv': 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)',\n",
    "    'soft-0.001': 'Soft Targets 0.001',\n",
    "    'soft-0.1': 'Soft Targets 0.1'\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Original LLaVA\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Original LLaVA\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Separate the data into two groups\n",
    "lora_variants = [\n",
    "    'LoRA (1/4 Full Rank)', 'LoRA (1/4 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank)', 'LoRA (1/2 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank, RSLoRA)', 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)'\n",
    "]\n",
    "\n",
    "lora_table_data = [item for item in table_data if item[0] in lora_variants]\n",
    "other_table_data = [item for item in table_data if item[0] not in lora_variants]\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for LoRA variants\n",
    "latex_code_lora = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
    "  \\\\label{tab:lora_variants_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_lora += \"Original LLaVA & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in lora_table_data:\n",
    "    latex_code_lora += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_lora += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "latex_code_other += \"Original LLaVA & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in other_table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_lora)\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
