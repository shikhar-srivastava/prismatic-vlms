{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythia410M Epochs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": 0.001,\n",
      "    \"textvqa-ocr\": 0.001953125,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.002,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.6446886446886447,\n",
      "    \"winogrande\": 0.5343330702446725,\n",
      "    \"lambada_standard\": 0.39355715117407336,\n",
      "    \"arc_easy\": 0.5147306397306397,\n",
      "    \"arc_challenge\": 0.20648464163822525\n",
      "  },\n",
      "  \"Naive FT (410M)\": {\n",
      "    \"vqa-v2\": 0.5488000000000001,\n",
      "    \"textvqa-ocr\": 0.24384765625000018,\n",
      "    \"textvqa-pure\": 0.20781250000000018,\n",
      "    \"gqa\": 0.4102,\n",
      "    \"refcoco\": 0.052734375,\n",
      "    \"wsc273\": 0.6043956043956044,\n",
      "    \"winogrande\": 0.5295974743488555,\n",
      "    \"lambada_standard\": 0.3073937512128857,\n",
      "    \"arc_easy\": 0.4978956228956229,\n",
      "    \"arc_challenge\": 0.2295221843003413\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.025699999999999997,\n",
      "    \"textvqa-ocr\": 0.003125,\n",
      "    \"textvqa-pure\": 0.0421875,\n",
      "    \"gqa\": 0.0039000000000000003,\n",
      "    \"refcoco\": 0.0341796875,\n",
      "    \"wsc273\": 0.6190476190476191,\n",
      "    \"winogrande\": 0.5445935280189423,\n",
      "    \"lambada_standard\": 0.2841063458179701,\n",
      "    \"arc_easy\": 0.4810606060606061,\n",
      "    \"arc_challenge\": 0.2354948805460751\n",
      "  },\n",
      "  \"Naive FT (410M, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6029,\n",
      "    \"textvqa-ocr\": 0.25458984375000004,\n",
      "    \"textvqa-pure\": 0.25410156250000016,\n",
      "    \"gqa\": 0.42869999999999997,\n",
      "    \"refcoco\": 0.0302734375,\n",
      "    \"wsc273\": 0.5897435897435898,\n",
      "    \"winogrande\": 0.5035516969218626,\n",
      "    \"lambada_standard\": 0.2679992237531535,\n",
      "    \"arc_easy\": 0.5004208754208754,\n",
      "    \"arc_challenge\": 0.24488054607508533\n",
      "  },\n",
      "  \"Soft Targets (410M)\": {\n",
      "    \"vqa-v2\": 0.4975,\n",
      "    \"textvqa-ocr\": 0.22988281250000006,\n",
      "    \"textvqa-pure\": 0.1310546875,\n",
      "    \"gqa\": 0.3418,\n",
      "    \"refcoco\": 0.052734375,\n",
      "    \"wsc273\": 0.6263736263736264,\n",
      "    \"winogrande\": 0.5335438042620363,\n",
      "    \"lambada_standard\": 0.3353386376867844,\n",
      "    \"arc_easy\": 0.5025252525252525,\n",
      "    \"arc_challenge\": 0.22525597269624573\n",
      "  },\n",
      "  \"Soft Targets (410M, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.5379,\n",
      "    \"textvqa-ocr\": 0.25917968750000014,\n",
      "    \"textvqa-pure\": 0.16738281250000012,\n",
      "    \"gqa\": 0.3945,\n",
      "    \"refcoco\": 0.0537109375,\n",
      "    \"wsc273\": 0.5934065934065934,\n",
      "    \"winogrande\": 0.5398579321231255,\n",
      "    \"lambada_standard\": 0.2938094313991849,\n",
      "    \"arc_easy\": 0.5058922558922558,\n",
      "    \"arc_challenge\": 0.25\n",
      "  },\n",
      "  \"Soft Targets (410M, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.5661,\n",
      "    \"textvqa-ocr\": 0.15341796875,\n",
      "    \"textvqa-pure\": 0.1733398437500001,\n",
      "    \"gqa\": 0.38380000000000003,\n",
      "    \"refcoco\": 0.033203125,\n",
      "    \"wsc273\": 0.6336996336996337,\n",
      "    \"winogrande\": 0.5240726124704025,\n",
      "    \"lambada_standard\": 0.28798758005045605,\n",
      "    \"arc_easy\": 0.4739057239057239,\n",
      "    \"arc_challenge\": 0.24829351535836178\n",
      "  },\n",
      "  \"Corrected OLF LLaVA (410M)\": {\n",
      "    \"vqa-v2\": 0.5396,\n",
      "    \"textvqa-ocr\": 0.21669921875000006,\n",
      "    \"textvqa-pure\": 0.19990234375000013,\n",
      "    \"gqa\": 0.39840000000000003,\n",
      "    \"refcoco\": 0.041015625,\n",
      "    \"wsc273\": 0.6007326007326007,\n",
      "    \"winogrande\": 0.5232833464877664,\n",
      "    \"lambada_standard\": 0.3013778381525325,\n",
      "    \"arc_easy\": 0.49242424242424243,\n",
      "    \"arc_challenge\": 0.22525597269624573\n",
      "  },\n",
      "  \"SGM + Corrected OLF (410M)\": {\n",
      "    \"vqa-v2\": 0.41119999999999995,\n",
      "    \"textvqa-ocr\": 0.14960937499999996,\n",
      "    \"textvqa-pure\": 0.08398437499999997,\n",
      "    \"gqa\": 0.2988,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.63003663003663,\n",
      "    \"winogrande\": 0.5209155485398579,\n",
      "    \"lambada_standard\": 0.3465942169609936,\n",
      "    \"arc_easy\": 0.4793771043771044,\n",
      "    \"arc_challenge\": 0.22098976109215018\n",
      "  },\n",
      "  \"SGM (410M)\": {\n",
      "    \"vqa-v2\": 0.424,\n",
      "    \"textvqa-ocr\": 0.18476562500000002,\n",
      "    \"textvqa-pure\": 0.08291015624999999,\n",
      "    \"gqa\": 0.2998,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.6190476190476191,\n",
      "    \"winogrande\": 0.5256511444356748,\n",
      "    \"lambada_standard\": 0.35144575975160103,\n",
      "    \"arc_easy\": 0.476010101010101,\n",
      "    \"arc_challenge\": 0.22440273037542663\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
      "  \\label{tab:lora_variants_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 54.88 & 24.38 & 20.78 & 41.02 & 30.37 & 1.23 & 37.99 \\\\\n",
      "Language Only LLM & 0.10 & 0.20 & 0.00 & 0.20 & 0.00 & - & 39.22 \\\\\n",
      "\\midrule\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 54.88 & 24.38 & 20.78 & 41.02 & 30.37 & 1.23 & 37.99 \\\\\n",
      "Language Only LLM & 0.10 & 0.20 & 0.00 & 0.20 & 0.00 & - & 39.22 \\\\\n",
      "\\midrule\n",
      "Naive FT (410M, +3 Epochs) & 60.29 & 25.46 & 25.41 & 42.87 & 33.74 & 2.17 & 37.05 \\\\\n",
      "Corrected OLF LLaVA (410M) & 53.96 & 21.67 & 19.99 & 39.84 & 28.61 & 1.80 & 37.41 \\\\\n",
      "Soft Targets (410M, +2 Epochs) & 53.79 & 25.92 & 16.74 & 39.45 & 28.12 & 0.51 & 38.71 \\\\\n",
      "Soft Targets (410M, +3 Epochs) & 56.61 & 15.34 & 17.33 & 38.38 & 24.01 & 1.04 & 38.18 \\\\\n",
      "Soft Targets (410M) & 49.75 & 22.99 & 13.11 & 34.18 & 23.65 & 0.40 & 38.81 \\\\\n",
      "SGM (410M) & 42.40 & 18.48 & 8.29 & 29.98 & 17.27 & 0.52 & 38.70 \\\\\n",
      "SGM + Corrected OLF (410M) & 41.12 & 14.96 & 8.40 & 29.88 & 16.41 & 0.77 & 38.45 \\\\\n",
      "Naive FT (410M, +2 Epochs) & 2.57 & 0.31 & 4.22 & 0.39 & 0.63 & 1.61 & 37.60 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'vicuna' : 'reproduction-align-pythia+410m',\n",
    "    'original' : 'stage-final-llava-v15-pythia+410m',\n",
    "    'original+2epochs': 'stage-final-llava-v15-pythia+410m-epochs-2',\n",
    "    'original+3epochs': 'stage-final-llava-v15-pythia+410m-epochs-3',\n",
    "    'soft': 'stage-final-llava-v15-pythia+410m-soft',\n",
    "    'soft+2epochs': 'stage-final-llava-v15-pythia+410m-soft-epochs-2',\n",
    "    'soft+3epochs': 'stage-final-llava-v15-pythia+410m-soft-epochs-3',\n",
    "    'oolf': 'stage-final-llava-v15-pythia+410m-oolf',\n",
    "    'sgm-oolf': 'stage-final-llava-v15-pythia+410m-sgm-oolf',\n",
    "    'sgm': 'stage-final-llava-v15-pythia+410m-sgm'\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants of LoRA\n",
    "name_mapping = {\n",
    "    'vicuna' : 'Language Only LLM',\n",
    "    'original': 'Naive FT (410M)',\n",
    "    'original+2epochs': 'Naive FT (410M, +2 Epochs)',\n",
    "    'original+3epochs': 'Naive FT (410M, +3 Epochs)',\n",
    "    'soft': 'Soft Targets (410M)',\n",
    "    'soft+2epochs': 'Soft Targets (410M, +2 Epochs)',\n",
    "    'soft+3epochs': 'Soft Targets (410M, +3 Epochs)',\n",
    "    'oolf': 'Corrected OLF LLaVA (410M)',\n",
    "    'sgm-oolf': 'SGM + Corrected OLF (410M)',\n",
    "    'sgm': 'SGM (410M)'\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Naive FT (410M)\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Naive FT (410M)\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Separate the data into two groups\n",
    "lora_variants = [\n",
    "    'LoRA (1/4 Full Rank)', 'LoRA (1/4 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank)', 'LoRA (1/2 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank, RSLoRA)', 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)'\n",
    "]\n",
    "\n",
    "lora_table_data = [item for item in table_data if item[0] in lora_variants]\n",
    "other_table_data = [item for item in table_data if item[0] not in lora_variants]\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for LoRA variants\n",
    "latex_code_lora = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
    "  \\\\label{tab:lora_variants_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_lora += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in lora_table_data:\n",
    "    latex_code_lora += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_lora += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "latex_code_other += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in other_table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_lora)\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythia1B Epochs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": 0.044000000000000004,\n",
      "    \"textvqa-ocr\": 0.00615234375,\n",
      "    \"textvqa-pure\": 0.04140625,\n",
      "    \"gqa\": 0.0127,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.673992673992674,\n",
      "    \"winogrande\": 0.5280189423835833,\n",
      "    \"lambada_standard\": 0.4395497768290316,\n",
      "    \"arc_easy\": 0.5845959595959596,\n",
      "    \"arc_challenge\": 0.24488054607508533\n",
      "  },\n",
      "  \"Naive FT (1B)\": {\n",
      "    \"vqa-v2\": 0.6443000000000001,\n",
      "    \"textvqa-ocr\": 0.3836914062500002,\n",
      "    \"textvqa-pure\": 0.3547851562499999,\n",
      "    \"gqa\": 0.45409999999999995,\n",
      "    \"refcoco\": 0.078125,\n",
      "    \"wsc273\": 0.6556776556776557,\n",
      "    \"winogrande\": 0.5351223362273086,\n",
      "    \"lambada_standard\": 0.390064040364836,\n",
      "    \"arc_easy\": 0.5715488215488216,\n",
      "    \"arc_challenge\": 0.27047781569965873\n",
      "  },\n",
      "  \"Naive FT (1B, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.664,\n",
      "    \"textvqa-ocr\": 0.38593750000000027,\n",
      "    \"textvqa-pure\": 0.36591796875000004,\n",
      "    \"gqa\": 0.4805,\n",
      "    \"refcoco\": 0.1220703125,\n",
      "    \"wsc273\": 0.663003663003663,\n",
      "    \"winogrande\": 0.5374901341752171,\n",
      "    \"lambada_standard\": 0.36561226470017466,\n",
      "    \"arc_easy\": 0.5702861952861953,\n",
      "    \"arc_challenge\": 0.2645051194539249\n",
      "  },\n",
      "  \"Naive FT (1B, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6535,\n",
      "    \"textvqa-ocr\": 0.3631835937500002,\n",
      "    \"textvqa-pure\": 0.3677734374999999,\n",
      "    \"gqa\": 0.48340000000000005,\n",
      "    \"refcoco\": 0.1513671875,\n",
      "    \"wsc273\": 0.652014652014652,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.35416262371434115,\n",
      "    \"arc_easy\": 0.569023569023569,\n",
      "    \"arc_challenge\": 0.2738907849829352\n",
      "  },\n",
      "  \"Soft Targets (1B)\": {\n",
      "    \"vqa-v2\": 0.5946,\n",
      "    \"textvqa-ocr\": 0.3458007812500003,\n",
      "    \"textvqa-pure\": 0.3119140625000001,\n",
      "    \"gqa\": 0.39840000000000003,\n",
      "    \"refcoco\": 0.0419921875,\n",
      "    \"wsc273\": 0.6593406593406593,\n",
      "    \"winogrande\": 0.5501183898973955,\n",
      "    \"lambada_standard\": 0.4116048903551329,\n",
      "    \"arc_easy\": 0.5765993265993266,\n",
      "    \"arc_challenge\": 0.26621160409556316\n",
      "  },\n",
      "  \"Soft Targets (1B, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6112,\n",
      "    \"textvqa-ocr\": 0.3769531250000001,\n",
      "    \"textvqa-pure\": 0.33125,\n",
      "    \"gqa\": 0.44920000000000004,\n",
      "    \"refcoco\": 0.0478515625,\n",
      "    \"wsc273\": 0.6703296703296703,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.40520085387153115,\n",
      "    \"arc_easy\": 0.5580808080808081,\n",
      "    \"arc_challenge\": 0.2841296928327645\n",
      "  },\n",
      "  \"Soft Targets (1B, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6182,\n",
      "    \"textvqa-ocr\": 0.3604492187500001,\n",
      "    \"textvqa-pure\": 0.32197265625,\n",
      "    \"gqa\": 0.4355,\n",
      "    \"refcoco\": 0.1005859375,\n",
      "    \"wsc273\": 0.6483516483516484,\n",
      "    \"winogrande\": 0.531965272296764,\n",
      "    \"lambada_standard\": 0.3700756840675335,\n",
      "    \"arc_easy\": 0.5509259259259259,\n",
      "    \"arc_challenge\": 0.2713310580204778\n",
      "  },\n",
      "  \"SGM + Corrected OLF (1B)\": {\n",
      "    \"vqa-v2\": 0.5354,\n",
      "    \"textvqa-ocr\": 0.3369140625000001,\n",
      "    \"textvqa-pure\": 0.28193359375000016,\n",
      "    \"gqa\": 0.374,\n",
      "    \"refcoco\": 0.0556640625,\n",
      "    \"wsc273\": 0.6813186813186813,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.44905880069862214,\n",
      "    \"arc_easy\": 0.569023569023569,\n",
      "    \"arc_challenge\": 0.26621160409556316\n",
      "  },\n",
      "  \"LoRA (1B), Track Plasticity, Cosine LR\": {\n",
      "    \"vqa-v2\": 0.5736,\n",
      "    \"textvqa-ocr\": 0.3387695312500002,\n",
      "    \"textvqa-pure\": 0.31220703125000004,\n",
      "    \"gqa\": 0.4053,\n",
      "    \"refcoco\": 0.0537109375,\n",
      "    \"wsc273\": 0.6666666666666666,\n",
      "    \"winogrande\": 0.5351223362273086,\n",
      "    \"lambada_standard\": 0.42033766737822625,\n",
      "    \"arc_easy\": 0.5614478114478114,\n",
      "    \"arc_challenge\": 0.27047781569965873\n",
      "  },\n",
      "  \"LoRA (1B), Track Plasticity, Constant LR, Warmup\": {\n",
      "    \"vqa-v2\": 0.5964,\n",
      "    \"textvqa-ocr\": 0.3736328125000002,\n",
      "    \"textvqa-pure\": 0.32041015625000013,\n",
      "    \"gqa\": 0.3975,\n",
      "    \"refcoco\": 0.0478515625,\n",
      "    \"wsc273\": 0.6703296703296703,\n",
      "    \"winogrande\": 0.5303867403314917,\n",
      "    \"lambada_standard\": 0.4240248398990879,\n",
      "    \"arc_easy\": 0.5808080808080808,\n",
      "    \"arc_challenge\": 0.26621160409556316\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
      "  \\label{tab:lora_variants_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 64.43 & 38.37 & 35.48 & 45.41 & 43.58 & -0.16 & 43.84 \\\\\n",
      "Language Only LLM & 4.40 & 0.62 & 4.14 & 1.27 & 1.39 & - & 43.68 \\\\\n",
      "\\midrule\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 64.43 & 38.37 & 35.48 & 45.41 & 43.58 & -0.16 & 43.84 \\\\\n",
      "Language Only LLM & 4.40 & 0.62 & 4.14 & 1.27 & 1.39 & - & 43.68 \\\\\n",
      "\\midrule\n",
      "Naive FT (1B, +2 Epochs) & 66.40 & 38.59 & 36.59 & 48.05 & 44.89 & 0.72 & 42.96 \\\\\n",
      "Naive FT (1B, +3 Epochs) & 65.35 & 36.32 & 36.78 & 48.34 & 44.09 & 0.62 & 43.06 \\\\\n",
      "Soft Targets (1B, +2 Epochs) & 61.12 & 37.70 & 33.12 & 44.92 & 41.96 & -1.29 & 44.97 \\\\\n",
      "Soft Targets (1B, +3 Epochs) & 61.82 & 36.04 & 32.20 & 43.55 & 40.84 & 0.67 & 43.01 \\\\\n",
      "LoRA (1B), Track Plasticity, Constant LR, Warmup & 59.64 & 37.36 & 32.04 & 39.75 & 40.04 & -0.91 & 44.59 \\\\\n",
      "Soft Targets (1B) & 59.46 & 34.58 & 31.19 & 39.84 & 38.87 & -0.75 & 44.43 \\\\\n",
      "LoRA (1B), Track Plasticity, Cosine LR & 57.36 & 33.88 & 31.22 & 40.53 & 38.59 & -0.86 & 44.54 \\\\\n",
      "SGM + Corrected OLF (1B) & 53.54 & 33.69 & 28.19 & 37.40 & 36.18 & -1.55 & 45.23 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'vicuna' : 'reproduction-align-pythia+1b',\n",
    "    'original' : 'stage-final-llava-v15-pythia+1b',\n",
    "    'original+2epochs': 'stage-final-llava-v15-pythia+1b-epochs-2',\n",
    "    'original+3epochs': 'stage-final-llava-v15-pythia+1b-epochs-3',\n",
    "    'soft': 'stage-final-llava-v15-pythia+1b-soft',\n",
    "    'soft+2epochs': 'stage-final-llava-v15-pythia+1b-soft-epochs-2',\n",
    "    'soft+3epochs': 'stage-final-llava-v15-pythia+1b-soft-epochs-3',\n",
    "    'sgm+oolf': 'stage-final-llava-v15-pythia+1b-sgm-oolf',\n",
    "    'track_plasticity': 'stage-final-llava-v15-pythia+1b-lora-track-plasticity',\n",
    "    'track_plasticity_constant_lr_with_warmup': 'stage-final-llava-v15-pythia+1b-lora-track-plasticity-constant_lr_with_warmup'\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants of LoRA\n",
    "name_mapping = {\n",
    "    'vicuna' : 'Language Only LLM',\n",
    "    'original': 'Naive FT (1B)',\n",
    "    'original+2epochs': 'Naive FT (1B, +2 Epochs)',\n",
    "    'original+3epochs': 'Naive FT (1B, +3 Epochs)',\n",
    "    'soft': 'Soft Targets (1B)',\n",
    "    'soft+2epochs': 'Soft Targets (1B, +2 Epochs)',\n",
    "    'soft+3epochs': 'Soft Targets (1B, +3 Epochs)',\n",
    "    'sgm+oolf': 'SGM + Corrected OLF (1B)',\n",
    "    'track_plasticity': 'LoRA (1B), Track Plasticity, Cosine LR',\n",
    "    'track_plasticity_constant_lr_with_warmup': 'LoRA (1B), Track Plasticity, Constant LR, Warmup'\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Naive FT (1B)\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Naive FT (1B)\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Separate the data into two groups\n",
    "lora_variants = [\n",
    "    'LoRA (1/4 Full Rank)', 'LoRA (1/4 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank)', 'LoRA (1/2 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank, RSLoRA)', 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)'\n",
    "]\n",
    "\n",
    "lora_table_data = [item for item in table_data if item[0] in lora_variants]\n",
    "other_table_data = [item for item in table_data if item[0] not in lora_variants]\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for LoRA variants\n",
    "latex_code_lora = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
    "  \\\\label{tab:lora_variants_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_lora += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in lora_table_data:\n",
    "    latex_code_lora += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_lora += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "latex_code_other += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in other_table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_lora)\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 410M Schedule Free Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model 'stage-final-llava-v15-pythia+410m-schedule-free-epochs-4' not found in results\n",
      "{\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": NaN,\n",
      "    \"textvqa-ocr\": NaN,\n",
      "    \"textvqa-pure\": NaN,\n",
      "    \"gqa\": NaN,\n",
      "    \"refcoco\": NaN,\n",
      "    \"wsc273\": 0.6446886446886447,\n",
      "    \"winogrande\": 0.5343330702446725,\n",
      "    \"lambada_standard\": 0.39355715117407336,\n",
      "    \"arc_easy\": 0.5147306397306397,\n",
      "    \"arc_challenge\": 0.20648464163822525\n",
      "  },\n",
      "  \"Naive FT (410M)\": {\n",
      "    \"vqa-v2\": 0.5488000000000001,\n",
      "    \"textvqa-ocr\": 0.24384765625000018,\n",
      "    \"textvqa-pure\": 0.20781250000000018,\n",
      "    \"gqa\": 0.4102,\n",
      "    \"refcoco\": 0.052734375,\n",
      "    \"wsc273\": 0.6043956043956044,\n",
      "    \"winogrande\": 0.5295974743488555,\n",
      "    \"lambada_standard\": 0.3073937512128857,\n",
      "    \"arc_easy\": 0.4978956228956229,\n",
      "    \"arc_challenge\": 0.2295221843003413\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.025699999999999997,\n",
      "    \"textvqa-ocr\": 0.003125,\n",
      "    \"textvqa-pure\": 0.0421875,\n",
      "    \"gqa\": 0.0039000000000000003,\n",
      "    \"refcoco\": 0.0341796875,\n",
      "    \"wsc273\": 0.6190476190476191,\n",
      "    \"winogrande\": 0.5445935280189423,\n",
      "    \"lambada_standard\": 0.2841063458179701,\n",
      "    \"arc_easy\": 0.4810606060606061,\n",
      "    \"arc_challenge\": 0.2354948805460751\n",
      "  },\n",
      "  \"Naive FT (410M, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.6029,\n",
      "    \"textvqa-ocr\": 0.25458984375000004,\n",
      "    \"textvqa-pure\": 0.25410156250000016,\n",
      "    \"gqa\": 0.42869999999999997,\n",
      "    \"refcoco\": 0.0302734375,\n",
      "    \"wsc273\": 0.5897435897435898,\n",
      "    \"winogrande\": 0.5035516969218626,\n",
      "    \"lambada_standard\": 0.2679992237531535,\n",
      "    \"arc_easy\": 0.5004208754208754,\n",
      "    \"arc_challenge\": 0.24488054607508533\n",
      "  },\n",
      "  \"Soft Targets (410M)\": {\n",
      "    \"vqa-v2\": 0.4975,\n",
      "    \"textvqa-ocr\": 0.22988281250000006,\n",
      "    \"textvqa-pure\": 0.1310546875,\n",
      "    \"gqa\": 0.3418,\n",
      "    \"refcoco\": 0.052734375,\n",
      "    \"wsc273\": 0.6263736263736264,\n",
      "    \"winogrande\": 0.5335438042620363,\n",
      "    \"lambada_standard\": 0.3353386376867844,\n",
      "    \"arc_easy\": 0.5025252525252525,\n",
      "    \"arc_challenge\": 0.22525597269624573\n",
      "  },\n",
      "  \"Soft Targets (410M, +2 Epochs)\": {\n",
      "    \"vqa-v2\": 0.5379,\n",
      "    \"textvqa-ocr\": 0.25917968750000014,\n",
      "    \"textvqa-pure\": 0.16738281250000012,\n",
      "    \"gqa\": 0.3945,\n",
      "    \"refcoco\": 0.0537109375,\n",
      "    \"wsc273\": 0.5934065934065934,\n",
      "    \"winogrande\": 0.5398579321231255,\n",
      "    \"lambada_standard\": 0.2938094313991849,\n",
      "    \"arc_easy\": 0.5058922558922558,\n",
      "    \"arc_challenge\": 0.25\n",
      "  },\n",
      "  \"Soft Targets (410M, +3 Epochs)\": {\n",
      "    \"vqa-v2\": 0.5661,\n",
      "    \"textvqa-ocr\": 0.15341796875,\n",
      "    \"textvqa-pure\": 0.1733398437500001,\n",
      "    \"gqa\": 0.38380000000000003,\n",
      "    \"refcoco\": 0.033203125,\n",
      "    \"wsc273\": 0.6336996336996337,\n",
      "    \"winogrande\": 0.5240726124704025,\n",
      "    \"lambada_standard\": 0.28798758005045605,\n",
      "    \"arc_easy\": 0.4739057239057239,\n",
      "    \"arc_challenge\": 0.24829351535836178\n",
      "  },\n",
      "  \"Corrected OLF LLaVA (410M)\": {\n",
      "    \"vqa-v2\": 0.5396,\n",
      "    \"textvqa-ocr\": 0.21669921875000006,\n",
      "    \"textvqa-pure\": 0.19990234375000013,\n",
      "    \"gqa\": 0.39840000000000003,\n",
      "    \"refcoco\": 0.041015625,\n",
      "    \"wsc273\": 0.6007326007326007,\n",
      "    \"winogrande\": 0.5232833464877664,\n",
      "    \"lambada_standard\": 0.3013778381525325,\n",
      "    \"arc_easy\": 0.49242424242424243,\n",
      "    \"arc_challenge\": 0.22525597269624573\n",
      "  },\n",
      "  \"SGM + Corrected OLF (410M)\": {\n",
      "    \"vqa-v2\": 0.41119999999999995,\n",
      "    \"textvqa-ocr\": 0.14960937499999996,\n",
      "    \"textvqa-pure\": 0.08398437499999997,\n",
      "    \"gqa\": 0.2988,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.63003663003663,\n",
      "    \"winogrande\": 0.5209155485398579,\n",
      "    \"lambada_standard\": 0.3465942169609936,\n",
      "    \"arc_easy\": 0.4793771043771044,\n",
      "    \"arc_challenge\": 0.22098976109215018\n",
      "  },\n",
      "  \"SGM (410M)\": {\n",
      "    \"vqa-v2\": 0.424,\n",
      "    \"textvqa-ocr\": 0.18476562500000002,\n",
      "    \"textvqa-pure\": 0.08291015624999999,\n",
      "    \"gqa\": 0.2998,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.6190476190476191,\n",
      "    \"winogrande\": 0.5256511444356748,\n",
      "    \"lambada_standard\": 0.35144575975160103,\n",
      "    \"arc_easy\": 0.476010101010101,\n",
      "    \"arc_challenge\": 0.22440273037542663\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs, Merge - 5198 Steps)\": {\n",
      "    \"vqa-v2\": 0.43700000000000006,\n",
      "    \"textvqa-ocr\": 0.17812499999999998,\n",
      "    \"textvqa-pure\": 0.10468749999999995,\n",
      "    \"gqa\": 0.3467,\n",
      "    \"refcoco\": 0.0185546875,\n",
      "    \"wsc273\": 0.6410256410256411,\n",
      "    \"winogrande\": 0.5232833464877664,\n",
      "    \"lambada_standard\": 0.31127498544537163,\n",
      "    \"arc_easy\": 0.47474747474747475,\n",
      "    \"arc_challenge\": 0.2226962457337884\n",
      "  },\n",
      "  \"Naive FT (410M, +1 Epoch, Merge - 2599 Steps)\": {\n",
      "    \"vqa-v2\": 0.4396,\n",
      "    \"textvqa-ocr\": 0.13261718749999998,\n",
      "    \"textvqa-pure\": 0.09921874999999998,\n",
      "    \"gqa\": 0.33590000000000003,\n",
      "    \"refcoco\": 0.0439453125,\n",
      "    \"wsc273\": 0.6373626373626373,\n",
      "    \"winogrande\": 0.5138121546961326,\n",
      "    \"lambada_standard\": 0.29322724626431207,\n",
      "    \"arc_easy\": 0.48569023569023567,\n",
      "    \"arc_challenge\": 0.22866894197952217\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs, Merge - 2599 Steps)\": {\n",
      "    \"vqa-v2\": 0.4261,\n",
      "    \"textvqa-ocr\": 0.13291015625,\n",
      "    \"textvqa-pure\": 0.08310546874999998,\n",
      "    \"gqa\": 0.3486,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.6483516483516484,\n",
      "    \"winogrande\": 0.5232833464877664,\n",
      "    \"lambada_standard\": 0.29943722103628956,\n",
      "    \"arc_easy\": 0.4734848484848485,\n",
      "    \"arc_challenge\": 0.23208191126279865\n",
      "  },\n",
      "  \"Naive FT (410M, +1 Epoch) Sch. Free\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.001171875,\n",
      "    \"textvqa-pure\": 0.001171875,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0185546875,\n",
      "    \"wsc273\": 0.6007326007326007,\n",
      "    \"winogrande\": 0.5327545382794001,\n",
      "    \"lambada_standard\": 0.2006598098195226,\n",
      "    \"arc_easy\": 0.4065656565656566,\n",
      "    \"arc_challenge\": 0.22781569965870307\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs) Sch. Free\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.0095703125,\n",
      "    \"textvqa-pure\": 0.0099609375,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.03125,\n",
      "    \"wsc273\": 0.5787545787545788,\n",
      "    \"winogrande\": 0.5224940805051302,\n",
      "    \"lambada_standard\": 0.2555792742091985,\n",
      "    \"arc_easy\": 0.4318181818181818,\n",
      "    \"arc_challenge\": 0.24744027303754265\n",
      "  },\n",
      "  \"Naive FT (410M, +3 Epochs) Sch. Free\": {\n",
      "    \"vqa-v2\": 0.5774,\n",
      "    \"textvqa-ocr\": 0.1515625,\n",
      "    \"textvqa-pure\": 0.24775390625000016,\n",
      "    \"gqa\": 0.4131,\n",
      "    \"refcoco\": 0.0478515625,\n",
      "    \"wsc273\": 0.5860805860805861,\n",
      "    \"winogrande\": 0.5224940805051302,\n",
      "    \"lambada_standard\": 0.28119542014360566,\n",
      "    \"arc_easy\": 0.4911616161616162,\n",
      "    \"arc_challenge\": 0.24061433447098976\n",
      "  },\n",
      "  \"Naive FT (410M, +1 Epoch) Inf. RSqrt\": {\n",
      "    \"vqa-v2\": 0.5191,\n",
      "    \"textvqa-ocr\": 0.17187500000000003,\n",
      "    \"textvqa-pure\": 0.1752929687500001,\n",
      "    \"gqa\": 0.36619999999999997,\n",
      "    \"refcoco\": 0.03125,\n",
      "    \"wsc273\": 0.6410256410256411,\n",
      "    \"winogrande\": 0.5414364640883977,\n",
      "    \"lambada_standard\": 0.3349505142635358,\n",
      "    \"arc_easy\": 0.49915824915824913,\n",
      "    \"arc_challenge\": 0.21075085324232082\n",
      "  },\n",
      "  \"Naive FT (410M, +2 Epochs) Inf. RSqrt\": {\n",
      "    \"vqa-v2\": 0.1295,\n",
      "    \"textvqa-ocr\": 0.01083984375,\n",
      "    \"textvqa-pure\": 0.01767578125,\n",
      "    \"gqa\": 0.0781,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.6227106227106227,\n",
      "    \"winogrande\": 0.5303867403314917,\n",
      "    \"lambada_standard\": 0.31069280031049873,\n",
      "    \"arc_easy\": 0.4612794612794613,\n",
      "    \"arc_challenge\": 0.23037542662116042\n",
      "  },\n",
      "  \"Naive FT (410M, +3 Epochs) Inf. RSqrt\": {\n",
      "    \"vqa-v2\": 0.068,\n",
      "    \"textvqa-ocr\": 0.0021484375,\n",
      "    \"textvqa-pure\": 0.023437500000000003,\n",
      "    \"gqa\": 0.042,\n",
      "    \"refcoco\": 0.0302734375,\n",
      "    \"wsc273\": 0.6153846153846154,\n",
      "    \"winogrande\": 0.5193370165745856,\n",
      "    \"lambada_standard\": 0.3277702309334368,\n",
      "    \"arc_easy\": 0.4650673400673401,\n",
      "    \"arc_challenge\": 0.23464163822525597\n",
      "  },\n",
      "  \"LoRA (410M) Track Plasticity\": {\n",
      "    \"vqa-v2\": 0.4384,\n",
      "    \"textvqa-ocr\": 0.18886718750000006,\n",
      "    \"textvqa-pure\": 0.10527343749999998,\n",
      "    \"gqa\": 0.3281,\n",
      "    \"refcoco\": 0.0048828125,\n",
      "    \"wsc273\": 0.6227106227106227,\n",
      "    \"winogrande\": 0.5288082083662194,\n",
      "    \"lambada_standard\": 0.29691441878517366,\n",
      "    \"arc_easy\": 0.4781144781144781,\n",
      "    \"arc_challenge\": 0.2295221843003413\n",
      "  },\n",
      "  \"LoRA (410M) Track Plasticity, Const. LR\": {\n",
      "    \"vqa-v2\": 0.4531,\n",
      "    \"textvqa-ocr\": 0.21376953125000006,\n",
      "    \"textvqa-pure\": 0.15107421875000002,\n",
      "    \"gqa\": 0.35450000000000004,\n",
      "    \"refcoco\": 0.0146484375,\n",
      "    \"wsc273\": 0.6153846153846154,\n",
      "    \"winogrande\": 0.5288082083662194,\n",
      "    \"lambada_standard\": 0.30855812148263145,\n",
      "    \"arc_easy\": 0.47264309764309764,\n",
      "    \"arc_challenge\": 0.22781569965870307\n",
      "  },\n",
      "  \"LoRA (410M) Track Plasticity, Const. LR, Warmup\": {\n",
      "    \"vqa-v2\": 0.4753,\n",
      "    \"textvqa-ocr\": 0.21201171875000005,\n",
      "    \"textvqa-pure\": 0.17148437500000008,\n",
      "    \"gqa\": 0.35450000000000004,\n",
      "    \"refcoco\": 0.0078125,\n",
      "    \"wsc273\": 0.6153846153846154,\n",
      "    \"winogrande\": 0.5311760063141279,\n",
      "    \"lambada_standard\": 0.32097807102658643,\n",
      "    \"arc_easy\": 0.502104377104377,\n",
      "    \"arc_challenge\": 0.23464163822525597\n",
      "  },\n",
      "  \"AdaLoRA (410M) Const. LR, Warmup\": {\n",
      "    \"vqa-v2\": 0.4413,\n",
      "    \"textvqa-ocr\": 0.1719726562500001,\n",
      "    \"textvqa-pure\": 0.10947265625,\n",
      "    \"gqa\": 0.32130000000000003,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5970695970695971,\n",
      "    \"winogrande\": 0.5272296764009471,\n",
      "    \"lambada_standard\": 0.28197166699010284,\n",
      "    \"arc_easy\": 0.4962121212121212,\n",
      "    \"arc_challenge\": 0.21331058020477817\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
      "  \\label{tab:lora_variants_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 54.88 & 24.38 & 20.78 & 41.02 & 30.37 & 1.23 & 37.99 \\\\\n",
      "Language Only LLM & - & - & - & - & - & - & 39.22 \\\\\n",
      "\\midrule\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 54.88 & 24.38 & 20.78 & 41.02 & 30.37 & 1.23 & 37.99 \\\\\n",
      "Language Only LLM & - & - & - & - & - & - & 39.22 \\\\\n",
      "\\midrule\n",
      "Naive FT (410M, +3 Epochs) & 60.29 & 25.46 & 25.41 & 42.87 & 33.74 & 2.17 & 37.05 \\\\\n",
      "Corrected OLF LLaVA (410M) & 53.96 & 21.67 & 19.99 & 39.84 & 28.61 & 1.80 & 37.41 \\\\\n",
      "Soft Targets (410M, +2 Epochs) & 53.79 & 25.92 & 16.74 & 39.45 & 28.12 & 0.51 & 38.71 \\\\\n",
      "Naive FT (410M, +3 Epochs) Sch. Free & 57.74 & 15.16 & 24.78 & 41.31 & 27.05 & 1.82 & 37.40 \\\\\n",
      "LoRA (410M) Track Plasticity, Const. LR, Warmup & 47.53 & 21.20 & 17.15 & 35.45 & 25.85 & 0.39 & 38.83 \\\\\n",
      "Naive FT (410M, +1 Epoch) Inf. RSqrt & 51.91 & 17.19 & 17.53 & 36.62 & 24.72 & 1.17 & 38.05 \\\\\n",
      "LoRA (410M) Track Plasticity, Const. LR & 45.31 & 21.38 & 15.11 & 35.45 & 24.50 & 1.52 & 37.70 \\\\\n",
      "Soft Targets (410M, +3 Epochs) & 56.61 & 15.34 & 17.33 & 38.38 & 24.01 & 1.04 & 38.18 \\\\\n",
      "Soft Targets (410M) & 49.75 & 22.99 & 13.11 & 34.18 & 23.65 & 0.40 & 38.81 \\\\\n",
      "LoRA (410M) Track Plasticity & 43.84 & 18.89 & 10.53 & 32.81 & 19.88 & 1.66 & 37.56 \\\\\n",
      "AdaLoRA (410M) Const. LR, Warmup & 44.13 & 17.20 & 10.95 & 32.13 & 19.68 & 3.04 & 36.18 \\\\\n",
      "Naive FT (410M, +2 Epochs, Merge - 5198 Steps) & 43.70 & 17.81 & 10.47 & 34.67 & 19.67 & 1.57 & 37.65 \\\\\n",
      "Naive FT (410M, +1 Epoch, Merge - 2599 Steps) & 43.96 & 13.26 & 9.92 & 33.59 & 17.49 & 1.79 & 37.43 \\\\\n",
      "SGM (410M) & 42.40 & 18.48 & 8.29 & 29.98 & 17.27 & 0.52 & 38.70 \\\\\n",
      "SGM + Corrected OLF (410M) & 41.12 & 14.96 & 8.40 & 29.88 & 16.41 & 0.77 & 38.45 \\\\\n",
      "Naive FT (410M, +2 Epochs, Merge - 2599 Steps) & 42.61 & 13.29 & 8.31 & 34.86 & 16.15 & 1.38 & 37.84 \\\\\n",
      "Naive FT (410M, +2 Epochs) Inf. RSqrt & 12.95 & 1.08 & 1.77 & 7.81 & 2.36 & 1.39 & 37.83 \\\\\n",
      "Naive FT (410M, +3 Epochs) Inf. RSqrt & 6.80 & 0.21 & 2.34 & 4.20 & 0.73 & 0.80 & 38.42 \\\\\n",
      "Naive FT (410M, +2 Epochs) & 2.57 & 0.31 & 4.22 & 0.39 & 0.63 & 1.61 & 37.60 \\\\\n",
      "Naive FT (410M, +2 Epochs) Sch. Free & 0.00 & 0.96 & 1.00 & 0.00 & 0.00 & 3.28 & 35.94 \\\\\n",
      "Naive FT (410M, +1 Epoch) Sch. Free & 0.00 & 0.12 & 0.12 & 0.00 & 0.00 & 6.70 & 32.52 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'vicuna' : 'reproduction-align-pythia+410m',\n",
    "    'original' : 'stage-final-llava-v15-pythia+410m',\n",
    "    'original+2epochs': 'stage-final-llava-v15-pythia+410m-epochs-2',\n",
    "    'original+3epochs': 'stage-final-llava-v15-pythia+410m-epochs-3',\n",
    "    'soft': 'stage-final-llava-v15-pythia+410m-soft',\n",
    "    'soft+2epochs': 'stage-final-llava-v15-pythia+410m-soft-epochs-2',\n",
    "    'soft+3epochs': 'stage-final-llava-v15-pythia+410m-soft-epochs-3',\n",
    "    'oolf': 'stage-final-llava-v15-pythia+410m-oolf',\n",
    "    'sgm-oolf': 'stage-final-llava-v15-pythia+410m-sgm-oolf',\n",
    "    'sgm': 'stage-final-llava-v15-pythia+410m-sgm',\n",
    "    'merging_per_epoch_1_epoch_2': 'stage-final-llava-v15-pythia+410m-merging_per_epoch-1-epochs-2',\n",
    "    'merging_per_epoch_2_epoch_1': 'stage-final-llava-v15-pythia+410m-merging_per_epoch-2-epochs-1',\n",
    "    'merging_per_epoch_2_epoch_2': 'stage-final-llava-v15-pythia+410m-merging_per_epoch-2-epochs-2',\n",
    "    'schedule_free_epoch_1': 'stage-final-llava-v15-pythia+410m-schedule-free-epochs-1',\n",
    "    'schedule_free_epoch_2': 'stage-final-llava-v15-pythia+410m-schedule-free-epochs-2',\n",
    "    'schedule_free_epoch_3': 'stage-final-llava-v15-pythia+410m-schedule-free-epochs-3',\n",
    "    'schedule_free_epoch_4': 'stage-final-llava-v15-pythia+410m-schedule-free-epochs-4',\n",
    "    'infinite_rsqrt_schedule_1': 'stage-final-llava-v15-pythia+410m-infinite_rsqrt_schedule-epochs-1',\n",
    "    'infinite_rsqrt_schedule_2': 'stage-final-llava-v15-pythia+410m-infinite_rsqrt_schedule-epochs-2',\n",
    "    'infinite_rsqrt_schedule_3': 'stage-final-llava-v15-pythia+410m-infinite_rsqrt_schedule-epochs-3',\n",
    "    'lora_track_plasticity': 'stage-final-llava-v15-pythia+410m-lora-track-plasticity',\n",
    "    'lora_track_plasticity_constant_lr': 'stage-final-llava-v15-pythia+410m-lora-track-plasticity-constant_lr',\n",
    "    'lora_track_plasticity_constant_lr_with_warmup': 'stage-final-llava-v15-pythia+410m-lora-track-plasticity-constant_lr_with_warmup',\n",
    "    'adalora': 'stage-final-llava-v15-pythia+410m-adalora-constant_lr_warmup'\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants\n",
    "name_mapping = {\n",
    "    'vicuna' : 'Language Only LLM',\n",
    "    'original': 'Naive FT (410M)',\n",
    "    'original+2epochs': 'Naive FT (410M, +2 Epochs)',\n",
    "    'original+3epochs': 'Naive FT (410M, +3 Epochs)',\n",
    "    'soft': 'Soft Targets (410M)',\n",
    "    'soft+2epochs': 'Soft Targets (410M, +2 Epochs)',\n",
    "    'soft+3epochs': 'Soft Targets (410M, +3 Epochs)',\n",
    "    'oolf': 'Corrected OLF LLaVA (410M)',\n",
    "    'sgm-oolf': 'SGM + Corrected OLF (410M)',\n",
    "    'sgm': 'SGM (410M)',\n",
    "    'merging_per_epoch_1_epoch_2': 'Naive FT (410M, +2 Epochs, Merge - 5198 Steps)',\n",
    "    'merging_per_epoch_2_epoch_1': 'Naive FT (410M, +1 Epoch, Merge - 2599 Steps)',\n",
    "    'merging_per_epoch_2_epoch_2': 'Naive FT (410M, +2 Epochs, Merge - 2599 Steps)',\n",
    "    'schedule_free_epoch_1': 'Naive FT (410M, +1 Epoch) Sch. Free',\n",
    "    'schedule_free_epoch_2': 'Naive FT (410M, +2 Epochs) Sch. Free',\n",
    "    'schedule_free_epoch_3': 'Naive FT (410M, +3 Epochs) Sch. Free',\n",
    "    'schedule_free_epoch_4': 'Naive FT (410M, +4 Epochs) Sch. Free',\n",
    "    'infinite_rsqrt_schedule_1': 'Naive FT (410M, +1 Epoch) Inf. RSqrt',\n",
    "    'infinite_rsqrt_schedule_2': 'Naive FT (410M, +2 Epochs) Inf. RSqrt',\n",
    "    'infinite_rsqrt_schedule_3': 'Naive FT (410M, +3 Epochs) Inf. RSqrt',\n",
    "    'lora_track_plasticity': 'LoRA (410M) Track Plasticity',\n",
    "    'lora_track_plasticity_constant_lr': 'LoRA (410M) Track Plasticity, Const. LR',\n",
    "    'lora_track_plasticity_constant_lr_with_warmup': 'LoRA (410M) Track Plasticity, Const. LR, Warmup',\n",
    "    'adalora': 'AdaLoRA (410M) Const. LR, Warmup'\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Naive FT (410M)\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Naive FT (410M)\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Separate the data into two groups\n",
    "lora_variants = [\n",
    "    'LoRA (1/4 Full Rank)', 'LoRA (1/4 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank)', 'LoRA (1/2 Full Rank, Higher Alpha)', \n",
    "    'LoRA (1/2 Full Rank, RSLoRA)', 'LoRA (1/2 Full Rank, RSLoRA, KQV Target)'\n",
    "]\n",
    "\n",
    "lora_table_data = [item for item in table_data if item[0] in lora_variants]\n",
    "other_table_data = [item for item in table_data if item[0] not in lora_variants]\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for LoRA variants\n",
    "latex_code_lora = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} LoRA Variants}\n",
    "  \\\\label{tab:lora_variants_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_lora += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_lora += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in lora_table_data:\n",
    "    latex_code_lora += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_lora += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "latex_code_other += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in other_table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_lora)\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythia 160M LoRA Merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model 'stage-final-llava-v15-pythia+160m-sgm-oolf' not found in results\n",
      "{\n",
      "  \"Language Only LLM\": {\n",
      "    \"vqa-v2\": NaN,\n",
      "    \"textvqa-ocr\": NaN,\n",
      "    \"textvqa-pure\": NaN,\n",
      "    \"gqa\": NaN,\n",
      "    \"refcoco\": NaN,\n",
      "    \"wsc273\": 0.5677655677655677,\n",
      "    \"winogrande\": 0.4956590370955012,\n",
      "    \"lambada_standard\": 0.2334562390840287,\n",
      "    \"arc_easy\": 0.44234006734006737,\n",
      "    \"arc_challenge\": 0.19965870307167236\n",
      "  },\n",
      "  \"Naive FT (160M)\": {\n",
      "    \"vqa-v2\": 0.3032,\n",
      "    \"textvqa-ocr\": 0.0240234375,\n",
      "    \"textvqa-pure\": 0.038281249999999996,\n",
      "    \"gqa\": 0.2217,\n",
      "    \"refcoco\": 0.00390625,\n",
      "    \"wsc273\": 0.5347985347985348,\n",
      "    \"winogrande\": 0.5193370165745856,\n",
      "    \"lambada_standard\": 0.11313797787696488,\n",
      "    \"arc_easy\": 0.390993265993266,\n",
      "    \"arc_challenge\": 0.20051194539249148\n",
      "  },\n",
      "  \"Soft Targets (160M)\": {\n",
      "    \"vqa-v2\": 0.3267,\n",
      "    \"textvqa-ocr\": 0.06923828124999999,\n",
      "    \"textvqa-pure\": 0.061035156249999986,\n",
      "    \"gqa\": 0.2539,\n",
      "    \"refcoco\": 0.015625,\n",
      "    \"wsc273\": 0.5128205128205128,\n",
      "    \"winogrande\": 0.5082872928176796,\n",
      "    \"lambada_standard\": 0.17019212109450804,\n",
      "    \"arc_easy\": 0.39941077441077444,\n",
      "    \"arc_challenge\": 0.2226962457337884\n",
      "  },\n",
      "  \"Corrected OLF LLaVA (160M)\": {\n",
      "    \"vqa-v2\": 0.0254,\n",
      "    \"textvqa-ocr\": 0.0220703125,\n",
      "    \"textvqa-pure\": 0.0041015625,\n",
      "    \"gqa\": 0.0195,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": NaN,\n",
      "    \"winogrande\": NaN,\n",
      "    \"lambada_standard\": NaN,\n",
      "    \"arc_easy\": NaN,\n",
      "    \"arc_challenge\": NaN\n",
      "  },\n",
      "  \"SGM (160M)\": {\n",
      "    \"vqa-v2\": 0.2839,\n",
      "    \"textvqa-ocr\": 0.013671875,\n",
      "    \"textvqa-pure\": 0.0271484375,\n",
      "    \"gqa\": 0.1748,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5677655677655677,\n",
      "    \"winogrande\": 0.5074980268350434,\n",
      "    \"lambada_standard\": 0.17698428100135843,\n",
      "    \"arc_easy\": 0.3998316498316498,\n",
      "    \"arc_challenge\": 0.20733788395904437\n",
      "  },\n",
      "  \"LoRA (160M)\": {\n",
      "    \"vqa-v2\": 0.2897,\n",
      "    \"textvqa-ocr\": 0.010156250000000002,\n",
      "    \"textvqa-pure\": 0.017382812500000004,\n",
      "    \"gqa\": 0.1797,\n",
      "    \"refcoco\": 0.0009765625,\n",
      "    \"wsc273\": 0.5897435897435898,\n",
      "    \"winogrande\": 0.510655090765588,\n",
      "    \"lambada_standard\": 0.22608189404230544,\n",
      "    \"arc_easy\": 0.42592592592592593,\n",
      "    \"arc_challenge\": 0.2030716723549488\n",
      "  },\n",
      "  \"Naive FT (160M, +2 Epochs), Merge - 5198 Steps\": {\n",
      "    \"vqa-v2\": 0.0149,\n",
      "    \"textvqa-ocr\": 0.00556640625,\n",
      "    \"textvqa-pure\": 0.002734375,\n",
      "    \"gqa\": 0.001,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5677655677655677,\n",
      "    \"winogrande\": 0.5059194948697711,\n",
      "    \"lambada_standard\": 0.1963904521637881,\n",
      "    \"arc_easy\": 0.36195286195286197,\n",
      "    \"arc_challenge\": 0.19283276450511946\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 2599 Steps\": {\n",
      "    \"vqa-v2\": 0.1151,\n",
      "    \"textvqa-ocr\": 0.00888671875,\n",
      "    \"textvqa-pure\": 0.013671875,\n",
      "    \"gqa\": 0.0664,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5531135531135531,\n",
      "    \"winogrande\": 0.5169692186266772,\n",
      "    \"lambada_standard\": 0.23365030079565302,\n",
      "    \"arc_easy\": 0.4048821548821549,\n",
      "    \"arc_challenge\": 0.19795221843003413\n",
      "  },\n",
      "  \"Naive FT (160M, +2 Epochs), Merge - 2599 Steps\": {\n",
      "    \"vqa-v2\": 0.1447,\n",
      "    \"textvqa-ocr\": 0.00556640625,\n",
      "    \"textvqa-pure\": 0.01181640625,\n",
      "    \"gqa\": 0.048799999999999996,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5604395604395604,\n",
      "    \"winogrande\": 0.5027624309392266,\n",
      "    \"lambada_standard\": 0.2173491170192121,\n",
      "    \"arc_easy\": 0.3846801346801347,\n",
      "    \"arc_challenge\": 0.20136518771331058\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 1299 Steps\": {\n",
      "    \"vqa-v2\": 0.028900000000000002,\n",
      "    \"textvqa-ocr\": 0.00634765625,\n",
      "    \"textvqa-pure\": 0.0046875,\n",
      "    \"gqa\": 0.0068000000000000005,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5641025641025641,\n",
      "    \"winogrande\": 0.5098658247829518,\n",
      "    \"lambada_standard\": 0.1946438967591694,\n",
      "    \"arc_easy\": 0.406986531986532,\n",
      "    \"arc_challenge\": 0.2098976109215017\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 649 Steps\": {\n",
      "    \"vqa-v2\": 0.001,\n",
      "    \"textvqa-ocr\": 0.001171875,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5347985347985348,\n",
      "    \"winogrande\": 0.5280189423835833,\n",
      "    \"lambada_standard\": 0.2233650300795653,\n",
      "    \"arc_easy\": 0.41119528619528617,\n",
      "    \"arc_challenge\": 0.2175767918088737\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 324 Steps\": {\n",
      "    \"vqa-v2\": 0.0009,\n",
      "    \"textvqa-ocr\": 0.00029296875,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5311355311355311,\n",
      "    \"winogrande\": 0.5177584846093133,\n",
      "    \"lambada_standard\": 0.228410634581797,\n",
      "    \"arc_easy\": 0.43308080808080807,\n",
      "    \"arc_challenge\": 0.21416382252559726\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 162 Steps\": {\n",
      "    \"vqa-v2\": 0.0096,\n",
      "    \"textvqa-ocr\": 0.0009765625,\n",
      "    \"textvqa-pure\": 0.00087890625,\n",
      "    \"gqa\": 0.0078000000000000005,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5494505494505495,\n",
      "    \"winogrande\": 0.5193370165745856,\n",
      "    \"lambada_standard\": 0.21521443819134484,\n",
      "    \"arc_easy\": 0.4398148148148148,\n",
      "    \"arc_challenge\": 0.2090443686006826\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 81 Steps\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.0,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5714285714285714,\n",
      "    \"winogrande\": 0.5138121546961326,\n",
      "    \"lambada_standard\": 0.21657287017271493,\n",
      "    \"arc_easy\": 0.44107744107744107,\n",
      "    \"arc_challenge\": 0.19795221843003413\n",
      "  },\n",
      "  \"Naive FT (160M, +1 Epoch), Merge - 40 Steps\": {\n",
      "    \"vqa-v2\": 0.0,\n",
      "    \"textvqa-ocr\": 0.0,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5567765567765568,\n",
      "    \"winogrande\": 0.5098658247829518,\n",
      "    \"lambada_standard\": 0.23132156025616146,\n",
      "    \"arc_easy\": 0.4398148148148148,\n",
      "    \"arc_challenge\": 0.19965870307167236\n",
      "  },\n",
      "  \"LoRA (160M) RSLoRA, Merge - 1040 Steps\": {\n",
      "    \"vqa-v2\": 0.1832,\n",
      "    \"textvqa-ocr\": 0.00322265625,\n",
      "    \"textvqa-pure\": 0.022851562500000002,\n",
      "    \"gqa\": 0.0801,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5054945054945055,\n",
      "    \"winogrande\": 0.48855564325177586,\n",
      "    \"lambada_standard\": 0.10130021346788279,\n",
      "    \"arc_easy\": 0.36784511784511786,\n",
      "    \"arc_challenge\": 0.19795221843003413\n",
      "  },\n",
      "  \"LoRA (160M) RSLoRA, Merge - 2600 Steps\": {\n",
      "    \"vqa-v2\": 0.32420000000000004,\n",
      "    \"textvqa-ocr\": 0.00732421875,\n",
      "    \"textvqa-pure\": 0.020019531250000003,\n",
      "    \"gqa\": 0.19140000000000001,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5238095238095238,\n",
      "    \"winogrande\": 0.4925019731649566,\n",
      "    \"lambada_standard\": 0.09819522608189404,\n",
      "    \"arc_easy\": 0.335016835016835,\n",
      "    \"arc_challenge\": 0.19027303754266212\n",
      "  },\n",
      "  \"LoRA (160M) RSLoRA, Merge - 650 Steps\": {\n",
      "    \"vqa-v2\": 0.0388,\n",
      "    \"textvqa-ocr\": 0.007910156250000001,\n",
      "    \"textvqa-pure\": 0.0060546875,\n",
      "    \"gqa\": 0.0146,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5347985347985348,\n",
      "    \"winogrande\": 0.5027624309392266,\n",
      "    \"lambada_standard\": 0.089656510770425,\n",
      "    \"arc_easy\": 0.36153198653198654,\n",
      "    \"arc_challenge\": 0.1962457337883959\n",
      "  },\n",
      "  \"LoRA (160M) RSLoRA, Merge - 400 Steps\": {\n",
      "    \"vqa-v2\": 0.0051,\n",
      "    \"textvqa-ocr\": 0.00185546875,\n",
      "    \"textvqa-pure\": 0.0021484375,\n",
      "    \"gqa\": 0.001,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5457875457875457,\n",
      "    \"winogrande\": 0.5090765588003157,\n",
      "    \"lambada_standard\": 0.1288569765185329,\n",
      "    \"arc_easy\": 0.3573232323232323,\n",
      "    \"arc_challenge\": 0.18515358361774745\n",
      "  },\n",
      "  \"LoRA (160M) RSLoRA, Merge - 200 Steps\": {\n",
      "    \"vqa-v2\": 0.0078000000000000005,\n",
      "    \"textvqa-ocr\": 0.001953125,\n",
      "    \"textvqa-pure\": 0.00185546875,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5457875457875457,\n",
      "    \"winogrande\": 0.4964483030781373,\n",
      "    \"lambada_standard\": 0.17543178730836406,\n",
      "    \"arc_easy\": 0.3640572390572391,\n",
      "    \"arc_challenge\": 0.2098976109215017\n",
      "  },\n",
      "  \"LoRA (160M) LoRA, Track Plasticity\": {\n",
      "    \"vqa-v2\": 0.022099999999999998,\n",
      "    \"textvqa-ocr\": 0.003125,\n",
      "    \"textvqa-pure\": 0.004296875,\n",
      "    \"gqa\": 0.0,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5714285714285714,\n",
      "    \"winogrande\": 0.5074980268350434,\n",
      "    \"lambada_standard\": 0.15796623326217737,\n",
      "    \"arc_easy\": 0.41203703703703703,\n",
      "    \"arc_challenge\": 0.21245733788395904\n",
      "  },\n",
      "  \"LoRA (160M) LoRA, Track Plasticity, Constant LR with Warmup\": {\n",
      "    \"vqa-v2\": 0.1245,\n",
      "    \"textvqa-ocr\": 0.00732421875,\n",
      "    \"textvqa-pure\": 0.008203125,\n",
      "    \"gqa\": 0.0557,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5311355311355311,\n",
      "    \"winogrande\": 0.5090765588003157,\n",
      "    \"lambada_standard\": 0.17504366388511547,\n",
      "    \"arc_easy\": 0.3918350168350168,\n",
      "    \"arc_challenge\": 0.197098976109215\n",
      "  },\n",
      "  \"AdaLoRA (160M)\": {\n",
      "    \"vqa-v2\": 0.003,\n",
      "    \"textvqa-ocr\": 0.00087890625,\n",
      "    \"textvqa-pure\": 0.0,\n",
      "    \"gqa\": 0.0039000000000000003,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5347985347985348,\n",
      "    \"winogrande\": 0.4996053670086819,\n",
      "    \"lambada_standard\": 0.12594605084416843,\n",
      "    \"arc_easy\": 0.37037037037037035,\n",
      "    \"arc_challenge\": 0.21245733788395904\n",
      "  },\n",
      "  \"LoRA (160M)*\": {\n",
      "    \"vqa-v2\": 0.0115,\n",
      "    \"textvqa-ocr\": 0.0009765625,\n",
      "    \"textvqa-pure\": 0.00087890625,\n",
      "    \"gqa\": 0.001,\n",
      "    \"refcoco\": 0.0,\n",
      "    \"wsc273\": 0.5238095238095238,\n",
      "    \"winogrande\": 0.4988161010260458,\n",
      "    \"lambada_standard\": 0.156413739569183,\n",
      "    \"arc_easy\": 0.380050505050505,\n",
      "    \"arc_challenge\": 0.2158703071672355\n",
      "  }\n",
      "}\n",
      "\n",
      "\\begin{table*}[h]\n",
      "  \\caption{\\textbf{LLaVA Model Performance:} Other Methods}\n",
      "  \\label{tab:other_methods_acc}\n",
      "  \\centering\n",
      "  \\resizebox{\\linewidth}{!}{\n",
      "    \\begin{tabular}{l|cccc|c|cc}\n",
      "     \\toprule\n",
      "     \\textbf{Model} & \\multicolumn{4}{c|}{\\textbf{Vision-Language (VL)}} & \\textbf{VL Avg.} & \\multicolumn{2}{c}{\\textbf{NL Avg.}} \\\\\n",
      "     & \\textbf{VQAv2} & \\textbf{TextVQA OCR} & \\textbf{TextVQA Pure} & \\textbf{GQA} & Acc $\\uparrow$ & $\\Delta \\downarrow$ & Acc $\\uparrow$ \\\\\n",
      "     \\midrule\n",
      "Naive FT & 30.32 & 2.40 & 3.83 & 22.17 & 5.29 & 7.83 & 24.78 \\\\\n",
      "Language Only LLM & - & - & - & - & - & - & 32.61 \\\\\n",
      "\\midrule\n",
      "Soft Targets (160M) & 32.67 & 6.92 & 6.10 & 25.39 & 10.57 & 2.83 & 29.78 \\\\\n",
      "SGM (160M) & 28.39 & 1.37 & 2.71 & 17.48 & 3.36 & 2.68 & 29.93 \\\\\n",
      "LoRA (160M) & 28.97 & 1.02 & 1.74 & 17.97 & 2.42 & 0.04 & 32.57 \\\\\n",
      "LoRA (160M) RSLoRA, Merge - 2600 Steps & 32.42 & 0.73 & 2.00 & 19.14 & 2.05 & 10.26 & 22.36 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 2599 Steps & 11.51 & 0.89 & 1.37 & 6.64 & 1.91 & 0.45 & 32.17 \\\\\n",
      "LoRA (160M) LoRA, Track Plasticity, Constant LR with Warmup & 12.45 & 0.73 & 0.82 & 5.57 & 1.41 & 3.52 & 29.09 \\\\\n",
      "Naive FT (160M, +2 Epochs), Merge - 2599 Steps & 14.47 & 0.56 & 1.18 & 4.88 & 1.37 & 1.24 & 31.37 \\\\\n",
      "LoRA (160M) RSLoRA, Merge - 1040 Steps & 18.32 & 0.32 & 2.29 & 8.01 & 1.08 & 9.54 & 23.08 \\\\\n",
      "Corrected OLF LLaVA (160M) & 2.54 & 2.21 & 0.41 & 1.95 & 1.05 & - & - \\\\\n",
      "LoRA (160M) RSLoRA, Merge - 650 Steps & 3.88 & 0.79 & 0.61 & 1.46 & 1.04 & 10.75 & 21.86 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 1299 Steps & 2.89 & 0.63 & 0.47 & 0.68 & 0.72 & 1.54 & 31.07 \\\\\n",
      "Naive FT (160M, +2 Epochs), Merge - 5198 Steps & 1.49 & 0.56 & 0.27 & 0.10 & 0.25 & 2.81 & 29.80 \\\\\n",
      "LoRA (160M) RSLoRA, Merge - 400 Steps & 0.51 & 0.19 & 0.21 & 0.10 & 0.18 & 7.30 & 25.31 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 162 Steps & 0.96 & 0.10 & 0.09 & 0.78 & 0.17 & 0.25 & 32.36 \\\\\n",
      "LoRA (160M)* & 1.15 & 0.10 & 0.09 & 0.10 & 0.12 & 4.16 & 28.46 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 324 Steps & 0.09 & 0.03 & 0.00 & 0.00 & 0.00 & -0.35 & 32.96 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 649 Steps & 0.10 & 0.12 & 0.00 & 0.00 & 0.00 & -0.13 & 32.75 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 40 Steps & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.07 & 32.55 \\\\\n",
      "Naive FT (160M, +1 Epoch), Merge - 81 Steps & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.63 & 31.98 \\\\\n",
      "LoRA (160M) RSLoRA, Merge - 200 Steps & 0.78 & 0.20 & 0.19 & 0.00 & 0.00 & 3.30 & 29.31 \\\\\n",
      "LoRA (160M) LoRA, Track Plasticity & 2.21 & 0.31 & 0.43 & 0.00 & 0.00 & 3.52 & 29.10 \\\\\n",
      "AdaLoRA (160M) & 0.30 & 0.09 & 0.00 & 0.39 & 0.00 & 6.60 & 26.02 \\\\\n",
      "\n",
      "     \\bottomrule\n",
      "    \\end{tabular}\n",
      "  }\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Define the datasets of interest\n",
    "datasets = [\n",
    "    'vqa-v2', 'textvqa-ocr', 'textvqa-pure', 'gqa', 'refcoco',\n",
    "    'wsc273', 'winogrande', 'lambada_standard', 'arc_easy', 'arc_challenge'\n",
    "]\n",
    "\n",
    "# Define the result dictionary\n",
    "result = {}\n",
    "\n",
    "# Path to the JSON results file\n",
    "results_file = 'results_nlp.json'\n",
    "\n",
    "# Read the JSON results file\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    print(f\"Error: File {results_file} not found.\")\n",
    "\n",
    "# Mapping from different methods to model names\n",
    "model_mappings = {\n",
    "    'vicuna' : 'reproduction-align-pythia+160m',\n",
    "    'original' : 'stage-final-llava-v15-pythia+160m',\n",
    "    'soft': 'stage-final-llava-v15-pythia+160m-soft',\n",
    "    'oolf': 'stage-final-llava-v15-pythia+160m-oolf',\n",
    "    'sgm-oolf': 'stage-final-llava-v15-pythia+160m-sgm-oolf',\n",
    "    'sgm': 'stage-final-llava-v15-pythia+160m-sgm',\n",
    "    'lora': 'stage-final-llava-v15-pythia+160m-lora',\n",
    "    'merging_per_epoch_1_epoch_2': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-1-epochs-2',\n",
    "    'merging_per_epoch_2_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-2-epochs-1',\n",
    "    'merging_per_epoch_2_epoch_2': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-2-epochs-2',\n",
    "    'merging_per_epoch_4_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-4-epochs-1',\n",
    "    'merging_per_epoch_8_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-8-epochs-1',\n",
    "    'merging_per_epoch_16_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-16-epochs-1',\n",
    "    'merging_per_epoch_32_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-32-epochs-1',\n",
    "    'merging_per_epoch_64_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-64-epochs-1',\n",
    "    'merging_per_epoch_128_epoch_1': 'stage-final-llava-v15-pythia+160m-merging_per_epoch-128-epochs-1',\n",
    "    'lora_after_warmup_1040': \"stage-final-llava-v15-pythia+160m-merges_after_steps-1040-lora_after_warmup\",\n",
    "    'lora_after_warmup_2600': \"stage-final-llava-v15-pythia+160m-merges_after_steps-2600-lora_after_warmup\",\n",
    "    'lora_after_warmup_650': \"stage-final-llava-v15-pythia+160m-merges_after_steps-650-lora_after_warmup\",\n",
    "    'lora_after_warmup_400': \"stage-final-llava-v15-pythia+160m-merges_after_steps-400-lora_after_warmup\",\n",
    "    'lora_after_warmup_200': \"stage-final-llava-v15-pythia+160m-merges_after_steps-200-lora_after_warmup-rerun\",\n",
    "    'lora_track_plasiticty': 'stage-final-llava-v15-pythia+160m-lora-track-plasticity',\n",
    "    'lora_track_plasticity_constant_lr_with_warmup': 'stage-final-llava-v15-pythia+160m-lora-track-plasticity-constant_lr_with_warmup',\n",
    "    'adalora': 'stage-final-llava-v15-pythia+160m-adalora-constant_lr_warmup', #\n",
    "    'lora-rerun': \"stage-final-llava-v15-pythia+160m-lora-track-plasticity-logpl-constant_lr_with_warmup\",#\n",
    "}\n",
    "\n",
    "# Label name mappings for the main methods and variants\n",
    "def get_merge_label(base_label, merge_per_epoch):\n",
    "    steps_per_merge = int(5198 / merge_per_epoch)\n",
    "    return f'{base_label}, Merge - {steps_per_merge} Steps'\n",
    "\n",
    "name_mapping = {\n",
    "    'vicuna' : 'Language Only LLM',\n",
    "    'original': 'Naive FT (160M)',\n",
    "    'lora': 'LoRA (160M)',\n",
    "    'soft': 'Soft Targets (160M)',\n",
    "    'oolf': 'Corrected OLF LLaVA (160M)',\n",
    "    'sgm-oolf': 'SGM + Corrected OLF (160M)',\n",
    "    'sgm': 'SGM (160M)',\n",
    "    'merging_per_epoch_1_epoch_2': get_merge_label('Naive FT (160M, +2 Epochs)', 1),\n",
    "    'merging_per_epoch_2_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 2),\n",
    "    'merging_per_epoch_2_epoch_2': get_merge_label('Naive FT (160M, +2 Epochs)', 2),\n",
    "    'merging_per_epoch_4_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 4),\n",
    "    'merging_per_epoch_8_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 8),\n",
    "    'merging_per_epoch_16_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 16),\n",
    "    'merging_per_epoch_32_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 32),\n",
    "    'merging_per_epoch_64_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 64),\n",
    "    'merging_per_epoch_128_epoch_1': get_merge_label('Naive FT (160M, +1 Epoch)', 128),\n",
    "    'schedule_free_epoch_1': 'Naive FT (160M, +1 Epoch) Sch. Free',\n",
    "    'schedule_free_epoch_2': 'Naive FT (160M, +2 Epochs) Sch. Free',\n",
    "    'schedule_free_epoch_3': 'Naive FT (160M, +3 Epochs) Sch. Free',\n",
    "    'schedule_free_epoch_4': 'Naive FT (160M, +4 Epochs) Sch. Free',\n",
    "    'lora_after_warmup_1040': 'LoRA (160M) RSLoRA, Merge - 1040 Steps',\n",
    "    'lora_after_warmup_2600': 'LoRA (160M) RSLoRA, Merge - 2600 Steps',\n",
    "    'lora_after_warmup_650': 'LoRA (160M) RSLoRA, Merge - 650 Steps',\n",
    "    'lora_after_warmup_400': 'LoRA (160M) RSLoRA, Merge - 400 Steps',\n",
    "    'lora_after_warmup_200': 'LoRA (160M) RSLoRA, Merge - 200 Steps',\n",
    "    'lora_track_plasiticty': 'LoRA (160M) LoRA, Track Plasticity',\n",
    "    'lora_track_plasticity_constant_lr_with_warmup': 'LoRA (160M) LoRA, Track Plasticity, Constant LR with Warmup',\n",
    "    'adalora': 'AdaLoRA (160M)', #\n",
    "    'lora-rerun': 'LoRA (160M)*',#\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize model mappings\n",
    "model_results = {model: [] for model in model_mappings.keys()}\n",
    "\n",
    "# Populate the mappings based on the given mappings\n",
    "for method, model_name in model_mappings.items():\n",
    "    if model_name in result:\n",
    "        metrics = result[model_name]\n",
    "        accuracies = list(metrics.values())\n",
    "        avg_accuracy = np.nanmean(accuracies)\n",
    "        model_results[method].append((model_name, avg_accuracy))\n",
    "    else:\n",
    "        print(f\"Warning: Model '{model_name}' not found in results\")\n",
    "\n",
    "# Identify the highest accuracy model for each mapping\n",
    "highest_accuracy_models = {}\n",
    "for method, mappings in model_results.items():\n",
    "    if mappings:\n",
    "        highest_accuracy_models[method] = max(mappings, key=lambda x: x[1])\n",
    "\n",
    "# Save the highest accuracy models to a file\n",
    "output_file = 'highest_accuracy_models.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(highest_accuracy_models, f, indent=2)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "methods = [name_mapping[model] for model in model_mappings.keys() if model in highest_accuracy_models]\n",
    "results_dict = {}\n",
    "\n",
    "for model in model_mappings.keys():\n",
    "    if model in highest_accuracy_models:\n",
    "        model_name, _ = highest_accuracy_models[model]\n",
    "        metrics = result[model_name]\n",
    "        accuracies = {dataset: metrics.get(dataset, np.nan) for dataset in datasets}\n",
    "        results_dict[name_mapping[model]] = accuracies\n",
    "\n",
    "# Output the results dictionary\n",
    "print(json.dumps(results_dict, indent=2))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Calculate delta values\n",
    "original_llava_acc = results_dict[\"Naive FT (160M)\"]\n",
    "language_only_llm_acc = results_dict.get(\"Language Only LLM\", {})\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model, accuracies in results_dict.items():\n",
    "    if model in [\"Naive FT (160M)\", \"Language Only LLM\"]:\n",
    "        continue\n",
    "    avg_acc_vl = hmean([accuracies[dataset] for dataset in [\"vqa-v2\", \"textvqa-ocr\", \"textvqa-pure\", \"gqa\"]])\n",
    "    avg_acc_nl = hmean([accuracies[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "    delta_nl = hmean([language_only_llm_acc.get(dataset, np.nan) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - avg_acc_nl \n",
    "    table_data.append((model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl))\n",
    "\n",
    "# Sort the data by Avg. VL Accuracy and highest NL Delta\n",
    "table_data = sorted(table_data, key=lambda x: (x[2], -x[3]), reverse=True)\n",
    "\n",
    "# Function to format values or return \"-\"\n",
    "def format_value(value):\n",
    "    return \"{:.2f}\".format(value * 100) if not np.isnan(value) else \"-\"\n",
    "\n",
    "# Generate LaTeX table for other methods\n",
    "latex_code_other = \"\"\"\n",
    "\\\\begin{table*}[h]\n",
    "  \\\\caption{\\\\textbf{LLaVA Model Performance:} Other Methods}\n",
    "  \\\\label{tab:other_methods_acc}\n",
    "  \\\\centering\n",
    "  \\\\resizebox{\\\\linewidth}{!}{\n",
    "    \\\\begin{tabular}{l|cccc|c|cc}\n",
    "     \\\\toprule\n",
    "     \\\\textbf{Model} & \\\\multicolumn{4}{c|}{\\\\textbf{Vision-Language (VL)}} & \\\\textbf{VL Avg.} & \\\\multicolumn{2}{c}{\\\\textbf{NL Avg.}} \\\\\\\\\n",
    "     & \\\\textbf{VQAv2} & \\\\textbf{TextVQA OCR} & \\\\textbf{TextVQA Pure} & \\\\textbf{GQA} & Acc $\\\\uparrow$ & $\\\\Delta \\\\downarrow$ & Acc $\\\\uparrow$ \\\\\\\\\n",
    "     \\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "original_llava_avg_delta_nl = hmean([language_only_llm_acc.get(dataset, 0) for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]]) - hmean([original_llava_acc[dataset] for dataset in [\"wsc273\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"lambada_standard\"]])\n",
    "\n",
    "latex_code_other += \"Naive FT & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & {delta_nl} & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(original_llava_acc[\"vqa-v2\"]),\n",
    "    textvqa_ocr=format_value(original_llava_acc[\"textvqa-ocr\"]),\n",
    "    textvqa_pure=format_value(original_llava_acc[\"textvqa-pure\"]),\n",
    "    gqa=format_value(original_llava_acc[\"gqa\"]),\n",
    "    avg_acc_vl=format_value(hmean([original_llava_acc[\"vqa-v2\"], original_llava_acc[\"textvqa-ocr\"], original_llava_acc[\"textvqa-pure\"], original_llava_acc[\"gqa\"]])),\n",
    "    delta_nl=format_value(original_llava_avg_delta_nl),\n",
    "    avg_acc_nl=format_value(hmean([original_llava_acc[\"wsc273\"], original_llava_acc[\"winogrande\"], original_llava_acc[\"arc_easy\"], original_llava_acc[\"arc_challenge\"], original_llava_acc[\"lambada_standard\"]]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"Language Only LLM & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {avg_acc_vl} & - & {avg_acc_nl} \\\\\\\\\\n\".format(\n",
    "    vqa_v2=format_value(language_only_llm_acc.get(\"vqa-v2\", np.nan)),\n",
    "    textvqa_ocr=format_value(language_only_llm_acc.get(\"textvqa-ocr\", np.nan)),\n",
    "    textvqa_pure=format_value(language_only_llm_acc.get(\"textvqa-pure\", np.nan)),\n",
    "    gqa=format_value(language_only_llm_acc.get(\"gqa\", np.nan)),\n",
    "    avg_acc_vl=format_value(hmean([language_only_llm_acc.get(\"vqa-v2\", 0), language_only_llm_acc.get(\"textvqa-ocr\", 0), language_only_llm_acc.get(\"textvqa-pure\", 0), language_only_llm_acc.get(\"gqa\", 0)])),\n",
    "    avg_acc_nl=format_value(hmean([language_only_llm_acc.get(\"wsc273\", 0), language_only_llm_acc.get(\"winogrande\", 0), language_only_llm_acc.get(\"arc_easy\", 0), language_only_llm_acc.get(\"arc_challenge\", 0), language_only_llm_acc.get(\"lambada_standard\", 0)]))\n",
    ")\n",
    "\n",
    "latex_code_other += \"\\\\midrule\\n\"\n",
    "\n",
    "for model, accuracies, avg_acc_vl, delta_nl, avg_acc_nl in table_data:\n",
    "    latex_code_other += \"{model} & {vqa_v2} & {textvqa_ocr} & {textvqa_pure} & {gqa} & {acc_vl} & {delta_nl} & {acc_nl} \\\\\\\\\\n\".format(\n",
    "        model=model,\n",
    "        vqa_v2=format_value(accuracies[\"vqa-v2\"]),\n",
    "        textvqa_ocr=format_value(accuracies[\"textvqa-ocr\"]),\n",
    "        textvqa_pure=format_value(accuracies[\"textvqa-pure\"]),\n",
    "        gqa=format_value(accuracies[\"gqa\"]),\n",
    "        acc_vl=format_value(avg_acc_vl),\n",
    "        delta_nl=format_value(delta_nl),\n",
    "        acc_nl=format_value(avg_acc_nl)\n",
    "    )\n",
    "\n",
    "latex_code_other += \"\"\"\n",
    "     \\\\bottomrule\n",
    "    \\\\end{tabular}\n",
    "  }\n",
    "\\\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code_other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
